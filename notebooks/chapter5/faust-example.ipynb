{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee1ee16",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install \"faust\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201c029e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install 'git+https://github.com/logicalclocks/hopsworks-api@main#egg=hopsworks&subdirectory=python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c22cb11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faust\n",
    "import hopsworks\n",
    "import ssl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b201addb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package faust:\n",
      "\n",
      "NAME\n",
      "    faust - Python Stream processing.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    __main__\n",
      "    _cython (package)\n",
      "    agents (package)\n",
      "    app (package)\n",
      "    assignor (package)\n",
      "    auth\n",
      "    channels\n",
      "    cli (package)\n",
      "    events\n",
      "    exceptions\n",
      "    fixups (package)\n",
      "    joins\n",
      "    livecheck (package)\n",
      "    models (package)\n",
      "    sensors (package)\n",
      "    serializers (package)\n",
      "    stores (package)\n",
      "    streams\n",
      "    tables (package)\n",
      "    topics\n",
      "    transport (package)\n",
      "    types (package)\n",
      "    utils (package)\n",
      "    web (package)\n",
      "    windows\n",
      "    worker\n",
      "\n",
      "CLASSES\n",
      "    abc.ABC(builtins.object)\n",
      "        faust.types.models.ModelOptions\n",
      "        faust.types.settings.Settings\n",
      "    collections.abc.AsyncIterable(builtins.object)\n",
      "        faust.types.streams.StreamT(collections.abc.AsyncIterable, faust.types.streams.JoinableT, mode.types.services.ServiceT)\n",
      "            faust.streams.Stream(faust.types.streams.StreamT, mode.services.Service)\n",
      "    collections.abc.AsyncIterator(collections.abc.AsyncIterable)\n",
      "        faust.types.channels.ChannelT(collections.abc.AsyncIterator, typing.Generic)\n",
      "            faust.channels.Channel\n",
      "            faust.types.topics.TopicT\n",
      "                faust.topics.Topic(faust.channels.SerializedChannel, faust.types.topics.TopicT)\n",
      "    contextlib.AbstractAsyncContextManager(abc.ABC)\n",
      "        faust.types.events.EventT(contextlib.AbstractAsyncContextManager, typing.Generic)\n",
      "            faust.events.Event\n",
      "        mode.types.services.ServiceT(contextlib.AbstractAsyncContextManager, typing.Generic)\n",
      "            faust.types.streams.StreamT(collections.abc.AsyncIterable, faust.types.streams.JoinableT, mode.types.services.ServiceT)\n",
      "                faust.streams.Stream(faust.types.streams.StreamT, mode.services.Service)\n",
      "    faust.auth.Credentials(faust.types.auth.CredentialsT)\n",
      "        faust.auth.GSSAPICredentials\n",
      "        faust.auth.SASLCredentials\n",
      "        faust.auth.SSLCredentials\n",
      "    faust.channels.SerializedChannel(faust.channels.Channel)\n",
      "        faust.topics.Topic(faust.channels.SerializedChannel, faust.types.topics.TopicT)\n",
      "    faust.models.base.Model(faust.types.models.ModelT)\n",
      "        faust.models.record.Record\n",
      "    faust.tables.base.Collection(mode.services.Service, faust.types.tables.CollectionT)\n",
      "        faust.tables.table.Table(faust.types.tables.TableT, faust.tables.base.Collection)\n",
      "            faust.tables.globaltable.GlobalTable(faust.tables.table.Table, faust.types.tables.GlobalTableT)\n",
      "            faust.tables.sets.SetTable\n",
      "                faust.tables.sets.SetGlobalTable(faust.tables.sets.SetTable, faust.types.tables.GlobalTableT)\n",
      "    faust.types.agents.AgentT(mode.types.services.ServiceT, typing.Generic)\n",
      "        faust.agents.agent.Agent(faust.types.agents.AgentT, mode.services.Service)\n",
      "    faust.types.app.AppT(mode.types.services.ServiceT)\n",
      "        faust.app.base.App(faust.types.app.AppT, mode.services.Service)\n",
      "    faust.types.codecs.CodecT(builtins.object)\n",
      "        faust.serializers.codecs.Codec\n",
      "    faust.types.sensors.SensorT(faust.types.sensors.SensorInterfaceT, mode.types.services.ServiceT)\n",
      "        faust.sensors.base.Sensor(faust.types.sensors.SensorT, mode.services.Service)\n",
      "            faust.sensors.monitor.Monitor(faust.sensors.base.Sensor, mode.utils.objects.KeywordReduce)\n",
      "    faust.types.serializers.SchemaT(typing.Generic)\n",
      "        faust.serializers.schemas.Schema\n",
      "    faust.types.streams.JoinableT(abc.ABC)\n",
      "        faust.types.streams.StreamT(collections.abc.AsyncIterable, faust.types.streams.JoinableT, mode.types.services.ServiceT)\n",
      "            faust.streams.Stream(faust.types.streams.StreamT, mode.services.Service)\n",
      "    faust.types.tables.TableT(faust.types.tables.CollectionT, mode.utils.collections.ManagedUserDict)\n",
      "        faust.tables.table.Table(faust.types.tables.TableT, faust.tables.base.Collection)\n",
      "            faust.tables.globaltable.GlobalTable(faust.tables.table.Table, faust.types.tables.GlobalTableT)\n",
      "            faust.tables.sets.SetTable\n",
      "                faust.tables.sets.SetGlobalTable(faust.tables.sets.SetTable, faust.types.tables.GlobalTableT)\n",
      "    faust.types.windows.WindowT(abc.ABC)\n",
      "        faust.windows.Window\n",
      "            faust.windows._PyHoppingWindow\n",
      "                faust.windows.TumblingWindow\n",
      "            faust.windows._PySlidingWindow\n",
      "    mode.services.ServiceBase(mode.types.services.ServiceT)\n",
      "        mode.services.Service(mode.services.ServiceBase, mode.services.ServiceCallbacks)\n",
      "            faust.agents.agent.Agent(faust.types.agents.AgentT, mode.services.Service)\n",
      "            faust.app.base.App(faust.types.app.AppT, mode.services.Service)\n",
      "            faust.sensors.base.Sensor(faust.types.sensors.SensorT, mode.services.Service)\n",
      "                faust.sensors.monitor.Monitor(faust.sensors.base.Sensor, mode.utils.objects.KeywordReduce)\n",
      "    mode.services.ServiceCallbacks(builtins.object)\n",
      "        mode.services.Service(mode.services.ServiceBase, mode.services.ServiceCallbacks)\n",
      "            faust.agents.agent.Agent(faust.types.agents.AgentT, mode.services.Service)\n",
      "            faust.app.base.App(faust.types.app.AppT, mode.services.Service)\n",
      "            faust.sensors.base.Sensor(faust.types.sensors.SensorT, mode.services.Service)\n",
      "                faust.sensors.monitor.Monitor(faust.sensors.base.Sensor, mode.utils.objects.KeywordReduce)\n",
      "    mode.worker.Worker(mode.services.Service)\n",
      "        faust.worker.Worker\n",
      "    typing.Generic(builtins.object)\n",
      "        faust.types.channels.ChannelT(collections.abc.AsyncIterator, typing.Generic)\n",
      "            faust.channels.Channel\n",
      "            faust.types.topics.TopicT\n",
      "                faust.topics.Topic(faust.channels.SerializedChannel, faust.types.topics.TopicT)\n",
      "        faust.types.events.EventT(contextlib.AbstractAsyncContextManager, typing.Generic)\n",
      "            faust.events.Event\n",
      "        mode.types.services.ServiceT(contextlib.AbstractAsyncContextManager, typing.Generic)\n",
      "            faust.types.streams.StreamT(collections.abc.AsyncIterable, faust.types.streams.JoinableT, mode.types.services.ServiceT)\n",
      "                faust.streams.Stream(faust.types.streams.StreamT, mode.services.Service)\n",
      "    \n",
      "    class Agent(faust.types.agents.AgentT, mode.services.Service)\n",
      "     |  Agent(*args, **kwds)\n",
      "     |  \n",
      "     |  Agent.\n",
      "     |  \n",
      "     |  This is the type of object returned by the ``@app.agent`` decorator.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Agent\n",
      "     |      faust.types.agents.AgentT\n",
      "     |      mode.services.Service\n",
      "     |      mode.services.ServiceBase\n",
      "     |      mode.types.services.ServiceT\n",
      "     |      contextlib.AbstractAsyncContextManager\n",
      "     |      abc.ABC\n",
      "     |      typing.Generic\n",
      "     |      mode.services.ServiceCallbacks\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, *, index: int = None, active_partitions: Set[faust.types.tuples.TP] = None, stream: faust.types.streams.StreamT = None, channel: faust.types.channels.ChannelT = None) -> faust.types.agents.ActorT[typing.Union[typing.AsyncIterable, typing.Awaitable]]\n",
      "     |      Create new actor instance for this agent.\n",
      "     |  \n",
      "     |  __init__(self, fun: Callable[[faust.types.streams.StreamT[~_T]], Union[Coroutine[Any, Any, NoneType], Awaitable[NoneType], AsyncIterable]], *, app: faust.types.app.AppT, name: str = None, channel: Union[str, faust.types.channels.ChannelT] = None, concurrency: int = 1, sink: Iterable[Union[ForwardRef('AgentT'), faust.types.channels.ChannelT, Callable[[Any], Union[Awaitable, NoneType]]]] = None, on_error: Callable[[ForwardRef('AgentT'), BaseException], Awaitable] = None, supervisor_strategy: Type[mode.types.supervisors.SupervisorStrategyT] = None, help: str = None, schema: faust.types.serializers.SchemaT = None, key_type: Union[Type[faust.types.models.ModelT], Type[bytes], Type[str]] = None, value_type: Union[Type[faust.types.models.ModelT], Type[bytes], Type[str]] = None, isolated_partitions: bool = False, use_reply_headers: bool = None, **kwargs: Any) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  actor_from_stream(self, stream: Union[faust.types.streams.StreamT, NoneType], *, index: int = None, active_partitions: Set[faust.types.tuples.TP] = None, channel: faust.types.channels.ChannelT = None) -> faust.types.agents.ActorT[typing.Union[typing.AsyncIterable, typing.Awaitable]]\n",
      "     |      Create new actor from stream.\n",
      "     |  \n",
      "     |  actor_tracebacks(self) -> List[str]\n",
      "     |  \n",
      "     |  add_sink(self, sink: Union[ForwardRef('AgentT'), faust.types.channels.ChannelT, Callable[[Any], Union[Awaitable, NoneType]]]) -> None\n",
      "     |      Add new sink to further handle results from this agent.\n",
      "     |  \n",
      "     |  async ask(self, value: Union[bytes, faust.types.core._ModelT, Any] = None, *, key: Union[bytes, faust.types.core._ModelT, Any, NoneType] = None, partition: int = None, timestamp: float = None, headers: Union[List[Tuple[str, bytes]], Mapping[str, bytes], NoneType] = None, reply_to: Union[ForwardRef('AgentT'), faust.types.channels.ChannelT, str] = None, correlation_id: str = None) -> Any\n",
      "     |      RPC operation: ask agent for result of processing value.\n",
      "     |      \n",
      "     |      This version will wait until the result is available\n",
      "     |      and return the processed value.\n",
      "     |  \n",
      "     |  async ask_nowait(self, value: Union[bytes, faust.types.core._ModelT, Any] = None, *, key: Union[bytes, faust.types.core._ModelT, Any, NoneType] = None, partition: int = None, timestamp: float = None, headers: Union[List[Tuple[str, bytes]], Mapping[str, bytes], NoneType] = None, reply_to: Union[ForwardRef('AgentT'), faust.types.channels.ChannelT, str] = None, correlation_id: str = None, force: bool = False) -> faust.agents.replies.ReplyPromise\n",
      "     |      RPC operation: ask agent for result of processing value.\n",
      "     |      \n",
      "     |      This version does not wait for the result to arrive,\n",
      "     |      but instead returns a promise of future evaluation.\n",
      "     |  \n",
      "     |  cancel(self) -> None\n",
      "     |      Cancel agent and its actor instances running in this process.\n",
      "     |  \n",
      "     |  async cast(self, value: Union[bytes, faust.types.core._ModelT, Any] = None, *, key: Union[bytes, faust.types.core._ModelT, Any, NoneType] = None, partition: int = None, timestamp: float = None, headers: Union[List[Tuple[str, bytes]], Mapping[str, bytes], NoneType] = None) -> None\n",
      "     |      RPC operation: like :meth:`ask` but do not expect reply.\n",
      "     |      \n",
      "     |      Cast here is like \"casting a spell\", and will not expect\n",
      "     |      a reply back from the agent.\n",
      "     |  \n",
      "     |  clone(self, *, cls: Type[faust.types.agents.AgentT] = None, **kwargs: Any) -> faust.types.agents.AgentT\n",
      "     |      Create clone of this agent object.\n",
      "     |      \n",
      "     |      Keyword arguments can be passed to override any argument\n",
      "     |      supported by :class:`Agent.__init__ <Agent>`.\n",
      "     |  \n",
      "     |  get_topic_names(self) -> Iterable[str]\n",
      "     |      Return list of topic names this agent subscribes to.\n",
      "     |  \n",
      "     |  info(self) -> Mapping\n",
      "     |      Return agent attributes as a dictionary.\n",
      "     |  \n",
      "     |  async join(self, values: Union[AsyncIterable[Union[bytes, faust.types.core._ModelT, Any]], Iterable[Union[bytes, faust.types.core._ModelT, Any]]], key: Union[bytes, faust.types.core._ModelT, Any, NoneType] = None, reply_to: Union[ForwardRef('AgentT'), faust.types.channels.ChannelT, str] = None) -> List[Any]\n",
      "     |      RPC map operation on a list of values.\n",
      "     |      \n",
      "     |      A join returns the results in order, and only returns once\n",
      "     |      all values have been processed.\n",
      "     |  \n",
      "     |  async kvjoin(self, items: Union[AsyncIterable[Tuple[Union[bytes, faust.types.core._ModelT, Any, NoneType], Union[bytes, faust.types.core._ModelT, Any]]], Iterable[Tuple[Union[bytes, faust.types.core._ModelT, Any, NoneType], Union[bytes, faust.types.core._ModelT, Any]]]], reply_to: Union[ForwardRef('AgentT'), faust.types.channels.ChannelT, str] = None) -> List[Any]\n",
      "     |      RPC map operation on list of ``(key, value)`` pairs.\n",
      "     |      \n",
      "     |      A join returns the results in order, and only returns once\n",
      "     |      all values have been processed.\n",
      "     |  \n",
      "     |  async kvmap(self, items: Union[AsyncIterable[Tuple[Union[bytes, faust.types.core._ModelT, Any, NoneType], Union[bytes, faust.types.core._ModelT, Any]]], Iterable[Tuple[Union[bytes, faust.types.core._ModelT, Any, NoneType], Union[bytes, faust.types.core._ModelT, Any]]]], reply_to: Union[ForwardRef('AgentT'), faust.types.channels.ChannelT, str] = None) -> AsyncIterator[str]\n",
      "     |      RPC map operation on a list of ``(key, value)`` pairs.\n",
      "     |      \n",
      "     |      A map operation iterates over results as they arrive.\n",
      "     |      See :meth:`join` and :meth:`kvjoin` if you want them in order.\n",
      "     |  \n",
      "     |  async map(self, values: Union[AsyncIterable, Iterable], key: Union[bytes, faust.types.core._ModelT, Any, NoneType] = None, reply_to: Union[ForwardRef('AgentT'), faust.types.channels.ChannelT, str] = None) -> AsyncIterator\n",
      "     |      RPC map operation on a list of values.\n",
      "     |      \n",
      "     |      A map operation iterates over results as they arrive.\n",
      "     |      See :meth:`join` and :meth:`kvjoin` if you want them in order.\n",
      "     |  \n",
      "     |  on_init_dependencies(self) -> Iterable[mode.types.services.ServiceT]\n",
      "     |      Return list of services dependencies required to start agent.\n",
      "     |  \n",
      "     |  async on_isolated_partitions_assigned(self, assigned: Set[faust.types.tuples.TP]) -> None\n",
      "     |      Call when isolated partitions are assigned.\n",
      "     |  \n",
      "     |  async on_isolated_partitions_revoked(self, revoked: Set[faust.types.tuples.TP]) -> None\n",
      "     |      Call when isolated partitions are revoked.\n",
      "     |  \n",
      "     |  async on_partitions_assigned(self, assigned: Set[faust.types.tuples.TP]) -> None\n",
      "     |      Call when partitions are assigned.\n",
      "     |  \n",
      "     |  async on_partitions_revoked(self, revoked: Set[faust.types.tuples.TP]) -> None\n",
      "     |      Call when partitions are revoked.\n",
      "     |  \n",
      "     |  async on_shared_partitions_assigned(self, assigned: Set[faust.types.tuples.TP]) -> None\n",
      "     |      Call when non-isolated partitions are assigned.\n",
      "     |  \n",
      "     |  async on_shared_partitions_revoked(self, revoked: Set[faust.types.tuples.TP]) -> None\n",
      "     |      Call when non-isolated partitions are revoked.\n",
      "     |  \n",
      "     |  async on_start(self) -> None\n",
      "     |      Call when an agent starts.\n",
      "     |  \n",
      "     |  async on_stop(self) -> None\n",
      "     |      Call when an agent stops.\n",
      "     |  \n",
      "     |  async send(self, *, key: Union[bytes, faust.types.core._ModelT, Any, NoneType] = None, value: Union[bytes, faust.types.core._ModelT, Any] = None, partition: int = None, timestamp: float = None, headers: Union[List[Tuple[str, bytes]], Mapping[str, bytes], NoneType] = None, key_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, value_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, callback: Callable[[faust.types.tuples.FutureMessage], Union[NoneType, Awaitable[NoneType]]] = None, reply_to: Union[ForwardRef('AgentT'), faust.types.channels.ChannelT, str] = None, correlation_id: str = None, force: bool = False) -> Awaitable[faust.types.tuples.RecordMetadata]\n",
      "     |      Send message to topic used by agent.\n",
      "     |  \n",
      "     |  stream(self, channel: faust.types.channels.ChannelT = None, active_partitions: Set[faust.types.tuples.TP] = None, **kwargs: Any) -> faust.types.streams.StreamT\n",
      "     |      Create underlying stream used by this agent.\n",
      "     |  \n",
      "     |  test_context(self, channel: faust.types.channels.ChannelT = None, supervisor_strategy: mode.types.supervisors.SupervisorStrategyT = None, on_error: Callable[[ForwardRef('AgentT'), BaseException], Awaitable] = None, **kwargs: Any) -> faust.types.agents.AgentTestWrapperT\n",
      "     |      Create new unit-testing wrapper for this agent.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  label\n",
      "     |      Return human-readable description of agent.\n",
      "     |  \n",
      "     |  shortlabel\n",
      "     |      Return short description of agent.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  channel\n",
      "     |      Return channel used by agent.\n",
      "     |  \n",
      "     |  channel_iterator\n",
      "     |      Return channel agent iterates over.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'_actor_by_partition': typing.MutableMapping[faust....\n",
      "     |  \n",
      "     |  logger = <Logger faust.agents.agent (INFO)>\n",
      "     |  \n",
      "     |  supervisor = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from faust.types.agents.AgentT:\n",
      "     |  \n",
      "     |  __orig_bases__ = (<class 'mode.types.services.ServiceT'>, typing.Gener...\n",
      "     |  \n",
      "     |  __parameters__ = (~_T,)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  __post_init__(self) -> None\n",
      "     |      Additional user initialization.\n",
      "     |  \n",
      "     |  async add_async_context(self, context: AbstractAsyncContextManager) -> Any\n",
      "     |  \n",
      "     |  add_context(self, context: AbstractContextManager) -> Any\n",
      "     |  \n",
      "     |  add_dependency(self, service: mode.types.services.ServiceT) -> mode.types.services.ServiceT\n",
      "     |      Add dependency to other service.\n",
      "     |      \n",
      "     |      The service will be started/stopped with this service.\n",
      "     |  \n",
      "     |  add_future(self, coro: Awaitable) -> _asyncio.Future\n",
      "     |      Add relationship to asyncio.Future.\n",
      "     |      \n",
      "     |      The future will be joined when this service is stopped.\n",
      "     |  \n",
      "     |  async add_runtime_dependency(self, service: mode.types.services.ServiceT) -> mode.types.services.ServiceT\n",
      "     |  \n",
      "     |  async crash(self, reason: BaseException) -> None\n",
      "     |      Crash the service and all child services.\n",
      "     |  \n",
      "     |  async itertimer(self, interval: Union[datetime.timedelta, float, str], *, max_drift_correction: float = 0.1, loop: asyncio.events.AbstractEventLoop = None, sleep: Callable[..., Awaitable] = None, clock: Callable[[], float] = <built-in function perf_counter>, name: str = '') -> AsyncIterator[float]\n",
      "     |      Sleep ``interval`` seconds for every iteration.\n",
      "     |      \n",
      "     |      This is an async iterator that takes advantage\n",
      "     |      of :func:`~mode.timers.Timer` to monitor drift and timer\n",
      "     |      oerlap.\n",
      "     |      \n",
      "     |      Uses ``Service.sleep`` so exits fast when the service is\n",
      "     |      stopped.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          Will sleep the full `interval` seconds before returning\n",
      "     |          from first iteration.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |          >>> async for sleep_time in self.itertimer(1.0):\n",
      "     |          ...   print('another second passed, just woke up...')\n",
      "     |          ...   await perform_some_http_request()\n",
      "     |  \n",
      "     |  async join_services(self, services: Sequence[mode.types.services.ServiceT]) -> None\n",
      "     |  \n",
      "     |  async maybe_start(self) -> bool\n",
      "     |      Start the service, if it has not already been started.\n",
      "     |  \n",
      "     |  on_init(self) -> None\n",
      "     |  \n",
      "     |  async remove_dependency(self, service: mode.types.services.ServiceT) -> mode.types.services.ServiceT\n",
      "     |      Stop and remove dependency of this service.\n",
      "     |  \n",
      "     |  async restart(self) -> None\n",
      "     |      Restart this service.\n",
      "     |  \n",
      "     |  service_reset(self) -> None\n",
      "     |  \n",
      "     |  set_shutdown(self) -> None\n",
      "     |      Set the shutdown signal.\n",
      "     |      \n",
      "     |      Notes:\n",
      "     |          If :attr:`wait_for_shutdown` is set, stopping the service\n",
      "     |          will wait for this flag to be set.\n",
      "     |  \n",
      "     |  async sleep(self, n: Union[datetime.timedelta, float, str], *, loop: asyncio.events.AbstractEventLoop = None) -> None\n",
      "     |      Sleep for ``n`` seconds, or until service stopped.\n",
      "     |  \n",
      "     |  async start(self) -> None\n",
      "     |  \n",
      "     |  async stop(self) -> None\n",
      "     |      Stop the service.\n",
      "     |  \n",
      "     |  async transition_with(self, flag: str, fut: Awaitable, *args: Any, **kwargs: Any) -> Any\n",
      "     |  \n",
      "     |  async wait(self, *coros: Union[_asyncio.Future, Generator[Any, NoneType, Any], Awaitable, asyncio.locks.Event, mode.utils.locks.Event], timeout: Union[datetime.timedelta, float, str] = None) -> mode.services.WaitResult\n",
      "     |      Wait for coroutines to complete, or until the service stops.\n",
      "     |  \n",
      "     |  async wait_first(self, *coros: Union[_asyncio.Future, Generator[Any, NoneType, Any], Awaitable, asyncio.locks.Event, mode.utils.locks.Event], timeout: Union[datetime.timedelta, float, str] = None) -> mode.services.WaitResults\n",
      "     |  \n",
      "     |  async wait_for_stopped(self, *coros: Union[_asyncio.Future, Generator[Any, NoneType, Any], Awaitable, asyncio.locks.Event, mode.utils.locks.Event], timeout: Union[datetime.timedelta, float, str] = None) -> bool\n",
      "     |  \n",
      "     |  async wait_many(self, coros: Iterable[Union[_asyncio.Future, Generator[Any, NoneType, Any], Awaitable, asyncio.locks.Event, mode.utils.locks.Event]], *, timeout: Union[datetime.timedelta, float, str] = None) -> mode.services.WaitResult\n",
      "     |  \n",
      "     |  async wait_until_stopped(self) -> None\n",
      "     |      Wait until the service is signalled to stop.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  __init_subclass__() -> None from abc.ABCMeta\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  from_awaitable(coro: Awaitable, *, name: str = None, **kwargs: Any) -> mode.types.services.ServiceT from abc.ABCMeta\n",
      "     |  \n",
      "     |  task(fun: Callable[[Any], Awaitable[NoneType]]) -> mode.services.ServiceTask from abc.ABCMeta\n",
      "     |      Decorate function to be used as background task.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> class S(Service):\n",
      "     |          ...\n",
      "     |          ...     @Service.task\n",
      "     |          ...     async def background_task(self):\n",
      "     |          ...         while not self.should_stop:\n",
      "     |          ...             await self.sleep(1.0)\n",
      "     |          ...             print('Waking up')\n",
      "     |  \n",
      "     |  timer(interval: Union[datetime.timedelta, float, str]) -> Callable[[Callable], mode.services.ServiceTask] from abc.ABCMeta\n",
      "     |      Background timer executing every ``n`` seconds.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> class S(Service):\n",
      "     |          ...\n",
      "     |          ...     @Service.timer(1.0)\n",
      "     |          ...     async def background_timer(self):\n",
      "     |          ...         print('Waking up')\n",
      "     |  \n",
      "     |  transitions_to(flag: str) -> Callable from abc.ABCMeta\n",
      "     |      Decorate function to set and reset diagnostic flag.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  crashed\n",
      "     |  \n",
      "     |  should_stop\n",
      "     |      Return :const:`True` if the service must stop.\n",
      "     |  \n",
      "     |  started\n",
      "     |      Return :const:`True` if the service was started.\n",
      "     |  \n",
      "     |  state\n",
      "     |      Service state - as a human readable string.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  beacon\n",
      "     |      Beacon used to track services in a dependency graph.\n",
      "     |  \n",
      "     |  crash_reason\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  Diag = <class 'mode.services.Diag'>\n",
      "     |      Service diagnostics.\n",
      "     |      \n",
      "     |      This can be used to track what your service is doing.\n",
      "     |      For example if your service is a Kafka consumer with a background\n",
      "     |      thread that commits the offset every 30 seconds, you may want to\n",
      "     |      see when this happens::\n",
      "     |      \n",
      "     |          DIAG_COMMITTING = 'committing'\n",
      "     |      \n",
      "     |          class Consumer(Service):\n",
      "     |      \n",
      "     |              @Service.task\n",
      "     |              async def _background_commit(self) -> None:\n",
      "     |                  while not self.should_stop:\n",
      "     |                      await self.sleep(30.0)\n",
      "     |                      self.diag.set_flag(DIAG_COMITTING)\n",
      "     |                      try:\n",
      "     |                          await self._consumer.commit()\n",
      "     |                      finally:\n",
      "     |                          self.diag.unset_flag(DIAG_COMMITTING)\n",
      "     |      \n",
      "     |      The above code is setting the flag manually, but you can also use\n",
      "     |      a decorator to accomplish the same thing::\n",
      "     |      \n",
      "     |          @Service.timer(30.0)\n",
      "     |          async def _background_commit(self) -> None:\n",
      "     |              await self.commit()\n",
      "     |      \n",
      "     |          @Service.transitions_with(DIAG_COMITTING)\n",
      "     |          async def commit(self) -> None:\n",
      "     |              await self._consumer.commit()\n",
      "     |  \n",
      "     |  abstract = False\n",
      "     |  \n",
      "     |  mundane_level = 'info'\n",
      "     |  \n",
      "     |  restart_count = 0\n",
      "     |  \n",
      "     |  shutdown_timeout = 60.0\n",
      "     |  \n",
      "     |  wait_for_shutdown = False\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mode.services.ServiceBase:\n",
      "     |  \n",
      "     |  async __aenter__(self) -> mode.types.services.ServiceT\n",
      "     |      Return `self` upon entering the runtime context.\n",
      "     |  \n",
      "     |  async __aexit__(self, exc_type: Type[BaseException] = None, exc_val: BaseException = None, exc_tb: traceback = None) -> Union[bool, NoneType]\n",
      "     |      Raise any exception triggered within the runtime context.\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from mode.services.ServiceBase:\n",
      "     |  \n",
      "     |  loop\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from contextlib.AbstractAsyncContextManager:\n",
      "     |  \n",
      "     |  __subclasshook__(C) from abc.ABCMeta\n",
      "     |      Abstract classes can override this to customize issubclass().\n",
      "     |      \n",
      "     |      This is invoked early on by abc.ABCMeta.__subclasscheck__().\n",
      "     |      It should return True, False or NotImplemented.  If it returns\n",
      "     |      NotImplemented, the normal algorithm is used.  Otherwise, it\n",
      "     |      overrides the normal algorithm (and the outcome is cached).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from contextlib.AbstractAsyncContextManager:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from abc.ABCMeta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mode.services.ServiceCallbacks:\n",
      "     |  \n",
      "     |  async on_first_start(self) -> None\n",
      "     |      Service started for the first time in this process.\n",
      "     |  \n",
      "     |  async on_restart(self) -> None\n",
      "     |      Service is being restarted.\n",
      "     |  \n",
      "     |  async on_shutdown(self) -> None\n",
      "     |      Service is being stopped/restarted.\n",
      "     |  \n",
      "     |  async on_started(self) -> None\n",
      "     |      Service has started.\n",
      "    \n",
      "    class App(faust.types.app.AppT, mode.services.Service)\n",
      "     |  App(*args, **kwds)\n",
      "     |  \n",
      "     |  Faust Application.\n",
      "     |  \n",
      "     |  Arguments:\n",
      "     |      id (str): Application ID.\n",
      "     |  \n",
      "     |  Keyword Arguments:\n",
      "     |      loop (asyncio.AbstractEventLoop): optional event loop to use.\n",
      "     |  \n",
      "     |  See Also:\n",
      "     |      :ref:`application-configuration` -- for supported keyword arguments.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      App\n",
      "     |      faust.types.app.AppT\n",
      "     |      mode.services.Service\n",
      "     |      mode.services.ServiceBase\n",
      "     |      mode.types.services.ServiceT\n",
      "     |      contextlib.AbstractAsyncContextManager\n",
      "     |      abc.ABC\n",
      "     |      typing.Generic\n",
      "     |      mode.services.ServiceCallbacks\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  FlowControlQueue(self, maxsize: int = None, *, clear_on_resume: bool = False, loop: asyncio.events.AbstractEventLoop = None) -> mode.utils.queues.ThrowableQueue\n",
      "     |      Like :class:`asyncio.Queue`, but can be suspended/resumed.\n",
      "     |  \n",
      "     |  GlobalTable(self, name: str, *, default: Callable[[], Any] = None, window: faust.types.windows.WindowT = None, partitions: int = None, help: str = None, **kwargs: Any) -> faust.types.tables.GlobalTableT\n",
      "     |      Define new global table.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          name: Name used for global table, note that two global tables\n",
      "     |              living in the same application cannot have the same name.\n",
      "     |      \n",
      "     |          default: A callable, or type that will return a default valu\n",
      "     |             for keys missing in this global table.\n",
      "     |          window: A windowing strategy to wrap this window in.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |          >>> gtable = app.GlobalTable('user_to_amount', default=int)\n",
      "     |          >>> gtable['George']\n",
      "     |          0\n",
      "     |          >>> gtable['Elaine'] += 1\n",
      "     |          >>> gtable['Elaine'] += 1\n",
      "     |          >>> gtable['Elaine']\n",
      "     |          2\n",
      "     |  \n",
      "     |  LiveCheck(self, **kwargs: Any) -> faust.app.base._LiveCheck\n",
      "     |      Return new LiveCheck instance testing features for this app.\n",
      "     |  \n",
      "     |  SetGlobalTable(self, name: str, *, window: faust.types.windows.WindowT = None, partitions: int = None, start_manager: bool = False, help: str = None, **kwargs: Any) -> faust.types.tables.TableT\n",
      "     |      Table of sets (global).\n",
      "     |  \n",
      "     |  SetTable(self, name: str, *, window: faust.types.windows.WindowT = None, partitions: int = None, start_manager: bool = False, help: str = None, **kwargs: Any) -> faust.types.tables.TableT\n",
      "     |      Table of sets.\n",
      "     |  \n",
      "     |  Table(self, name: str, *, default: Callable[[], Any] = None, window: faust.types.windows.WindowT = None, partitions: int = None, help: str = None, **kwargs: Any) -> faust.types.tables.TableT\n",
      "     |      Define new table.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          name: Name used for table, note that two tables living in\n",
      "     |              the same application cannot have the same name.\n",
      "     |      \n",
      "     |          default: A callable, or type that will return a default value\n",
      "     |             for keys missing in this table.\n",
      "     |          window: A windowing strategy to wrap this window in.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |          >>> table = app.Table('user_to_amount', default=int)\n",
      "     |          >>> table['George']\n",
      "     |          0\n",
      "     |          >>> table['Elaine'] += 1\n",
      "     |          >>> table['Elaine'] += 1\n",
      "     |          >>> table['Elaine']\n",
      "     |          2\n",
      "     |  \n",
      "     |  Worker(self, **kwargs: Any) -> faust.app.base._Worker\n",
      "     |      Return application worker instance.\n",
      "     |  \n",
      "     |  __init__(self, id: str, *, monitor: faust.sensors.monitor.Monitor = None, config_source: Any = None, loop: asyncio.events.AbstractEventLoop = None, beacon: mode.utils.types.trees.NodeT = None, **options: Any) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  actor = agent(self, channel: Union[str, faust.types.channels.ChannelT[~_T]] = None, *, name: str = None, concurrency: int = 1, supervisor_strategy: Type[mode.types.supervisors.SupervisorStrategyT] = None, sink: Iterable[Union[ForwardRef('AgentT'), faust.types.channels.ChannelT, Callable[[Any], Union[Awaitable, NoneType]]]] = None, isolated_partitions: bool = False, use_reply_headers: bool = True, **kwargs: Any) -> Callable[[Callable[[faust.types.streams.StreamT[~_T]], Union[Coroutine[Any, Any, NoneType], Awaitable[NoneType], AsyncIterable[+T_co]]]], faust.types.agents.AgentT[~_T]]\n",
      "     |  \n",
      "     |  agent(self, channel: Union[str, faust.types.channels.ChannelT[~_T]] = None, *, name: str = None, concurrency: int = 1, supervisor_strategy: Type[mode.types.supervisors.SupervisorStrategyT] = None, sink: Iterable[Union[ForwardRef('AgentT'), faust.types.channels.ChannelT, Callable[[Any], Union[Awaitable, NoneType]]]] = None, isolated_partitions: bool = False, use_reply_headers: bool = True, **kwargs: Any) -> Callable[[Callable[[faust.types.streams.StreamT[~_T]], Union[Coroutine[Any, Any, NoneType], Awaitable[NoneType], AsyncIterable[+T_co]]]], faust.types.agents.AgentT[~_T]]\n",
      "     |      Create Agent from async def function.\n",
      "     |      \n",
      "     |      It can be a regular async function::\n",
      "     |      \n",
      "     |          @app.agent()\n",
      "     |          async def my_agent(stream):\n",
      "     |              async for number in stream:\n",
      "     |                  print(f'Received: {number!r}')\n",
      "     |      \n",
      "     |      Or it can be an async iterator that yields values.\n",
      "     |      These values can be used as the reply in an RPC-style call,\n",
      "     |      or for sinks: callbacks that forward events to\n",
      "     |      other agents/topics/statsd, and so on::\n",
      "     |      \n",
      "     |          @app.agent(sink=[log_topic])\n",
      "     |          async def my_agent(requests):\n",
      "     |              async for number in requests:\n",
      "     |                  yield number * 2\n",
      "     |  \n",
      "     |  channel(self, *, schema: faust.types.serializers.SchemaT = None, key_type: Union[Type[faust.types.models.ModelT], Type[bytes], Type[str]] = None, value_type: Union[Type[faust.types.models.ModelT], Type[bytes], Type[str]] = None, maxsize: int = None, loop: asyncio.events.AbstractEventLoop = None) -> faust.types.channels.ChannelT\n",
      "     |      Create new channel.\n",
      "     |      \n",
      "     |      By default this will create an in-memory channel\n",
      "     |      used for intra-process communication, but in practice\n",
      "     |      channels can be backed by any transport (network or even means\n",
      "     |      of inter-process communication).\n",
      "     |      \n",
      "     |      See Also:\n",
      "     |          :class:`faust.channels.Channel`.\n",
      "     |  \n",
      "     |  command(self, *options: Any, base: Union[Type[faust.app.base._AppCommand], NoneType] = None, **kwargs: Any) -> Callable[[Callable], Type[faust.app.base._AppCommand]]\n",
      "     |      Decorate ``async def`` function to be used as CLI command.\n",
      "     |  \n",
      "     |  async commit(self, topics: AbstractSet[Union[str, faust.types.tuples.TP]]) -> bool\n",
      "     |      Commit offset for acked messages in specified topics'.\n",
      "     |      \n",
      "     |      Warning:\n",
      "     |          This will commit acked messages in **all topics**\n",
      "     |          if the topics argument is passed in as :const:`None`.\n",
      "     |  \n",
      "     |  config_from_object(self, obj: Any, *, silent: bool = False, force: bool = False) -> None\n",
      "     |      Read configuration from object.\n",
      "     |      \n",
      "     |      Object is either an actual object or the name of a module to import.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |          >>> app.config_from_object('myproj.faustconfig')\n",
      "     |      \n",
      "     |          >>> from myproj import faustconfig\n",
      "     |          >>> app.config_from_object(faustconfig)\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          silent (bool): If true then import errors will be ignored.\n",
      "     |          force (bool): Force reading configuration immediately.\n",
      "     |              By default the configuration will be read only when required.\n",
      "     |  \n",
      "     |  create_event(self, key: Union[bytes, faust.types.core._ModelT, Any, NoneType], value: Union[bytes, faust.types.core._ModelT, Any], headers: Union[List[Tuple[str, bytes]], Mapping[str, bytes], NoneType], message: faust.types.tuples.Message) -> faust.types.events.EventT\n",
      "     |      Create new :class:`faust.Event` object.\n",
      "     |  \n",
      "     |  crontab(self, cron_format: str, *, timezone: datetime.tzinfo = None, on_leader: bool = False, traced: bool = True) -> Callable\n",
      "     |      Define periodic task using Crontab description.\n",
      "     |      \n",
      "     |      This is an ``async def`` function to be run at the fixed times,\n",
      "     |      defined by the Cron format.\n",
      "     |      \n",
      "     |      Like :meth:`timer`, but executes at fixed times instead of executing\n",
      "     |      at certain intervals.\n",
      "     |      \n",
      "     |      This decorator takes an async function and adds it to a\n",
      "     |      list of Cronjobs started with the app.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          cron_format: The Cron spec defining fixed times to run the\n",
      "     |              decorated function.\n",
      "     |      \n",
      "     |      Keyword Arguments:\n",
      "     |          timezone: The timezone to be taken into account for the Cron jobs.\n",
      "     |              If not set value from :setting:`timezone` will be taken.\n",
      "     |      \n",
      "     |          on_leader: Should the Cron job only run on the leader?\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> @app.crontab(cron_format='30 18 * * *',\n",
      "     |                           timezone=pytz.timezone('US/Pacific'))\n",
      "     |          >>> async def every_6_30_pm_pacific():\n",
      "     |          ...     print('IT IS 6:30pm')\n",
      "     |      \n",
      "     |      \n",
      "     |          >>> app.crontab(cron_format='30 18 * * *', on_leader=True)\n",
      "     |          >>> async def every_6_30_pm():\n",
      "     |          ...     print('6:30pm UTC; ALSO, I AM THE LEADER!')\n",
      "     |  \n",
      "     |  discover(self, *extra_modules: str, categories: Iterable[str] = None, ignore: Iterable[Any] = [<built-in method search of re.Pattern object at 0x7fc52ac186c0>, '.__main__']) -> None\n",
      "     |      Discover decorators in packages.\n",
      "     |  \n",
      "     |  finalize(self) -> None\n",
      "     |      Finalize app configuration.\n",
      "     |  \n",
      "     |  is_leader(self) -> bool\n",
      "     |      Return :const:`True` if we are in leader worker process.\n",
      "     |  \n",
      "     |  main(self) -> NoReturn\n",
      "     |      Execute the :program:`faust` umbrella command using this app.\n",
      "     |  \n",
      "     |  async maybe_start_client(self) -> None\n",
      "     |      Start the app in Client-Only mode if not started as Server.\n",
      "     |  \n",
      "     |  maybe_start_producer(self) -> faust.types.transports.ProducerT\n",
      "     |      Ensure producer is started.\n",
      "     |  \n",
      "     |  async on_first_start(self) -> None\n",
      "     |      Call first time app starts in this process.\n",
      "     |  \n",
      "     |  on_init_dependencies(self) -> Iterable[mode.types.services.ServiceT]\n",
      "     |      Return list of additional service dependencies.\n",
      "     |      \n",
      "     |      The services returned will be started with the\n",
      "     |      app when the app starts.\n",
      "     |  \n",
      "     |  async on_init_extra_service(self, service: Union[mode.types.services.ServiceT, Type[mode.types.services.ServiceT]]) -> mode.types.services.ServiceT\n",
      "     |      Call when adding user services to this app.\n",
      "     |  \n",
      "     |  on_rebalance_end(self) -> None\n",
      "     |      Call when rebalancing is done.\n",
      "     |  \n",
      "     |  on_rebalance_return(self) -> None\n",
      "     |  \n",
      "     |  on_rebalance_start(self) -> None\n",
      "     |      Call when rebalancing starts.\n",
      "     |  \n",
      "     |  async on_start(self) -> None\n",
      "     |      Call every time app start/restarts.\n",
      "     |  \n",
      "     |  async on_started(self) -> None\n",
      "     |      Call when app is fully started.\n",
      "     |  \n",
      "     |  async on_started_init_extra_services(self) -> None\n",
      "     |      Call when initializing extra services at startup.\n",
      "     |  \n",
      "     |  async on_started_init_extra_tasks(self) -> None\n",
      "     |      Call when started to start additional tasks.\n",
      "     |  \n",
      "     |  async on_stop(self) -> None\n",
      "     |      Call when application stops.\n",
      "     |      \n",
      "     |      Tip:\n",
      "     |          Remember to call ``super`` if you override this method.\n",
      "     |  \n",
      "     |  on_webserver_init(self, web: faust.types.web.Web) -> None\n",
      "     |      Call when the Web server is initializing.\n",
      "     |  \n",
      "     |  page(self, path: str, *, base: Type[faust.web.views.View] = <class 'faust.web.views.View'>, cors_options: Mapping[str, faust.types.web.ResourceOptions] = None, name: str = None) -> Callable[[Union[Type[faust.types.web.View], Callable[[faust.types.web.View, faust.types.web.Request], Union[Coroutine[Any, Any, faust.types.web.Response], Awaitable[faust.types.web.Response]]], Callable[[faust.types.web.View, faust.types.web.Request, Any, Any], Union[Coroutine[Any, Any, faust.types.web.Response], Awaitable[faust.types.web.Response]]]]], Type[faust.web.views.View]]\n",
      "     |      Decorate view to be included in the web server.\n",
      "     |  \n",
      "     |  async send(self, channel: Union[faust.types.channels.ChannelT, str], key: Union[bytes, faust.types.core._ModelT, Any, NoneType] = None, value: Union[bytes, faust.types.core._ModelT, Any] = None, partition: int = None, timestamp: float = None, headers: Union[List[Tuple[str, bytes]], Mapping[str, bytes], NoneType] = None, schema: faust.types.serializers.SchemaT = None, key_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, value_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, callback: Callable[[faust.types.tuples.FutureMessage], Union[NoneType, Awaitable[NoneType]]] = None) -> Awaitable[faust.types.tuples.RecordMetadata]\n",
      "     |      Send event to channel/topic.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          channel: Channel/topic or the name of a topic to send event to.\n",
      "     |          key: Message key.\n",
      "     |          value: Message value.\n",
      "     |          partition: Specific partition to send to.\n",
      "     |              If not set the partition will be chosen by the partitioner.\n",
      "     |          timestamp: Epoch seconds (from Jan 1 1970\n",
      "     |              UTC) to use as the message timestamp. Defaults to current time.\n",
      "     |          headers: Mapping of key/value pairs, or iterable of key value\n",
      "     |              pairs to use as headers for the message.\n",
      "     |          schema: :class:`~faust.Schema` to use for serialization.\n",
      "     |          key_serializer: Serializer to use (if value is not model).\n",
      "     |              Overrides schema if one is specified.\n",
      "     |          value_serializer: Serializer to use (if value is not model).\n",
      "     |              Overrides schema if one is specified.\n",
      "     |          callback: Called after the message is fully delivered to the\n",
      "     |              channel, but not to the consumer.\n",
      "     |              Signature must be unary as the\n",
      "     |              :class:`~faust.types.tuples.FutureMessage` future is passed\n",
      "     |              to it.\n",
      "     |      \n",
      "     |              The resulting :class:`faust.types.tuples.RecordMetadata`\n",
      "     |              object is then available as ``fut.result()``.\n",
      "     |  \n",
      "     |  service(self, cls: Type[mode.types.services.ServiceT]) -> Type[mode.types.services.ServiceT]\n",
      "     |      Decorate :class:`mode.Service` to be started with the app.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |          .. sourcecode:: python\n",
      "     |      \n",
      "     |              from mode import Service\n",
      "     |      \n",
      "     |              @app.service\n",
      "     |              class Foo(Service):\n",
      "     |                  ...\n",
      "     |  \n",
      "     |  async start_client(self) -> None\n",
      "     |      Start the app in Client-Only mode necessary for RPC requests.\n",
      "     |      \n",
      "     |      Notes:\n",
      "     |          Once started as a client the app cannot be restarted as Server.\n",
      "     |  \n",
      "     |  stream(self, channel: Union[AsyncIterable, Iterable], beacon: mode.utils.types.trees.NodeT = None, **kwargs: Any) -> faust.types.streams.StreamT\n",
      "     |      Create new stream from channel/topic/iterable/async iterable.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          channel: Iterable to stream over (async or non-async).\n",
      "     |      \n",
      "     |          kwargs: See :class:`Stream`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          faust.Stream:\n",
      "     |              to iterate over events in the stream.\n",
      "     |  \n",
      "     |  table_route(self, table: faust.types.tables.CollectionT, shard_param: str = None, *, query_param: str = None, match_info: str = None, exact_key: str = None) -> Callable[[Union[Callable[[faust.types.web.View, faust.types.web.Request], Union[Coroutine[Any, Any, faust.types.web.Response], Awaitable[faust.types.web.Response]]], Callable[[faust.types.web.View, faust.types.web.Request, Any, Any], Union[Coroutine[Any, Any, faust.types.web.Response], Awaitable[faust.types.web.Response]]]]], Union[Callable[[faust.types.web.View, faust.types.web.Request], Union[Coroutine[Any, Any, faust.types.web.Response], Awaitable[faust.types.web.Response]]], Callable[[faust.types.web.View, faust.types.web.Request, Any, Any], Union[Coroutine[Any, Any, faust.types.web.Response], Awaitable[faust.types.web.Response]]]]]\n",
      "     |      Decorate view method to route request to table key destination.\n",
      "     |  \n",
      "     |  task(self, fun: Union[Callable[[ForwardRef('AppT')], Awaitable], Callable[[], Awaitable]] = None, *, on_leader: bool = False, traced: bool = True) -> Union[Callable[[Union[Callable[[ForwardRef('AppT')], Awaitable], Callable[[], Awaitable]]], Union[Callable[[ForwardRef('AppT')], Awaitable], Callable[[], Awaitable]]], Callable[[ForwardRef('AppT')], Awaitable], Callable[[], Awaitable]]\n",
      "     |      Define an async def function to be started with the app.\n",
      "     |      \n",
      "     |      This is like :meth:`timer` but a one-shot task only\n",
      "     |      executed at worker startup (after recovery and the worker is\n",
      "     |      fully ready for operation).\n",
      "     |      \n",
      "     |      The function may take zero, or one argument.\n",
      "     |      If the target function takes an argument, the ``app`` argument\n",
      "     |      is passed::\n",
      "     |      \n",
      "     |          >>> @app.task\n",
      "     |          >>> async def on_startup(app):\n",
      "     |          ...    print('STARTING UP: %r' % (app,))\n",
      "     |      \n",
      "     |      Nullary functions are also supported::\n",
      "     |      \n",
      "     |          >>> @app.task\n",
      "     |          >>> async def on_startup():\n",
      "     |          ...     print('STARTING UP')\n",
      "     |  \n",
      "     |  timer(self, interval: Union[datetime.timedelta, float, str], on_leader: bool = False, traced: bool = True, name: str = None, max_drift_correction: float = 0.1) -> Callable\n",
      "     |      Define an async def function to be run at periodic intervals.\n",
      "     |      \n",
      "     |      Like :meth:`task`, but executes periodically until the worker\n",
      "     |      is shut down.\n",
      "     |      \n",
      "     |      This decorator takes an async function and adds it to a\n",
      "     |      list of timers started with the app.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          interval (Seconds): How often the timer executes in seconds.\n",
      "     |      \n",
      "     |          on_leader (bool) = False: Should the timer only run on the leader?\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> @app.timer(interval=10.0)\n",
      "     |          >>> async def every_10_seconds():\n",
      "     |          ...     print('TEN SECONDS JUST PASSED')\n",
      "     |      \n",
      "     |      \n",
      "     |          >>> app.timer(interval=5.0, on_leader=True)\n",
      "     |          >>> async def every_5_seconds():\n",
      "     |          ...     print('FIVE SECONDS JUST PASSED. ALSO, I AM THE LEADER!')\n",
      "     |  \n",
      "     |  topic(self, *topics: str, pattern: Union[str, Pattern] = None, schema: faust.types.serializers.SchemaT = None, key_type: Union[Type[faust.types.models.ModelT], Type[bytes], Type[str]] = None, value_type: Union[Type[faust.types.models.ModelT], Type[bytes], Type[str]] = None, key_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, value_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, partitions: int = None, retention: Union[datetime.timedelta, float, str] = None, compacting: bool = None, deleting: bool = None, replicas: int = None, acks: bool = True, internal: bool = False, config: Mapping[str, Any] = None, maxsize: int = None, allow_empty: bool = False, has_prefix: bool = False, loop: asyncio.events.AbstractEventLoop = None) -> faust.types.topics.TopicT\n",
      "     |      Create topic description.\n",
      "     |      \n",
      "     |      Topics are named channels (for example a Kafka topic),\n",
      "     |      that exist on a server.  To make an ephemeral local communication\n",
      "     |      channel use: :meth:`channel`.\n",
      "     |      \n",
      "     |      See Also:\n",
      "     |          :class:`faust.topics.Topic`\n",
      "     |  \n",
      "     |  trace(self, name: str, trace_enabled: bool = True, **extra_context: Any) -> AbstractContextManager\n",
      "     |      Return new trace context to trace operation using OpenTracing.\n",
      "     |  \n",
      "     |  traced(self, fun: Callable, name: str = None, sample_rate: float = 1.0, **context: Any) -> Callable\n",
      "     |      Decorate function to be traced using the OpenTracing API.\n",
      "     |  \n",
      "     |  worker_init(self) -> None\n",
      "     |      Init worker/CLI commands.\n",
      "     |  \n",
      "     |  worker_init_post_autodiscover(self) -> None\n",
      "     |      Init worker after autodiscover.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  label\n",
      "     |      Return human readable description of application.\n",
      "     |  \n",
      "     |  shortlabel\n",
      "     |      Return short description of application.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  assignor\n",
      "     |      Partition Assignor.\n",
      "     |      \n",
      "     |      Responsible for partition assignment.\n",
      "     |  \n",
      "     |  cache\n",
      "     |      Cache backend.\n",
      "     |  \n",
      "     |  conf\n",
      "     |      Application configuration.\n",
      "     |  \n",
      "     |  consumer\n",
      "     |      Message consumer.\n",
      "     |  \n",
      "     |  flow_control\n",
      "     |      Flow control of streams.\n",
      "     |      \n",
      "     |      This object controls flow into stream queues,\n",
      "     |      and can also clear all buffers.\n",
      "     |  \n",
      "     |  http_client\n",
      "     |      HTTP client Session.\n",
      "     |  \n",
      "     |  in_transaction\n",
      "     |      Return :const:`True` if stream is using transactions.\n",
      "     |  \n",
      "     |  monitor\n",
      "     |      Monitor keeps stats about what's going on inside the worker.\n",
      "     |  \n",
      "     |  producer\n",
      "     |      Message producer.\n",
      "     |  \n",
      "     |  producer_transport\n",
      "     |      Producer message transport.\n",
      "     |  \n",
      "     |  router\n",
      "     |      Find the node partitioned data belongs to.\n",
      "     |      \n",
      "     |      The router helps us route web requests to the wanted Faust node.\n",
      "     |      If a topic is sharded by account_id, the router can send us to the\n",
      "     |      Faust worker responsible for any account.  Used by the\n",
      "     |      ``@app.table_route`` decorator.\n",
      "     |  \n",
      "     |  serializers\n",
      "     |      Return serializer registry.\n",
      "     |  \n",
      "     |  tables\n",
      "     |      Map of available tables, and the table manager service.\n",
      "     |  \n",
      "     |  topics\n",
      "     |      Topic Conductor.\n",
      "     |      \n",
      "     |      This is the mediator that moves messages fetched by the Consumer\n",
      "     |      into the streams.\n",
      "     |      \n",
      "     |      It's also a set of registered topics by string topic name, so you\n",
      "     |      can check if a topic is being consumed from by doing\n",
      "     |      ``topic in app.topics``.\n",
      "     |  \n",
      "     |  transport\n",
      "     |      Consumer message transport.\n",
      "     |  \n",
      "     |  web\n",
      "     |      Web driver.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  BootStrategy = <class 'faust.app.base.BootStrategy'>\n",
      "     |      App startup strategy.\n",
      "     |      \n",
      "     |      The startup strategy defines the graph of services\n",
      "     |      to start when the Faust worker for an app starts.\n",
      "     |  \n",
      "     |  SCAN_CATEGORIES = ['faust.agent', 'faust.command', 'faust.page', 'faus...\n",
      "     |  \n",
      "     |  Settings = <class 'faust.types.settings.Settings'>\n",
      "     |      Helper class that provides a standard way to create an ABC using\n",
      "     |      inheritance.\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'SCAN_CATEGORIES': typing.ClassVar[typing.List[str]...\n",
      "     |  \n",
      "     |  client_only = False\n",
      "     |  \n",
      "     |  logger = <Logger faust.app.base (INFO)>\n",
      "     |  \n",
      "     |  producer_only = False\n",
      "     |  \n",
      "     |  tracer = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from faust.types.app.AppT:\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  configured = False\n",
      "     |  \n",
      "     |  finalized = False\n",
      "     |  \n",
      "     |  in_worker = False\n",
      "     |  \n",
      "     |  on_after_configured = <SyncSignal: AppT.on_after_configured>\n",
      "     |      Signal that is synchronous (using regular ``def`` functions).\n",
      "     |  \n",
      "     |  on_before_configured = <SyncSignal: AppT.on_before_configured>\n",
      "     |      Signal that is synchronous (using regular ``def`` functions).\n",
      "     |  \n",
      "     |  on_before_shutdown = <Signal: AppT.on_before_shutdown>\n",
      "     |      Asynchronous signal (using ``async def`` functions).\n",
      "     |  \n",
      "     |  on_configured = <SyncSignal: AppT.on_configured>\n",
      "     |      Signal that is synchronous (using regular ``def`` functions).\n",
      "     |  \n",
      "     |  on_partitions_assigned = <Signal: AppT.on_partitions_assigned>\n",
      "     |      Asynchronous signal (using ``async def`` functions).\n",
      "     |  \n",
      "     |  on_partitions_revoked = <Signal: AppT.on_partitions_revoked>\n",
      "     |      Asynchronous signal (using ``async def`` functions).\n",
      "     |  \n",
      "     |  on_produce_message = <SyncSignal: AppT.on_produce_message>\n",
      "     |      Signal that is synchronous (using regular ``def`` functions).\n",
      "     |  \n",
      "     |  on_rebalance_complete = <Signal: AppT.on_rebalance_complete>\n",
      "     |      Asynchronous signal (using ``async def`` functions).\n",
      "     |  \n",
      "     |  on_worker_init = <SyncSignal: AppT.on_worker_init>\n",
      "     |      Signal that is synchronous (using regular ``def`` functions).\n",
      "     |  \n",
      "     |  rebalancing = False\n",
      "     |  \n",
      "     |  rebalancing_count = 0\n",
      "     |  \n",
      "     |  unassigned = False\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  __post_init__(self) -> None\n",
      "     |      Additional user initialization.\n",
      "     |  \n",
      "     |  async add_async_context(self, context: AbstractAsyncContextManager) -> Any\n",
      "     |  \n",
      "     |  add_context(self, context: AbstractContextManager) -> Any\n",
      "     |  \n",
      "     |  add_dependency(self, service: mode.types.services.ServiceT) -> mode.types.services.ServiceT\n",
      "     |      Add dependency to other service.\n",
      "     |      \n",
      "     |      The service will be started/stopped with this service.\n",
      "     |  \n",
      "     |  add_future(self, coro: Awaitable) -> _asyncio.Future\n",
      "     |      Add relationship to asyncio.Future.\n",
      "     |      \n",
      "     |      The future will be joined when this service is stopped.\n",
      "     |  \n",
      "     |  async add_runtime_dependency(self, service: mode.types.services.ServiceT) -> mode.types.services.ServiceT\n",
      "     |  \n",
      "     |  async crash(self, reason: BaseException) -> None\n",
      "     |      Crash the service and all child services.\n",
      "     |  \n",
      "     |  async itertimer(self, interval: Union[datetime.timedelta, float, str], *, max_drift_correction: float = 0.1, loop: asyncio.events.AbstractEventLoop = None, sleep: Callable[..., Awaitable] = None, clock: Callable[[], float] = <built-in function perf_counter>, name: str = '') -> AsyncIterator[float]\n",
      "     |      Sleep ``interval`` seconds for every iteration.\n",
      "     |      \n",
      "     |      This is an async iterator that takes advantage\n",
      "     |      of :func:`~mode.timers.Timer` to monitor drift and timer\n",
      "     |      oerlap.\n",
      "     |      \n",
      "     |      Uses ``Service.sleep`` so exits fast when the service is\n",
      "     |      stopped.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          Will sleep the full `interval` seconds before returning\n",
      "     |          from first iteration.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |          >>> async for sleep_time in self.itertimer(1.0):\n",
      "     |          ...   print('another second passed, just woke up...')\n",
      "     |          ...   await perform_some_http_request()\n",
      "     |  \n",
      "     |  async join_services(self, services: Sequence[mode.types.services.ServiceT]) -> None\n",
      "     |  \n",
      "     |  async maybe_start(self) -> bool\n",
      "     |      Start the service, if it has not already been started.\n",
      "     |  \n",
      "     |  on_init(self) -> None\n",
      "     |  \n",
      "     |  async remove_dependency(self, service: mode.types.services.ServiceT) -> mode.types.services.ServiceT\n",
      "     |      Stop and remove dependency of this service.\n",
      "     |  \n",
      "     |  async restart(self) -> None\n",
      "     |      Restart this service.\n",
      "     |  \n",
      "     |  service_reset(self) -> None\n",
      "     |  \n",
      "     |  set_shutdown(self) -> None\n",
      "     |      Set the shutdown signal.\n",
      "     |      \n",
      "     |      Notes:\n",
      "     |          If :attr:`wait_for_shutdown` is set, stopping the service\n",
      "     |          will wait for this flag to be set.\n",
      "     |  \n",
      "     |  async sleep(self, n: Union[datetime.timedelta, float, str], *, loop: asyncio.events.AbstractEventLoop = None) -> None\n",
      "     |      Sleep for ``n`` seconds, or until service stopped.\n",
      "     |  \n",
      "     |  async start(self) -> None\n",
      "     |  \n",
      "     |  async stop(self) -> None\n",
      "     |      Stop the service.\n",
      "     |  \n",
      "     |  async transition_with(self, flag: str, fut: Awaitable, *args: Any, **kwargs: Any) -> Any\n",
      "     |  \n",
      "     |  async wait(self, *coros: Union[_asyncio.Future, Generator[Any, NoneType, Any], Awaitable, asyncio.locks.Event, mode.utils.locks.Event], timeout: Union[datetime.timedelta, float, str] = None) -> mode.services.WaitResult\n",
      "     |      Wait for coroutines to complete, or until the service stops.\n",
      "     |  \n",
      "     |  async wait_first(self, *coros: Union[_asyncio.Future, Generator[Any, NoneType, Any], Awaitable, asyncio.locks.Event, mode.utils.locks.Event], timeout: Union[datetime.timedelta, float, str] = None) -> mode.services.WaitResults\n",
      "     |  \n",
      "     |  async wait_for_stopped(self, *coros: Union[_asyncio.Future, Generator[Any, NoneType, Any], Awaitable, asyncio.locks.Event, mode.utils.locks.Event], timeout: Union[datetime.timedelta, float, str] = None) -> bool\n",
      "     |  \n",
      "     |  async wait_many(self, coros: Iterable[Union[_asyncio.Future, Generator[Any, NoneType, Any], Awaitable, asyncio.locks.Event, mode.utils.locks.Event]], *, timeout: Union[datetime.timedelta, float, str] = None) -> mode.services.WaitResult\n",
      "     |  \n",
      "     |  async wait_until_stopped(self) -> None\n",
      "     |      Wait until the service is signalled to stop.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  __init_subclass__() -> None from abc.ABCMeta\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  from_awaitable(coro: Awaitable, *, name: str = None, **kwargs: Any) -> mode.types.services.ServiceT from abc.ABCMeta\n",
      "     |  \n",
      "     |  transitions_to(flag: str) -> Callable from abc.ABCMeta\n",
      "     |      Decorate function to set and reset diagnostic flag.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  crashed\n",
      "     |  \n",
      "     |  should_stop\n",
      "     |      Return :const:`True` if the service must stop.\n",
      "     |  \n",
      "     |  started\n",
      "     |      Return :const:`True` if the service was started.\n",
      "     |  \n",
      "     |  state\n",
      "     |      Service state - as a human readable string.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  beacon\n",
      "     |      Beacon used to track services in a dependency graph.\n",
      "     |  \n",
      "     |  crash_reason\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  Diag = <class 'mode.services.Diag'>\n",
      "     |      Service diagnostics.\n",
      "     |      \n",
      "     |      This can be used to track what your service is doing.\n",
      "     |      For example if your service is a Kafka consumer with a background\n",
      "     |      thread that commits the offset every 30 seconds, you may want to\n",
      "     |      see when this happens::\n",
      "     |      \n",
      "     |          DIAG_COMMITTING = 'committing'\n",
      "     |      \n",
      "     |          class Consumer(Service):\n",
      "     |      \n",
      "     |              @Service.task\n",
      "     |              async def _background_commit(self) -> None:\n",
      "     |                  while not self.should_stop:\n",
      "     |                      await self.sleep(30.0)\n",
      "     |                      self.diag.set_flag(DIAG_COMITTING)\n",
      "     |                      try:\n",
      "     |                          await self._consumer.commit()\n",
      "     |                      finally:\n",
      "     |                          self.diag.unset_flag(DIAG_COMMITTING)\n",
      "     |      \n",
      "     |      The above code is setting the flag manually, but you can also use\n",
      "     |      a decorator to accomplish the same thing::\n",
      "     |      \n",
      "     |          @Service.timer(30.0)\n",
      "     |          async def _background_commit(self) -> None:\n",
      "     |              await self.commit()\n",
      "     |      \n",
      "     |          @Service.transitions_with(DIAG_COMITTING)\n",
      "     |          async def commit(self) -> None:\n",
      "     |              await self._consumer.commit()\n",
      "     |  \n",
      "     |  abstract = False\n",
      "     |  \n",
      "     |  mundane_level = 'info'\n",
      "     |  \n",
      "     |  restart_count = 0\n",
      "     |  \n",
      "     |  shutdown_timeout = 60.0\n",
      "     |  \n",
      "     |  wait_for_shutdown = False\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mode.services.ServiceBase:\n",
      "     |  \n",
      "     |  async __aenter__(self) -> mode.types.services.ServiceT\n",
      "     |      Return `self` upon entering the runtime context.\n",
      "     |  \n",
      "     |  async __aexit__(self, exc_type: Type[BaseException] = None, exc_val: BaseException = None, exc_tb: traceback = None) -> Union[bool, NoneType]\n",
      "     |      Raise any exception triggered within the runtime context.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from mode.services.ServiceBase:\n",
      "     |  \n",
      "     |  loop\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from mode.types.services.ServiceT:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.AbstractAsyncContextManager,)\n",
      "     |  \n",
      "     |  supervisor = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from contextlib.AbstractAsyncContextManager:\n",
      "     |  \n",
      "     |  __subclasshook__(C) from abc.ABCMeta\n",
      "     |      Abstract classes can override this to customize issubclass().\n",
      "     |      \n",
      "     |      This is invoked early on by abc.ABCMeta.__subclasscheck__().\n",
      "     |      It should return True, False or NotImplemented.  If it returns\n",
      "     |      NotImplemented, the normal algorithm is used.  Otherwise, it\n",
      "     |      overrides the normal algorithm (and the outcome is cached).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from contextlib.AbstractAsyncContextManager:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from abc.ABCMeta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mode.services.ServiceCallbacks:\n",
      "     |  \n",
      "     |  async on_restart(self) -> None\n",
      "     |      Service is being restarted.\n",
      "     |  \n",
      "     |  async on_shutdown(self) -> None\n",
      "     |      Service is being stopped/restarted.\n",
      "    \n",
      "    class Channel(faust.types.channels.ChannelT)\n",
      "     |  Channel(*args, **kwds)\n",
      "     |  \n",
      "     |  Create new channel.\n",
      "     |  \n",
      "     |  Arguments:\n",
      "     |      app: The app that created this channel (``app.channel()``)\n",
      "     |  \n",
      "     |      schema: Schema used for serialization/deserialization\n",
      "     |      key_type:  The Model used for keys in this channel.\n",
      "     |         (overrides schema if one is defined)\n",
      "     |      value_type: The Model used for values in this channel.\n",
      "     |         (overrides schema if one is defined)\n",
      "     |      maxsize: The maximum number of messages this channel can hold.\n",
      "     |               If exceeded any new ``put`` call will block until a message\n",
      "     |               is removed from the channel.\n",
      "     |      is_iterator: When streams iterate over a channel they will call\n",
      "     |          ``stream.clone(is_iterator=True)`` so this attribute\n",
      "     |          denotes that this channel instance is currently being iterated\n",
      "     |          over.\n",
      "     |      active_partitions: Set of active topic partitions this\n",
      "     |         channel instance is assigned to.\n",
      "     |      loop: The :mod:`asyncio` event loop to use.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Channel\n",
      "     |      faust.types.channels.ChannelT\n",
      "     |      collections.abc.AsyncIterator\n",
      "     |      collections.abc.AsyncIterable\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __aiter__(self) -> faust.types.channels.ChannelT[~T]\n",
      "     |  \n",
      "     |  async __anext__(self) -> faust.types.events.EventT[~T]\n",
      "     |      Return the next item or raise StopAsyncIteration when exhausted.\n",
      "     |  \n",
      "     |  __init__(self, app: faust.types.app.AppT, *, schema: faust.types.serializers.SchemaT = None, key_type: Union[Type[faust.types.models.ModelT], Type[bytes], Type[str]] = None, value_type: Union[Type[faust.types.models.ModelT], Type[bytes], Type[str]] = None, is_iterator: bool = False, queue: mode.utils.queues.ThrowableQueue = None, maxsize: int = None, root: faust.types.channels.ChannelT = None, active_partitions: Set[faust.types.tuples.TP] = None, loop: asyncio.events.AbstractEventLoop = None) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self) -> str\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  as_future_message(self, key: Union[bytes, faust.types.core._ModelT, Any, NoneType] = None, value: Union[bytes, faust.types.core._ModelT, Any] = None, partition: int = None, timestamp: float = None, headers: Union[List[Tuple[str, bytes]], Mapping[str, bytes], NoneType] = None, schema: faust.types.serializers.SchemaT = None, key_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, value_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, callback: Callable[[faust.types.tuples.FutureMessage], Union[NoneType, Awaitable[NoneType]]] = None, eager_partitioning: bool = False) -> faust.types.tuples.FutureMessage\n",
      "     |      Create promise that message will be transmitted.\n",
      "     |  \n",
      "     |  clone(self, *, is_iterator: bool = None, **kwargs: Any) -> faust.types.channels.ChannelT[~T]\n",
      "     |      Create clone of this channel.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          is_iterator: Set to True if this is now a channel\n",
      "     |              that is being iterated over.\n",
      "     |      \n",
      "     |      Keyword Arguments:\n",
      "     |          **kwargs: Any keyword arguments passed will override any\n",
      "     |              of the arguments supported by\n",
      "     |              :class:`Channel.__init__ <Channel>`.\n",
      "     |  \n",
      "     |  clone_using_queue(self, queue: asyncio.queues.Queue) -> faust.types.channels.ChannelT[~T]\n",
      "     |      Create clone of this channel using specific queue instance.\n",
      "     |  \n",
      "     |  async declare(self) -> None\n",
      "     |      Declare/create this channel.\n",
      "     |      \n",
      "     |      This is used to create this channel on a server,\n",
      "     |      if that is required to operate it.\n",
      "     |  \n",
      "     |  async decode(self, message: faust.types.tuples.Message, *, propagate: bool = False) -> faust.types.events.EventT[~T]\n",
      "     |      Decode :class:`~faust.types.Message` into :class:`~faust.Event`.\n",
      "     |  \n",
      "     |  async deliver(self, message: faust.types.tuples.Message) -> None\n",
      "     |      Deliver message to queue from consumer.\n",
      "     |      \n",
      "     |      This is called by the consumer to deliver the message\n",
      "     |      to the channel.\n",
      "     |  \n",
      "     |  derive(self, **kwargs: Any) -> faust.types.channels.ChannelT[~T]\n",
      "     |      Derive new channel from this channel, using new configuration.\n",
      "     |      \n",
      "     |      See :class:`faust.Topic.derive`.\n",
      "     |      \n",
      "     |      For local channels this will simply return the same channel.\n",
      "     |  \n",
      "     |  empty(self) -> bool\n",
      "     |      Return :const:`True` if the queue is empty.\n",
      "     |  \n",
      "     |  async get(self, *, timeout: Union[datetime.timedelta, float, str] = None) -> faust.types.events.EventT[~T]\n",
      "     |      Get the next :class:`~faust.Event` received on this channel.\n",
      "     |  \n",
      "     |  get_topic_name(self) -> str\n",
      "     |      Get the topic name, or raise if this is not a named channel.\n",
      "     |  \n",
      "     |  maybe_declare(self) -> None\n",
      "     |      Declare/create this channel, but only if it doesn't exist.\n",
      "     |  \n",
      "     |  async on_decode_error(self, exc: Exception, message: faust.types.tuples.Message) -> None\n",
      "     |      Signal that there was an error reading an event in the queue.\n",
      "     |      \n",
      "     |      When a message in the channel needs deserialization\n",
      "     |      to be reconstructed back to its original form, we will sometimes\n",
      "     |      see decoding/deserialization errors being raised, from missing\n",
      "     |      fields or malformed payloads, and so on.\n",
      "     |      \n",
      "     |      We will log the exception, but you can also override this\n",
      "     |      to perform additional actions.\n",
      "     |      \n",
      "     |      Admonition: Kafka\n",
      "     |          In the event a deserialization error occurs, we\n",
      "     |          HAVE to commit the offset of the source message to continue\n",
      "     |          processing the stream.\n",
      "     |      \n",
      "     |          For this reason it is important that you keep a close eye on\n",
      "     |          error logs. For easy of use, we suggest using log aggregation\n",
      "     |          software, such as Sentry, to surface these errors to your\n",
      "     |          operations team.\n",
      "     |  \n",
      "     |  async on_key_decode_error(self, exc: Exception, message: faust.types.tuples.Message) -> None\n",
      "     |      Unable to decode the key of an item in the queue.\n",
      "     |      \n",
      "     |      See Also:\n",
      "     |          :meth:`on_decode_error`\n",
      "     |  \n",
      "     |  on_stop_iteration(self) -> None\n",
      "     |      Signal that iteration over this channel was stopped.\n",
      "     |      \n",
      "     |      Tip:\n",
      "     |          Remember to call ``super`` when overriding this method.\n",
      "     |  \n",
      "     |  async on_value_decode_error(self, exc: Exception, message: faust.types.tuples.Message) -> None\n",
      "     |      Unable to decode the value of an item in the queue.\n",
      "     |      \n",
      "     |      See Also:\n",
      "     |          :meth:`on_decode_error`\n",
      "     |  \n",
      "     |  prepare_headers(self, headers: Union[List[Tuple[str, bytes]], Mapping[str, bytes], NoneType]) -> Union[List[Tuple[str, bytes]], MutableMapping[str, bytes], NoneType]\n",
      "     |      Prepare ``headers`` passed before publishing.\n",
      "     |  \n",
      "     |  prepare_key(self, key: Union[bytes, faust.types.core._ModelT, Any, NoneType], key_serializer: Union[faust.types.codecs.CodecT, str, NoneType], schema: faust.types.serializers.SchemaT = None, headers: Union[List[Tuple[str, bytes]], MutableMapping[str, bytes], NoneType] = None) -> Tuple[Any, Union[List[Tuple[str, bytes]], MutableMapping[str, bytes], NoneType]]\n",
      "     |      Prepare key before it is sent to this channel.\n",
      "     |      \n",
      "     |      :class:`~faust.Topic` uses this to implement serialization of keys\n",
      "     |      sent to the channel.\n",
      "     |  \n",
      "     |  prepare_value(self, value: Union[bytes, faust.types.core._ModelT, Any], value_serializer: Union[faust.types.codecs.CodecT, str, NoneType], schema: faust.types.serializers.SchemaT = None, headers: Union[List[Tuple[str, bytes]], MutableMapping[str, bytes], NoneType] = None) -> Tuple[Any, Union[List[Tuple[str, bytes]], MutableMapping[str, bytes], NoneType]]\n",
      "     |      Prepare value before it is sent to this channel.\n",
      "     |      \n",
      "     |      :class:`~faust.Topic` uses this to implement serialization of values\n",
      "     |      sent to the channel.\n",
      "     |  \n",
      "     |  async publish_message(self, fut: faust.types.tuples.FutureMessage, wait: bool = True) -> Awaitable[faust.types.tuples.RecordMetadata]\n",
      "     |      Publish message to channel.\n",
      "     |      \n",
      "     |      This is the interface used by ``topic.send()``, etc.\n",
      "     |      to actually publish the message on the channel\n",
      "     |      after being buffered up or similar.\n",
      "     |      \n",
      "     |      It takes a :class:`~faust.types.FutureMessage` object,\n",
      "     |      which contains all the information required to send\n",
      "     |      the message, and acts as a promise that is resolved\n",
      "     |      once the message has been fully transmitted.\n",
      "     |  \n",
      "     |  async put(self, value: faust.types.events.EventT[-T_contra]) -> None\n",
      "     |      Put event onto this channel.\n",
      "     |  \n",
      "     |  async send(self, *, key: Union[bytes, faust.types.core._ModelT, Any, NoneType] = None, value: Union[bytes, faust.types.core._ModelT, Any] = None, partition: int = None, timestamp: float = None, headers: Union[List[Tuple[str, bytes]], Mapping[str, bytes], NoneType] = None, schema: faust.types.serializers.SchemaT = None, key_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, value_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, callback: Callable[[faust.types.tuples.FutureMessage], Union[NoneType, Awaitable[NoneType]]] = None, force: bool = False) -> Awaitable[faust.types.tuples.RecordMetadata]\n",
      "     |      Send message to channel.\n",
      "     |  \n",
      "     |  send_soon(self, *, key: Union[bytes, faust.types.core._ModelT, Any, NoneType] = None, value: Union[bytes, faust.types.core._ModelT, Any] = None, partition: int = None, timestamp: float = None, headers: Union[List[Tuple[str, bytes]], Mapping[str, bytes], NoneType] = None, schema: faust.types.serializers.SchemaT = None, key_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, value_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, callback: Callable[[faust.types.tuples.FutureMessage], Union[NoneType, Awaitable[NoneType]]] = None, force: bool = False, eager_partitioning: bool = False) -> faust.types.tuples.FutureMessage\n",
      "     |      Produce message by adding to buffer.\n",
      "     |      \n",
      "     |      This method is only supported by :class:`~faust.Topic`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          NotImplementedError: always for in-memory channel.\n",
      "     |  \n",
      "     |  stream(self, **kwargs: Any) -> faust.types.streams.StreamT[~T]\n",
      "     |      Create stream reading from this channel.\n",
      "     |  \n",
      "     |  async throw(self, exc: BaseException) -> None\n",
      "     |      Throw exception to be received by channel subscribers.\n",
      "     |      \n",
      "     |      Tip:\n",
      "     |          When you find yourself having to call this from\n",
      "     |          a regular, non-``async def`` function, you can use :meth:`_throw`\n",
      "     |          instead.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  label\n",
      "     |      Short textual description of channel.\n",
      "     |  \n",
      "     |  queue\n",
      "     |      Return the underlying queue/buffer backing this channel.\n",
      "     |  \n",
      "     |  subscriber_count\n",
      "     |      Return number of active subscribers to local channel.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'_queue': typing.Union[mode.utils.queues.ThrowableQ...\n",
      "     |  \n",
      "     |  __orig_bases__ = (faust.types.channels.ChannelT[~T],)\n",
      "     |  \n",
      "     |  __parameters__ = (~T,)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from faust.types.channels.ChannelT:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from collections.abc.AsyncIterator:\n",
      "     |  \n",
      "     |  __subclasshook__(C) from abc.ABCMeta\n",
      "     |      Abstract classes can override this to customize issubclass().\n",
      "     |      \n",
      "     |      This is invoked early on by abc.ABCMeta.__subclasscheck__().\n",
      "     |      It should return True, False or NotImplemented.  If it returns\n",
      "     |      NotImplemented, the normal algorithm is used.  Otherwise, it\n",
      "     |      overrides the normal algorithm (and the outcome is cached).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from abc.ABCMeta\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from abc.ABCMeta\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class ChannelT(collections.abc.AsyncIterator, typing.Generic)\n",
      "     |  ChannelT(*args, **kwds)\n",
      "     |  \n",
      "     |  Abstract base class for generic types.\n",
      "     |  \n",
      "     |  A generic type is typically declared by inheriting from\n",
      "     |  this class parameterized with one or more type variables.\n",
      "     |  For example, a generic mapping type might be defined as::\n",
      "     |  \n",
      "     |    class Mapping(Generic[KT, VT]):\n",
      "     |        def __getitem__(self, key: KT) -> VT:\n",
      "     |            ...\n",
      "     |        # Etc.\n",
      "     |  \n",
      "     |  This class can then be used as follows::\n",
      "     |  \n",
      "     |    def lookup_name(mapping: Mapping[KT, VT], key: KT, default: VT) -> VT:\n",
      "     |        try:\n",
      "     |            return mapping[key]\n",
      "     |        except KeyError:\n",
      "     |            return default\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ChannelT\n",
      "     |      collections.abc.AsyncIterator\n",
      "     |      collections.abc.AsyncIterable\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __aiter__(self) -> 'ChannelT'\n",
      "     |  \n",
      "     |  __anext__(self) -> Awaitable[faust.types.channels._EventT[~_T]]\n",
      "     |      Return the next item or raise StopAsyncIteration when exhausted.\n",
      "     |  \n",
      "     |  __init__(self, app: faust.types.channels._AppT, *, schema: faust.types.channels._SchemaT = None, key_type: faust.types.channels._ModelArg = None, value_type: faust.types.channels._ModelArg = None, is_iterator: bool = False, queue: mode.utils.queues.ThrowableQueue = None, maxsize: int = None, root: 'ChannelT' = None, active_partitions: Set[faust.types.tuples.TP] = None, loop: asyncio.events.AbstractEventLoop = None) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  as_future_message(self, key: Union[bytes, faust.types.core._ModelT, Any, NoneType] = None, value: Union[bytes, faust.types.core._ModelT, Any] = None, partition: int = None, timestamp: float = None, headers: Union[List[Tuple[str, bytes]], Mapping[str, bytes], NoneType] = None, schema: faust.types.channels._SchemaT = None, key_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, value_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, callback: Callable[[faust.types.tuples.FutureMessage], Union[NoneType, Awaitable[NoneType]]] = None, eager_partitioning: bool = False) -> faust.types.tuples.FutureMessage\n",
      "     |  \n",
      "     |  clone(self, *, is_iterator: bool = None, **kwargs: Any) -> 'ChannelT[_T]'\n",
      "     |  \n",
      "     |  clone_using_queue(self, queue: asyncio.queues.Queue) -> 'ChannelT[_T]'\n",
      "     |  \n",
      "     |  async declare(self) -> None\n",
      "     |  \n",
      "     |  async decode(self, message: faust.types.tuples.Message, *, propagate: bool = False) -> faust.types.channels._EventT[~_T]\n",
      "     |  \n",
      "     |  async deliver(self, message: faust.types.tuples.Message) -> None\n",
      "     |  \n",
      "     |  derive(self, **kwargs: Any) -> 'ChannelT'\n",
      "     |  \n",
      "     |  empty(self) -> bool\n",
      "     |  \n",
      "     |  async get(self, *, timeout: Union[datetime.timedelta, float, str] = None) -> faust.types.channels._EventT[~_T]\n",
      "     |  \n",
      "     |  get_topic_name(self) -> str\n",
      "     |  \n",
      "     |  maybe_declare(self) -> None\n",
      "     |  \n",
      "     |  async on_decode_error(self, exc: Exception, message: faust.types.tuples.Message) -> None\n",
      "     |  \n",
      "     |  async on_key_decode_error(self, exc: Exception, message: faust.types.tuples.Message) -> None\n",
      "     |  \n",
      "     |  on_stop_iteration(self) -> None\n",
      "     |  \n",
      "     |  async on_value_decode_error(self, exc: Exception, message: faust.types.tuples.Message) -> None\n",
      "     |  \n",
      "     |  prepare_key(self, key: Union[bytes, faust.types.core._ModelT, Any, NoneType], key_serializer: Union[faust.types.codecs.CodecT, str, NoneType], schema: faust.types.channels._SchemaT = None) -> Any\n",
      "     |  \n",
      "     |  prepare_value(self, value: Union[bytes, faust.types.core._ModelT, Any], value_serializer: Union[faust.types.codecs.CodecT, str, NoneType], schema: faust.types.channels._SchemaT = None) -> Any\n",
      "     |  \n",
      "     |  async publish_message(self, fut: faust.types.tuples.FutureMessage, wait: bool = True) -> Awaitable[faust.types.tuples.RecordMetadata]\n",
      "     |  \n",
      "     |  async put(self, value: faust.types.channels._EventT[~_T]) -> None\n",
      "     |  \n",
      "     |  async send(self, *, key: Union[bytes, faust.types.core._ModelT, Any, NoneType] = None, value: Union[bytes, faust.types.core._ModelT, Any] = None, partition: int = None, timestamp: float = None, headers: Union[List[Tuple[str, bytes]], Mapping[str, bytes], NoneType] = None, schema: faust.types.channels._SchemaT = None, key_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, value_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, callback: Callable[[faust.types.tuples.FutureMessage], Union[NoneType, Awaitable[NoneType]]] = None, force: bool = False) -> Awaitable[faust.types.tuples.RecordMetadata]\n",
      "     |  \n",
      "     |  send_soon(self, *, key: Union[bytes, faust.types.core._ModelT, Any, NoneType] = None, value: Union[bytes, faust.types.core._ModelT, Any] = None, partition: int = None, timestamp: float = None, headers: Union[List[Tuple[str, bytes]], Mapping[str, bytes], NoneType] = None, schema: faust.types.channels._SchemaT = None, key_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, value_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, callback: Callable[[faust.types.tuples.FutureMessage], Union[NoneType, Awaitable[NoneType]]] = None, force: bool = False, eager_partitioning: bool = False) -> faust.types.tuples.FutureMessage\n",
      "     |  \n",
      "     |  stream(self, **kwargs: Any) -> '_StreamT[_T]'\n",
      "     |  \n",
      "     |  async throw(self, exc: BaseException) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  queue\n",
      "     |  \n",
      "     |  subscriber_count\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset({'__aiter__', '__anext__', '__init__',...\n",
      "     |  \n",
      "     |  __annotations__ = {'active_partitions': typing.Union[typing.Set[faust....\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.AsyncIterator[faust.types.channels._EventT[~_...\n",
      "     |  \n",
      "     |  __parameters__ = (~_T,)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from collections.abc.AsyncIterator:\n",
      "     |  \n",
      "     |  __subclasshook__(C) from abc.ABCMeta\n",
      "     |      Abstract classes can override this to customize issubclass().\n",
      "     |      \n",
      "     |      This is invoked early on by abc.ABCMeta.__subclasscheck__().\n",
      "     |      It should return True, False or NotImplemented.  If it returns\n",
      "     |      NotImplemented, the normal algorithm is used.  Otherwise, it\n",
      "     |      overrides the normal algorithm (and the outcome is cached).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from abc.ABCMeta\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from abc.ABCMeta\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Codec(faust.types.codecs.CodecT)\n",
      "     |  Codec(children: Tuple[faust.types.codecs.CodecT, ...] = None, **kwargs: Any) -> None\n",
      "     |  \n",
      "     |  Base class for codecs.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Codec\n",
      "     |      faust.types.codecs.CodecT\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, children: Tuple[faust.types.codecs.CodecT, ...] = None, **kwargs: Any) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __or__(self, other: Any) -> Any\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  clone(self, *children: faust.types.codecs.CodecT) -> faust.types.codecs.CodecT\n",
      "     |      Create a clone of this codec, with optional children added.\n",
      "     |  \n",
      "     |  dumps(self, obj: Any) -> bytes\n",
      "     |      Encode object ``obj``.\n",
      "     |  \n",
      "     |  loads(self, s: bytes) -> Any\n",
      "     |      Decode object from string.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'children': typing.Tuple[faust.types.codecs.CodecT,...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from faust.types.codecs.CodecT:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Event(faust.types.events.EventT)\n",
      "     |  Event(*args, **kwds)\n",
      "     |  \n",
      "     |  An event received on a channel.\n",
      "     |  \n",
      "     |  Notes:\n",
      "     |      - Events have a key and a value::\n",
      "     |  \n",
      "     |          event.key, event.value\n",
      "     |  \n",
      "     |      - They also have a reference to the original message\n",
      "     |        (if available), such as a Kafka record:\n",
      "     |  \n",
      "     |          event.message.offset\n",
      "     |  \n",
      "     |      - Iterating over channels/topics yields Event:\n",
      "     |  \n",
      "     |          async for event in channel:\n",
      "     |              ...\n",
      "     |  \n",
      "     |      - Iterating over a stream (that in turn iterate over channel) yields\n",
      "     |        Event.value::\n",
      "     |  \n",
      "     |          async for value in channel.stream()  # value is event.value\n",
      "     |              ...\n",
      "     |  \n",
      "     |      - If you only have a Stream object, you can also access underlying\n",
      "     |        events by using ``Stream.events``.\n",
      "     |  \n",
      "     |          For example:\n",
      "     |  \n",
      "     |          .. sourcecode:: python\n",
      "     |  \n",
      "     |              async for event in channel.stream.events():\n",
      "     |                  ...\n",
      "     |  \n",
      "     |        Also commonly used for finding the \"current event\" related to\n",
      "     |        a value in the stream:\n",
      "     |  \n",
      "     |        .. sourcecode:: python\n",
      "     |  \n",
      "     |            stream = channel.stream()\n",
      "     |            async for event in stream.events():\n",
      "     |                event = stream.current_event\n",
      "     |                message = event.message\n",
      "     |                topic = event.message.topic\n",
      "     |  \n",
      "     |        You can retrieve the current event in a stream to:\n",
      "     |  \n",
      "     |            - Get access to the serialized key+value.\n",
      "     |            - Get access to message properties like, what topic+partition\n",
      "     |              the value was received on, or its offset.\n",
      "     |  \n",
      "     |        If you want access to both key and value, you should use\n",
      "     |        ``stream.items()`` instead.\n",
      "     |  \n",
      "     |          .. sourcecode:: python\n",
      "     |  \n",
      "     |              async for key, value in stream.items():\n",
      "     |                  ...\n",
      "     |  \n",
      "     |          ``stream.current_event`` can also be accessed but you must take\n",
      "     |          extreme care you are using the correct stream object. Methods\n",
      "     |          such as ``.group_by(key)`` and ``.through(topic)`` returns cloned\n",
      "     |          stream objects, so in the example:\n",
      "     |  \n",
      "     |          The best way to access the current_event in an agent is\n",
      "     |          to use the :class:`~contextvars.ContextVar`:\n",
      "     |  \n",
      "     |          .. sourcecode:: python\n",
      "     |  \n",
      "     |              from faust import current_event\n",
      "     |  \n",
      "     |              @app.agent(topic)\n",
      "     |              async def process(stream):\n",
      "     |                  async for value in stream:\n",
      "     |                      event = current_event()\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Event\n",
      "     |      faust.types.events.EventT\n",
      "     |      contextlib.AbstractAsyncContextManager\n",
      "     |      abc.ABC\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  async __aenter__(self) -> faust.types.events.EventT\n",
      "     |      Return `self` upon entering the runtime context.\n",
      "     |  \n",
      "     |  async __aexit__(self, _exc_type: Type[BaseException] = None, _exc_val: BaseException = None, _exc_tb: traceback = None) -> Union[bool, NoneType]\n",
      "     |      Raise any exception triggered within the runtime context.\n",
      "     |  \n",
      "     |  __init__(self, app: faust.types.app.AppT, key: Union[bytes, faust.types.core._ModelT, Any, NoneType], value: Union[bytes, faust.types.core._ModelT, Any], headers: Union[List[Tuple[str, bytes]], Mapping[str, bytes], NoneType], message: faust.types.tuples.Message) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ack(self) -> bool\n",
      "     |      Acknowledge event as being processed by stream.\n",
      "     |      \n",
      "     |      When the last stream processor acks the message, the\n",
      "     |      offset in the source topic will be marked as safe-to-commit,\n",
      "     |      and the worker will commit and advance the committed offset.\n",
      "     |  \n",
      "     |  async forward(self, channel: Union[str, faust.types.channels.ChannelT], key: Union[bytes, faust.types.core._ModelT, Any, NoneType] = <object object at 0x7fc52ac00f00>, value: Union[bytes, faust.types.core._ModelT, Any] = <object object at 0x7fc52ac00400>, partition: int = None, timestamp: float = None, headers: Any = <object object at 0x7fc52ac00600>, schema: faust.types.serializers.SchemaT = None, key_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, value_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, callback: Callable[[faust.types.tuples.FutureMessage], Union[NoneType, Awaitable[NoneType]]] = None, force: bool = False) -> Awaitable[faust.types.tuples.RecordMetadata]\n",
      "     |      Forward original message (will not be reserialized).\n",
      "     |  \n",
      "     |  async send(self, channel: Union[str, faust.types.channels.ChannelT], key: Union[bytes, faust.types.core._ModelT, Any, NoneType] = <object object at 0x7fc52ac00f00>, value: Union[bytes, faust.types.core._ModelT, Any] = <object object at 0x7fc52ac00400>, partition: int = None, timestamp: float = None, headers: Any = <object object at 0x7fc52ac00600>, schema: faust.types.serializers.SchemaT = None, key_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, value_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, callback: Callable[[faust.types.tuples.FutureMessage], Union[NoneType, Awaitable[NoneType]]] = None, force: bool = False) -> Awaitable[faust.types.tuples.RecordMetadata]\n",
      "     |      Send object to channel.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from faust.types.events.EventT:\n",
      "     |  \n",
      "     |  acked\n",
      "     |  \n",
      "     |  app\n",
      "     |  \n",
      "     |  headers\n",
      "     |  \n",
      "     |  key\n",
      "     |  \n",
      "     |  message\n",
      "     |  \n",
      "     |  value\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from faust.types.events.EventT:\n",
      "     |  \n",
      "     |  __annotations__ = {'acked': <class 'bool'>, 'app': <class 'faust.types...\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[~T], typing.AbstractAsyncContextManag...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from contextlib.AbstractAsyncContextManager:\n",
      "     |  \n",
      "     |  __subclasshook__(C) from abc.ABCMeta\n",
      "     |      Abstract classes can override this to customize issubclass().\n",
      "     |      \n",
      "     |      This is invoked early on by abc.ABCMeta.__subclasscheck__().\n",
      "     |      It should return True, False or NotImplemented.  If it returns\n",
      "     |      NotImplemented, the normal algorithm is used.  Otherwise, it\n",
      "     |      overrides the normal algorithm (and the outcome is cached).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from contextlib.AbstractAsyncContextManager:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from abc.ABCMeta\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from abc.ABCMeta\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class EventT(contextlib.AbstractAsyncContextManager, typing.Generic)\n",
      "     |  EventT(*args, **kwds)\n",
      "     |  \n",
      "     |  An abstract base class for asynchronous context managers.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      EventT\n",
      "     |      contextlib.AbstractAsyncContextManager\n",
      "     |      abc.ABC\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, app: faust.types.events._AppT, key: Union[bytes, faust.types.core._ModelT, Any, NoneType], value: Union[bytes, faust.types.core._ModelT, Any], headers: Union[List[Tuple[str, bytes]], Mapping[str, bytes], NoneType], message: faust.types.tuples.Message) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ack(self) -> bool\n",
      "     |  \n",
      "     |  async forward(self, channel: Union[str, faust.types.events._ChannelT], key: Any = None, value: Any = None, partition: int = None, timestamp: float = None, headers: Union[List[Tuple[str, bytes]], Mapping[str, bytes], NoneType] = None, schema: faust.types.events._SchemaT = None, key_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, value_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, callback: Callable[[faust.types.tuples.FutureMessage], Union[NoneType, Awaitable[NoneType]]] = None, force: bool = False) -> Awaitable[faust.types.tuples.RecordMetadata]\n",
      "     |  \n",
      "     |  async send(self, channel: Union[str, faust.types.events._ChannelT], key: Union[bytes, faust.types.core._ModelT, Any, NoneType] = None, value: Union[bytes, faust.types.core._ModelT, Any] = None, partition: int = None, timestamp: float = None, headers: Union[List[Tuple[str, bytes]], Mapping[str, bytes], NoneType] = None, schema: faust.types.events._SchemaT = None, key_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, value_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, callback: Callable[[faust.types.tuples.FutureMessage], Union[NoneType, Awaitable[NoneType]]] = None, force: bool = False) -> Awaitable[faust.types.tuples.RecordMetadata]\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  acked\n",
      "     |  \n",
      "     |  app\n",
      "     |  \n",
      "     |  headers\n",
      "     |  \n",
      "     |  key\n",
      "     |  \n",
      "     |  message\n",
      "     |  \n",
      "     |  value\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset({'__aexit__', '__init__', 'ack', 'forw...\n",
      "     |  \n",
      "     |  __annotations__ = {'acked': <class 'bool'>, 'app': <class 'faust.types...\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[~T], typing.AbstractAsyncContextManag...\n",
      "     |  \n",
      "     |  __parameters__ = (~T,)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from contextlib.AbstractAsyncContextManager:\n",
      "     |  \n",
      "     |  async __aenter__(self)\n",
      "     |      Return `self` upon entering the runtime context.\n",
      "     |  \n",
      "     |  async __aexit__(self, exc_type, exc_value, traceback)\n",
      "     |      Raise any exception triggered within the runtime context.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from contextlib.AbstractAsyncContextManager:\n",
      "     |  \n",
      "     |  __subclasshook__(C) from abc.ABCMeta\n",
      "     |      Abstract classes can override this to customize issubclass().\n",
      "     |      \n",
      "     |      This is invoked early on by abc.ABCMeta.__subclasscheck__().\n",
      "     |      It should return True, False or NotImplemented.  If it returns\n",
      "     |      NotImplemented, the normal algorithm is used.  Otherwise, it\n",
      "     |      overrides the normal algorithm (and the outcome is cached).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from contextlib.AbstractAsyncContextManager:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from abc.ABCMeta\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from abc.ABCMeta\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class GSSAPICredentials(Credentials)\n",
      "     |  GSSAPICredentials(*, kerberos_service_name: str = 'kafka', kerberos_domain_name: str = None, ssl_context: ssl.SSLContext = None, mechanism: Union[str, faust.types.auth.SASLMechanism] = None) -> None\n",
      "     |  \n",
      "     |  Describe GSSAPI credentials over SASL.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GSSAPICredentials\n",
      "     |      Credentials\n",
      "     |      faust.types.auth.CredentialsT\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *, kerberos_service_name: str = 'kafka', kerberos_domain_name: str = None, ssl_context: ssl.SSLContext = None, mechanism: Union[str, faust.types.auth.SASLMechanism] = None) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {'mechanism': <enum 'SASLMechanism'>, 'ssl_context':...\n",
      "     |  \n",
      "     |  mechanism = <SASLMechanism.GSSAPI: 'GSSAPI'>\n",
      "     |  \n",
      "     |  protocol = <AuthProtocol.SASL_PLAINTEXT: 'SASL_PLAINTEXT'>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from faust.types.auth.CredentialsT:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class GlobalTable(faust.tables.table.Table, faust.types.tables.GlobalTableT)\n",
      "     |  GlobalTable(*args, **kwds)\n",
      "     |  \n",
      "     |  Table (non-windowed).\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GlobalTable\n",
      "     |      faust.tables.table.Table\n",
      "     |      faust.types.tables.GlobalTableT\n",
      "     |      faust.types.tables.TableT\n",
      "     |      faust.tables.base.Collection\n",
      "     |      mode.services.Service\n",
      "     |      mode.services.ServiceBase\n",
      "     |      faust.types.tables.CollectionT\n",
      "     |      mode.types.services.ServiceT\n",
      "     |      contextlib.AbstractAsyncContextManager\n",
      "     |      faust.types.streams.JoinableT\n",
      "     |      abc.ABC\n",
      "     |      mode.utils.collections.ManagedUserDict\n",
      "     |      mode.utils.collections.FastUserDict\n",
      "     |      collections.abc.MutableMapping\n",
      "     |      collections.abc.Mapping\n",
      "     |      collections.abc.Collection\n",
      "     |      collections.abc.Sized\n",
      "     |      collections.abc.Iterable\n",
      "     |      collections.abc.Container\n",
      "     |      typing.Generic\n",
      "     |      mode.services.ServiceCallbacks\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  logger = <Logger faust.tables.globaltable (INFO)>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from faust.tables.table.Table:\n",
      "     |  \n",
      "     |  __missing__(self, key: ~KT) -> ~VT\n",
      "     |  \n",
      "     |  as_ansitable(self, title: str = '{table.name}', **kwargs: Any) -> str\n",
      "     |      Draw table as a a terminal ANSI table.\n",
      "     |  \n",
      "     |  hopping(self, size: Union[datetime.timedelta, float, str], step: Union[datetime.timedelta, float, str], expires: Union[datetime.timedelta, float, str] = None, key_index: bool = False) -> faust.types.tables.WindowWrapperT\n",
      "     |      Wrap table in a hopping window.\n",
      "     |  \n",
      "     |  on_key_del(self, key: ~KT) -> None\n",
      "     |      Call when a key in this table is removed.\n",
      "     |  \n",
      "     |  on_key_get(self, key: ~KT) -> None\n",
      "     |      Call when the value for a key in this table is retrieved.\n",
      "     |  \n",
      "     |  on_key_set(self, key: ~KT, value: ~VT) -> None\n",
      "     |      Call when the value for a key in this table is set.\n",
      "     |  \n",
      "     |  tumbling(self, size: Union[datetime.timedelta, float, str], expires: Union[datetime.timedelta, float, str] = None, key_index: bool = False) -> faust.types.tables.WindowWrapperT\n",
      "     |      Wrap table in a tumbling window.\n",
      "     |  \n",
      "     |  using_window(self, window: faust.types.windows.WindowT, *, key_index: bool = False) -> faust.types.tables.WindowWrapperT\n",
      "     |      Wrap table using a specific window type.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from faust.tables.table.Table:\n",
      "     |  \n",
      "     |  WindowWrapper = <class 'faust.tables.wrappers.WindowWrapper'>\n",
      "     |      Windowed table wrapper.\n",
      "     |      \n",
      "     |      A windowed table does not return concrete values when keys are\n",
      "     |      accessed, instead :class:`WindowSet` is returned so that\n",
      "     |      the values can be further reduced to the wanted time period.\n",
      "     |  \n",
      "     |  __annotations__ = {'WindowWrapper': typing.ClassVar[typing.Type[faust....\n",
      "     |  \n",
      "     |  __orig_bases__ = (faust.types.tables.TableT[~KT, ~VT], <class 'faust.t...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from faust.types.tables.GlobalTableT:\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from faust.tables.base.Collection:\n",
      "     |  \n",
      "     |  __and__(self, other: Any) -> Any\n",
      "     |  \n",
      "     |  __copy__(self) -> Any\n",
      "     |  \n",
      "     |  __hash__(self) -> int\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __init__(self, app: faust.types.app.AppT, *, name: str = None, default: Callable[[], Any] = None, store: Union[str, yarl.URL] = None, schema: faust.types.serializers.SchemaT = None, key_type: Union[Type[faust.types.models.ModelT], Type[bytes], Type[str]] = None, value_type: Union[Type[faust.types.models.ModelT], Type[bytes], Type[str]] = None, partitions: int = None, window: faust.types.windows.WindowT = None, changelog_topic: faust.types.topics.TopicT = None, help: str = None, on_recover: Callable[[], Awaitable[NoneType]] = None, on_changelog_event: Callable[[faust.types.events.EventT], Awaitable[NoneType]] = None, recovery_buffer_size: int = 1000, standby_buffer_size: int = None, extra_topic_configs: Mapping[str, Any] = None, recover_callbacks: Set[Callable[[], Awaitable[NoneType]]] = None, options: Mapping[str, Any] = None, use_partitioner: bool = False, on_window_close: Callable[[Any, Any], NoneType] = None, is_global: bool = False, **kwargs: Any) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  apply_changelog_batch(self, batch: Iterable[faust.types.events.EventT]) -> None\n",
      "     |      Apply batch of events from changelog topic local table storage.\n",
      "     |  \n",
      "     |  async call_recover_callbacks(self) -> None\n",
      "     |      Call any configured recovery callbacks after rebalancing.\n",
      "     |  \n",
      "     |  clone(self, **kwargs: Any) -> Any\n",
      "     |      Clone table instance.\n",
      "     |  \n",
      "     |  combine(self, *nodes: faust.types.streams.JoinableT, **kwargs: Any) -> faust.types.streams.StreamT\n",
      "     |      Combine tables and streams.\n",
      "     |  \n",
      "     |  contribute_to_stream(self, active: faust.types.streams.StreamT) -> None\n",
      "     |      Contribute table to stream join.\n",
      "     |  \n",
      "     |  info(self) -> Mapping[str, Any]\n",
      "     |      Return table attributes as dictionary.\n",
      "     |  \n",
      "     |  inner_join(self, *fields: faust.types.models.FieldDescriptorT) -> faust.types.streams.StreamT\n",
      "     |      Inner join of this table and another stream/table.\n",
      "     |  \n",
      "     |  join(self, *fields: faust.types.models.FieldDescriptorT) -> faust.types.streams.StreamT\n",
      "     |      Right join of this table and another stream/table.\n",
      "     |  \n",
      "     |  left_join(self, *fields: faust.types.models.FieldDescriptorT) -> faust.types.streams.StreamT\n",
      "     |      Left join of this table and another stream/table.\n",
      "     |  \n",
      "     |  async need_active_standby_for(self, tp: faust.types.tuples.TP) -> bool\n",
      "     |      Return :const:`False` if we have access to partition data.\n",
      "     |  \n",
      "     |  async on_changelog_event(self, event: faust.types.events.EventT) -> None\n",
      "     |      Call when a new changelog event is received.\n",
      "     |  \n",
      "     |  async on_rebalance(self, assigned: Set[faust.types.tuples.TP], revoked: Set[faust.types.tuples.TP], newly_assigned: Set[faust.types.tuples.TP]) -> None\n",
      "     |      Call when cluster is rebalancing.\n",
      "     |  \n",
      "     |  on_recover(self, fun: Callable[[], Awaitable[NoneType]]) -> Callable[[], Awaitable[NoneType]]\n",
      "     |      Add function as callback to be called on table recovery.\n",
      "     |  \n",
      "     |  async on_recovery_completed(self, active_tps: Set[faust.types.tuples.TP], standby_tps: Set[faust.types.tuples.TP]) -> None\n",
      "     |      Call when recovery has completed after rebalancing.\n",
      "     |  \n",
      "     |  async on_start(self) -> None\n",
      "     |      Call when table starts.\n",
      "     |  \n",
      "     |  on_window_close(self, key: Any, value: Any) -> None\n",
      "     |  \n",
      "     |  outer_join(self, *fields: faust.types.models.FieldDescriptorT) -> faust.types.streams.StreamT\n",
      "     |      Outer join of this table and another stream/table.\n",
      "     |  \n",
      "     |  partition_for_key(self, key: Any) -> Union[int, NoneType]\n",
      "     |      Return partition number for table key.\n",
      "     |      \n",
      "     |      Always returns :const:`None` when :attr:`use_partitioner`\n",
      "     |      is enabled.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Optional[int]: specific partition or :const:`None` if\n",
      "     |              the producer should select partition using its partitioner.\n",
      "     |  \n",
      "     |  persisted_offset(self, tp: faust.types.tuples.TP) -> Union[int, NoneType]\n",
      "     |      Return the last persisted offset for topic partition.\n",
      "     |  \n",
      "     |  async remove_from_stream(self, stream: faust.types.streams.StreamT) -> None\n",
      "     |      Remove table from stream join after stream stopped.\n",
      "     |  \n",
      "     |  reset_state(self) -> None\n",
      "     |      Reset local state.\n",
      "     |  \n",
      "     |  send_changelog(self, partition: Union[int, NoneType], key: Any, value: Any, key_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, value_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None) -> faust.types.tuples.FutureMessage\n",
      "     |      Send modification event to changelog topic.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from faust.tables.base.Collection:\n",
      "     |  \n",
      "     |  changelog_topic_name\n",
      "     |  \n",
      "     |  data\n",
      "     |      Underlying table storage.\n",
      "     |  \n",
      "     |  label\n",
      "     |      Return human-readable label used to represent this table.\n",
      "     |  \n",
      "     |  shortlabel\n",
      "     |      Return short label used to represent this table in logs.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from faust.tables.base.Collection:\n",
      "     |  \n",
      "     |  changelog_topic\n",
      "     |      Return the changelog topic used by this table.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  __post_init__(self) -> None\n",
      "     |      Additional user initialization.\n",
      "     |  \n",
      "     |  async add_async_context(self, context: AbstractAsyncContextManager) -> Any\n",
      "     |  \n",
      "     |  add_context(self, context: AbstractContextManager) -> Any\n",
      "     |  \n",
      "     |  add_dependency(self, service: mode.types.services.ServiceT) -> mode.types.services.ServiceT\n",
      "     |      Add dependency to other service.\n",
      "     |      \n",
      "     |      The service will be started/stopped with this service.\n",
      "     |  \n",
      "     |  add_future(self, coro: Awaitable) -> _asyncio.Future\n",
      "     |      Add relationship to asyncio.Future.\n",
      "     |      \n",
      "     |      The future will be joined when this service is stopped.\n",
      "     |  \n",
      "     |  async add_runtime_dependency(self, service: mode.types.services.ServiceT) -> mode.types.services.ServiceT\n",
      "     |  \n",
      "     |  async crash(self, reason: BaseException) -> None\n",
      "     |      Crash the service and all child services.\n",
      "     |  \n",
      "     |  async itertimer(self, interval: Union[datetime.timedelta, float, str], *, max_drift_correction: float = 0.1, loop: asyncio.events.AbstractEventLoop = None, sleep: Callable[..., Awaitable] = None, clock: Callable[[], float] = <built-in function perf_counter>, name: str = '') -> AsyncIterator[float]\n",
      "     |      Sleep ``interval`` seconds for every iteration.\n",
      "     |      \n",
      "     |      This is an async iterator that takes advantage\n",
      "     |      of :func:`~mode.timers.Timer` to monitor drift and timer\n",
      "     |      oerlap.\n",
      "     |      \n",
      "     |      Uses ``Service.sleep`` so exits fast when the service is\n",
      "     |      stopped.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          Will sleep the full `interval` seconds before returning\n",
      "     |          from first iteration.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |          >>> async for sleep_time in self.itertimer(1.0):\n",
      "     |          ...   print('another second passed, just woke up...')\n",
      "     |          ...   await perform_some_http_request()\n",
      "     |  \n",
      "     |  async join_services(self, services: Sequence[mode.types.services.ServiceT]) -> None\n",
      "     |  \n",
      "     |  async maybe_start(self) -> bool\n",
      "     |      Start the service, if it has not already been started.\n",
      "     |  \n",
      "     |  on_init(self) -> None\n",
      "     |  \n",
      "     |  on_init_dependencies(self) -> Iterable[mode.types.services.ServiceT]\n",
      "     |      Return list of service dependencies for this service.\n",
      "     |  \n",
      "     |  async remove_dependency(self, service: mode.types.services.ServiceT) -> mode.types.services.ServiceT\n",
      "     |      Stop and remove dependency of this service.\n",
      "     |  \n",
      "     |  async restart(self) -> None\n",
      "     |      Restart this service.\n",
      "     |  \n",
      "     |  service_reset(self) -> None\n",
      "     |  \n",
      "     |  set_shutdown(self) -> None\n",
      "     |      Set the shutdown signal.\n",
      "     |      \n",
      "     |      Notes:\n",
      "     |          If :attr:`wait_for_shutdown` is set, stopping the service\n",
      "     |          will wait for this flag to be set.\n",
      "     |  \n",
      "     |  async sleep(self, n: Union[datetime.timedelta, float, str], *, loop: asyncio.events.AbstractEventLoop = None) -> None\n",
      "     |      Sleep for ``n`` seconds, or until service stopped.\n",
      "     |  \n",
      "     |  async start(self) -> None\n",
      "     |  \n",
      "     |  async stop(self) -> None\n",
      "     |      Stop the service.\n",
      "     |  \n",
      "     |  async transition_with(self, flag: str, fut: Awaitable, *args: Any, **kwargs: Any) -> Any\n",
      "     |  \n",
      "     |  async wait(self, *coros: Union[_asyncio.Future, Generator[Any, NoneType, Any], Awaitable, asyncio.locks.Event, mode.utils.locks.Event], timeout: Union[datetime.timedelta, float, str] = None) -> mode.services.WaitResult\n",
      "     |      Wait for coroutines to complete, or until the service stops.\n",
      "     |  \n",
      "     |  async wait_first(self, *coros: Union[_asyncio.Future, Generator[Any, NoneType, Any], Awaitable, asyncio.locks.Event, mode.utils.locks.Event], timeout: Union[datetime.timedelta, float, str] = None) -> mode.services.WaitResults\n",
      "     |  \n",
      "     |  async wait_for_stopped(self, *coros: Union[_asyncio.Future, Generator[Any, NoneType, Any], Awaitable, asyncio.locks.Event, mode.utils.locks.Event], timeout: Union[datetime.timedelta, float, str] = None) -> bool\n",
      "     |  \n",
      "     |  async wait_many(self, coros: Iterable[Union[_asyncio.Future, Generator[Any, NoneType, Any], Awaitable, asyncio.locks.Event, mode.utils.locks.Event]], *, timeout: Union[datetime.timedelta, float, str] = None) -> mode.services.WaitResult\n",
      "     |  \n",
      "     |  async wait_until_stopped(self) -> None\n",
      "     |      Wait until the service is signalled to stop.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  __init_subclass__() -> None from abc.ABCMeta\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  from_awaitable(coro: Awaitable, *, name: str = None, **kwargs: Any) -> mode.types.services.ServiceT from abc.ABCMeta\n",
      "     |  \n",
      "     |  task(fun: Callable[[Any], Awaitable[NoneType]]) -> mode.services.ServiceTask from abc.ABCMeta\n",
      "     |      Decorate function to be used as background task.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> class S(Service):\n",
      "     |          ...\n",
      "     |          ...     @Service.task\n",
      "     |          ...     async def background_task(self):\n",
      "     |          ...         while not self.should_stop:\n",
      "     |          ...             await self.sleep(1.0)\n",
      "     |          ...             print('Waking up')\n",
      "     |  \n",
      "     |  timer(interval: Union[datetime.timedelta, float, str]) -> Callable[[Callable], mode.services.ServiceTask] from abc.ABCMeta\n",
      "     |      Background timer executing every ``n`` seconds.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> class S(Service):\n",
      "     |          ...\n",
      "     |          ...     @Service.timer(1.0)\n",
      "     |          ...     async def background_timer(self):\n",
      "     |          ...         print('Waking up')\n",
      "     |  \n",
      "     |  transitions_to(flag: str) -> Callable from abc.ABCMeta\n",
      "     |      Decorate function to set and reset diagnostic flag.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  crashed\n",
      "     |  \n",
      "     |  should_stop\n",
      "     |      Return :const:`True` if the service must stop.\n",
      "     |  \n",
      "     |  started\n",
      "     |      Return :const:`True` if the service was started.\n",
      "     |  \n",
      "     |  state\n",
      "     |      Service state - as a human readable string.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  beacon\n",
      "     |      Beacon used to track services in a dependency graph.\n",
      "     |  \n",
      "     |  crash_reason\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  Diag = <class 'mode.services.Diag'>\n",
      "     |      Service diagnostics.\n",
      "     |      \n",
      "     |      This can be used to track what your service is doing.\n",
      "     |      For example if your service is a Kafka consumer with a background\n",
      "     |      thread that commits the offset every 30 seconds, you may want to\n",
      "     |      see when this happens::\n",
      "     |      \n",
      "     |          DIAG_COMMITTING = 'committing'\n",
      "     |      \n",
      "     |          class Consumer(Service):\n",
      "     |      \n",
      "     |              @Service.task\n",
      "     |              async def _background_commit(self) -> None:\n",
      "     |                  while not self.should_stop:\n",
      "     |                      await self.sleep(30.0)\n",
      "     |                      self.diag.set_flag(DIAG_COMITTING)\n",
      "     |                      try:\n",
      "     |                          await self._consumer.commit()\n",
      "     |                      finally:\n",
      "     |                          self.diag.unset_flag(DIAG_COMMITTING)\n",
      "     |      \n",
      "     |      The above code is setting the flag manually, but you can also use\n",
      "     |      a decorator to accomplish the same thing::\n",
      "     |      \n",
      "     |          @Service.timer(30.0)\n",
      "     |          async def _background_commit(self) -> None:\n",
      "     |              await self.commit()\n",
      "     |      \n",
      "     |          @Service.transitions_with(DIAG_COMITTING)\n",
      "     |          async def commit(self) -> None:\n",
      "     |              await self._consumer.commit()\n",
      "     |  \n",
      "     |  abstract = False\n",
      "     |  \n",
      "     |  mundane_level = 'info'\n",
      "     |  \n",
      "     |  restart_count = 0\n",
      "     |  \n",
      "     |  shutdown_timeout = 60.0\n",
      "     |  \n",
      "     |  wait_for_shutdown = False\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mode.services.ServiceBase:\n",
      "     |  \n",
      "     |  async __aenter__(self) -> mode.types.services.ServiceT\n",
      "     |      Return `self` upon entering the runtime context.\n",
      "     |  \n",
      "     |  async __aexit__(self, exc_type: Type[BaseException] = None, exc_val: BaseException = None, exc_tb: traceback = None) -> Union[bool, NoneType]\n",
      "     |      Raise any exception triggered within the runtime context.\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from mode.services.ServiceBase:\n",
      "     |  \n",
      "     |  loop\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from faust.types.tables.CollectionT:\n",
      "     |  \n",
      "     |  is_global = False\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from mode.types.services.ServiceT:\n",
      "     |  \n",
      "     |  supervisor = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from contextlib.AbstractAsyncContextManager:\n",
      "     |  \n",
      "     |  __subclasshook__(C) from abc.ABCMeta\n",
      "     |      Abstract classes can override this to customize issubclass().\n",
      "     |      \n",
      "     |      This is invoked early on by abc.ABCMeta.__subclasscheck__().\n",
      "     |      It should return True, False or NotImplemented.  If it returns\n",
      "     |      NotImplemented, the normal algorithm is used.  Otherwise, it\n",
      "     |      overrides the normal algorithm (and the outcome is cached).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from contextlib.AbstractAsyncContextManager:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mode.utils.collections.ManagedUserDict:\n",
      "     |  \n",
      "     |  __delitem__(self, key: ~KT) -> None\n",
      "     |  \n",
      "     |  __getitem__(self, key: ~KT) -> Any\n",
      "     |  \n",
      "     |  __setitem__(self, key: ~KT, value: ~VT) -> None\n",
      "     |  \n",
      "     |  clear(self) -> None\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |  \n",
      "     |  on_clear(self) -> None\n",
      "     |      Handle that the mapping is being cleared.\n",
      "     |  \n",
      "     |  raw_update(self, *args: Any, **kwargs: Any) -> None\n",
      "     |  \n",
      "     |  update(self, *args: Any, **kwargs: Any) -> None\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E present and has a .keys() method, does:     for k in E: D[k] = E[k]\n",
      "     |      If E present and lacks .keys() method, does:     for (k, v) in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k, v in F.items(): D[k] = v\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mode.utils.collections.FastUserDict:\n",
      "     |  \n",
      "     |  __contains__(self, key: object) -> bool\n",
      "     |  \n",
      "     |  __iter__(self) -> Iterator[~KT]\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  copy(self) -> dict\n",
      "     |  \n",
      "     |  items(self) -> ItemsView\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |  \n",
      "     |  keys(self) -> KeysView\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |  \n",
      "     |  values(self) -> ValuesView\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from mode.utils.collections.FastUserDict:\n",
      "     |  \n",
      "     |  fromkeys(iterable: Iterable[~KT], value: ~VT = None) -> 'FastUserDict' from abc.ABCMeta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from collections.abc.MutableMapping:\n",
      "     |  \n",
      "     |  pop(self, key, default=<object object at 0x7fc595cbb150>)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |      If key is not found, d is returned if given, otherwise KeyError is raised.\n",
      "     |  \n",
      "     |  popitem(self)\n",
      "     |      D.popitem() -> (k, v), remove and return some (key, value) pair\n",
      "     |      as a 2-tuple; but raise KeyError if D is empty.\n",
      "     |  \n",
      "     |  setdefault(self, key, default=None)\n",
      "     |      D.setdefault(k[,d]) -> D.get(k,d), also set D[k]=d if k not in D\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from collections.abc.Mapping:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  get(self, key, default=None)\n",
      "     |      D.get(k[,d]) -> D[k] if k in D, else d.  d defaults to None.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from collections.abc.Mapping:\n",
      "     |  \n",
      "     |  __reversed__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from abc.ABCMeta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mode.services.ServiceCallbacks:\n",
      "     |  \n",
      "     |  async on_first_start(self) -> None\n",
      "     |      Service started for the first time in this process.\n",
      "     |  \n",
      "     |  async on_restart(self) -> None\n",
      "     |      Service is being restarted.\n",
      "     |  \n",
      "     |  async on_shutdown(self) -> None\n",
      "     |      Service is being stopped/restarted.\n",
      "     |  \n",
      "     |  async on_started(self) -> None\n",
      "     |      Service has started.\n",
      "     |  \n",
      "     |  async on_stop(self) -> None\n",
      "     |      Service is being stopped/restarted.\n",
      "    \n",
      "    HoppingWindow = class _PyHoppingWindow(Window)\n",
      "     |  HoppingWindow(size: Union[datetime.timedelta, float, str], step: Union[datetime.timedelta, float, str], expires: Union[datetime.timedelta, float, str] = None) -> None\n",
      "     |  \n",
      "     |  Hopping window type.\n",
      "     |  \n",
      "     |  Fixed-size, overlapping windows.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      _PyHoppingWindow\n",
      "     |      Window\n",
      "     |      faust.types.windows.WindowT\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, size: Union[datetime.timedelta, float, str], step: Union[datetime.timedelta, float, str], expires: Union[datetime.timedelta, float, str] = None) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  current(self, timestamp: float) -> Tuple[float, float]\n",
      "     |      Get the latest window range for a given timestamp.\n",
      "     |  \n",
      "     |  delta(self, timestamp: float, d: Union[datetime.timedelta, float, str]) -> Tuple[float, float]\n",
      "     |  \n",
      "     |  earliest(self, timestamp: float) -> Tuple[float, float]\n",
      "     |  \n",
      "     |  ranges(self, timestamp: float) -> List[Tuple[float, float]]\n",
      "     |  \n",
      "     |  stale(self, timestamp: float, latest_timestamp: float) -> bool\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'size': <class 'float'>, 'step': <class 'float'>}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from faust.types.windows.WindowT:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from faust.types.windows.WindowT:\n",
      "     |  \n",
      "     |  expires = None\n",
      "     |  \n",
      "     |  tz = None\n",
      "    \n",
      "    class ModelOptions(abc.ABC)\n",
      "     |  Helper class that provides a standard way to create an ABC using\n",
      "     |  inheritance.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ModelOptions\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  clone_defaults(self) -> 'ModelOptions'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'allow_blessed_key': <class 'bool'>, 'coerce': <cla...\n",
      "     |  \n",
      "     |  allow_blessed_key = False\n",
      "     |  \n",
      "     |  coerce = False\n",
      "     |  \n",
      "     |  coercions = None\n",
      "     |  \n",
      "     |  date_parser = None\n",
      "     |  \n",
      "     |  decimals = False\n",
      "     |  \n",
      "     |  defaults = None\n",
      "     |  \n",
      "     |  descriptors = None\n",
      "     |  \n",
      "     |  fieldpos = None\n",
      "     |  \n",
      "     |  fields = None\n",
      "     |  \n",
      "     |  fieldset = None\n",
      "     |  \n",
      "     |  has_personal_fields = False\n",
      "     |  \n",
      "     |  has_secret_fields = False\n",
      "     |  \n",
      "     |  has_sensitive_fields = False\n",
      "     |  \n",
      "     |  has_tagged_fields = False\n",
      "     |  \n",
      "     |  include_metadata = True\n",
      "     |  \n",
      "     |  isodates = False\n",
      "     |  \n",
      "     |  optionalset = None\n",
      "     |  \n",
      "     |  personal_fields = None\n",
      "     |  \n",
      "     |  polymorphic_fields = False\n",
      "     |  \n",
      "     |  secret_fields = None\n",
      "     |  \n",
      "     |  sensitive_fields = None\n",
      "     |  \n",
      "     |  serializer = None\n",
      "     |  \n",
      "     |  tagged_fields = None\n",
      "     |  \n",
      "     |  validation = False\n",
      "    \n",
      "    class Monitor(faust.sensors.base.Sensor, mode.utils.objects.KeywordReduce)\n",
      "     |  Monitor(*args, **kwds)\n",
      "     |  \n",
      "     |  Default Faust Sensor.\n",
      "     |  \n",
      "     |  This is the default sensor, recording statistics about\n",
      "     |  events, etc.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Monitor\n",
      "     |      faust.sensors.base.Sensor\n",
      "     |      faust.types.sensors.SensorT\n",
      "     |      faust.types.sensors.SensorInterfaceT\n",
      "     |      mode.services.Service\n",
      "     |      mode.services.ServiceBase\n",
      "     |      mode.types.services.ServiceT\n",
      "     |      contextlib.AbstractAsyncContextManager\n",
      "     |      abc.ABC\n",
      "     |      typing.Generic\n",
      "     |      mode.services.ServiceCallbacks\n",
      "     |      mode.utils.objects.KeywordReduce\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *, max_avg_history: int = None, max_commit_latency_history: int = None, max_send_latency_history: int = None, max_assignment_latency_history: int = None, messages_sent: int = 0, tables: MutableMapping[str, faust.sensors.monitor.TableState] = None, messages_active: int = 0, events_active: int = 0, messages_received_total: int = 0, messages_received_by_topic: Counter[str] = None, events_total: int = 0, events_by_stream: Counter[faust.types.streams.StreamT] = None, events_by_task: Counter[_asyncio.Task] = None, events_runtime: Deque[float] = None, commit_latency: Deque[float] = None, send_latency: Deque[float] = None, assignment_latency: Deque[float] = None, events_s: int = 0, messages_s: int = 0, events_runtime_avg: float = 0.0, topic_buffer_full: Counter[faust.types.topics.TopicT] = None, rebalances: int = None, rebalance_return_latency: Deque[float] = None, rebalance_end_latency: Deque[float] = None, rebalance_return_avg: float = 0.0, rebalance_end_avg: float = 0.0, time: Callable[[], float] = <built-in function monotonic>, http_response_codes: Counter[http.HTTPStatus] = None, http_response_latency: Deque[float] = None, http_response_latency_avg: float = 0.0, **kwargs: Any) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  asdict(self) -> Mapping\n",
      "     |      Return monitor state as dictionary.\n",
      "     |  \n",
      "     |  count(self, metric_name: str, count: int = 1) -> None\n",
      "     |      Count metric by name.\n",
      "     |  \n",
      "     |  ms_since(self, start_time: float) -> float\n",
      "     |      Given timestamp start, return number of ms since that time.\n",
      "     |  \n",
      "     |  on_assignment_completed(self, assignor: faust.types.assignor.PartitionAssignorT, state: Dict) -> None\n",
      "     |      Partition assignor completed assignment.\n",
      "     |  \n",
      "     |  on_assignment_error(self, assignor: faust.types.assignor.PartitionAssignorT, state: Dict, exc: BaseException) -> None\n",
      "     |      Partition assignor did not complete assignor due to error.\n",
      "     |  \n",
      "     |  on_assignment_start(self, assignor: faust.types.assignor.PartitionAssignorT) -> Dict\n",
      "     |      Partition assignor is starting to assign partitions.\n",
      "     |  \n",
      "     |  on_commit_completed(self, consumer: faust.types.transports.ConsumerT, state: Any) -> None\n",
      "     |      Call when consumer commit offset operation completed.\n",
      "     |  \n",
      "     |  on_commit_initiated(self, consumer: faust.types.transports.ConsumerT) -> Any\n",
      "     |      Consumer is about to commit topic offset.\n",
      "     |  \n",
      "     |  on_message_in(self, tp: faust.types.tuples.TP, offset: int, message: faust.types.tuples.Message) -> None\n",
      "     |      Call before message is delegated to streams.\n",
      "     |  \n",
      "     |  on_message_out(self, tp: faust.types.tuples.TP, offset: int, message: faust.types.tuples.Message) -> None\n",
      "     |      Call when message is fully acknowledged and can be committed.\n",
      "     |  \n",
      "     |  on_rebalance_end(self, app: faust.types.app.AppT, state: Dict) -> None\n",
      "     |      Cluster rebalance fully completed (including recovery).\n",
      "     |  \n",
      "     |  on_rebalance_return(self, app: faust.types.app.AppT, state: Dict) -> None\n",
      "     |      Consumer replied assignment is done to broker.\n",
      "     |  \n",
      "     |  on_rebalance_start(self, app: faust.types.app.AppT) -> Dict\n",
      "     |      Cluster rebalance in progress.\n",
      "     |  \n",
      "     |  on_send_completed(self, producer: faust.types.transports.ProducerT, state: Any, metadata: faust.types.tuples.RecordMetadata) -> None\n",
      "     |      Call when producer finished sending message.\n",
      "     |  \n",
      "     |  on_send_error(self, producer: faust.types.transports.ProducerT, exc: BaseException, state: Any) -> None\n",
      "     |      Call when producer was unable to publish message.\n",
      "     |  \n",
      "     |  on_send_initiated(self, producer: faust.types.transports.ProducerT, topic: str, message: faust.types.tuples.PendingMessage, keysize: int, valsize: int) -> Any\n",
      "     |      Call when message added to producer buffer.\n",
      "     |  \n",
      "     |  on_stream_event_in(self, tp: faust.types.tuples.TP, offset: int, stream: faust.types.streams.StreamT, event: faust.types.events.EventT) -> Union[Dict, NoneType]\n",
      "     |      Call when stream starts processing an event.\n",
      "     |  \n",
      "     |  on_stream_event_out(self, tp: faust.types.tuples.TP, offset: int, stream: faust.types.streams.StreamT, event: faust.types.events.EventT, state: Dict = None) -> None\n",
      "     |      Call when stream is done processing an event.\n",
      "     |  \n",
      "     |  on_table_del(self, table: faust.types.tables.CollectionT, key: Any) -> None\n",
      "     |      Call when key in a table is deleted.\n",
      "     |  \n",
      "     |  on_table_get(self, table: faust.types.tables.CollectionT, key: Any) -> None\n",
      "     |      Call when value in table is retrieved.\n",
      "     |  \n",
      "     |  on_table_set(self, table: faust.types.tables.CollectionT, key: Any, value: Any) -> None\n",
      "     |      Call when new value for key in table is set.\n",
      "     |  \n",
      "     |  on_topic_buffer_full(self, topic: faust.types.topics.TopicT) -> None\n",
      "     |      Call when conductor topic buffer is full and has to wait.\n",
      "     |  \n",
      "     |  on_tp_commit(self, tp_offsets: MutableMapping[faust.types.tuples.TP, int]) -> None\n",
      "     |      Call when offset in topic partition is committed.\n",
      "     |  \n",
      "     |  on_web_request_end(self, app: faust.types.app.AppT, request: faust.web.base.Request, response: Union[faust.web.base.Response, NoneType], state: Dict, *, view: faust.web.views.View = None) -> None\n",
      "     |      Web server finished working on request.\n",
      "     |  \n",
      "     |  on_web_request_start(self, app: faust.types.app.AppT, request: faust.web.base.Request, *, view: faust.web.views.View = None) -> Dict\n",
      "     |      Web server started working on request.\n",
      "     |  \n",
      "     |  secs_since(self, start_time: float) -> float\n",
      "     |      Given timestamp start, return number of seconds since that time.\n",
      "     |  \n",
      "     |  secs_to_ms(self, timestamp: float) -> float\n",
      "     |      Convert seconds to milliseconds.\n",
      "     |  \n",
      "     |  track_tp_end_offset(self, tp: faust.types.tuples.TP, offset: int) -> None\n",
      "     |      Track new topic partition end offset for monitoring lags.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'assignment_latency': typing.Deque[float], 'commit_...\n",
      "     |  \n",
      "     |  assignment_latency = None\n",
      "     |  \n",
      "     |  assignments_completed = 0\n",
      "     |  \n",
      "     |  assignments_failed = 0\n",
      "     |  \n",
      "     |  commit_latency = None\n",
      "     |  \n",
      "     |  events_active = 0\n",
      "     |  \n",
      "     |  events_by_stream = None\n",
      "     |  \n",
      "     |  events_by_task = None\n",
      "     |  \n",
      "     |  events_runtime = None\n",
      "     |  \n",
      "     |  events_runtime_avg = 0.0\n",
      "     |  \n",
      "     |  events_s = 0\n",
      "     |  \n",
      "     |  events_total = 0\n",
      "     |  \n",
      "     |  http_response_codes = None\n",
      "     |  \n",
      "     |  http_response_latency = None\n",
      "     |  \n",
      "     |  http_response_latency_avg = 0.0\n",
      "     |  \n",
      "     |  logger = <Logger faust.sensors.monitor (INFO)>\n",
      "     |  \n",
      "     |  max_assignment_latency_history = 30\n",
      "     |  \n",
      "     |  max_avg_history = 100\n",
      "     |  \n",
      "     |  max_commit_latency_history = 30\n",
      "     |  \n",
      "     |  max_send_latency_history = 30\n",
      "     |  \n",
      "     |  messages_active = 0\n",
      "     |  \n",
      "     |  messages_received_by_topic = None\n",
      "     |  \n",
      "     |  messages_received_total = 0\n",
      "     |  \n",
      "     |  messages_s = 0\n",
      "     |  \n",
      "     |  messages_sent = 0\n",
      "     |  \n",
      "     |  messages_sent_by_topic = None\n",
      "     |  \n",
      "     |  metric_counts = None\n",
      "     |  \n",
      "     |  rebalance_end_avg = 0.0\n",
      "     |  \n",
      "     |  rebalance_end_latency = None\n",
      "     |  \n",
      "     |  rebalance_return_avg = 0.0\n",
      "     |  \n",
      "     |  rebalance_return_latency = None\n",
      "     |  \n",
      "     |  rebalances = 0\n",
      "     |  \n",
      "     |  send_errors = 0\n",
      "     |  \n",
      "     |  send_latency = None\n",
      "     |  \n",
      "     |  stream_inbound_time = None\n",
      "     |  \n",
      "     |  tables = None\n",
      "     |  \n",
      "     |  topic_buffer_full = None\n",
      "     |  \n",
      "     |  tp_committed_offsets = None\n",
      "     |  \n",
      "     |  tp_end_offsets = None\n",
      "     |  \n",
      "     |  tp_read_offsets = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from faust.types.sensors.SensorT:\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from faust.types.sensors.SensorInterfaceT:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  __post_init__(self) -> None\n",
      "     |      Additional user initialization.\n",
      "     |  \n",
      "     |  async add_async_context(self, context: AbstractAsyncContextManager) -> Any\n",
      "     |  \n",
      "     |  add_context(self, context: AbstractContextManager) -> Any\n",
      "     |  \n",
      "     |  add_dependency(self, service: mode.types.services.ServiceT) -> mode.types.services.ServiceT\n",
      "     |      Add dependency to other service.\n",
      "     |      \n",
      "     |      The service will be started/stopped with this service.\n",
      "     |  \n",
      "     |  add_future(self, coro: Awaitable) -> _asyncio.Future\n",
      "     |      Add relationship to asyncio.Future.\n",
      "     |      \n",
      "     |      The future will be joined when this service is stopped.\n",
      "     |  \n",
      "     |  async add_runtime_dependency(self, service: mode.types.services.ServiceT) -> mode.types.services.ServiceT\n",
      "     |  \n",
      "     |  async crash(self, reason: BaseException) -> None\n",
      "     |      Crash the service and all child services.\n",
      "     |  \n",
      "     |  async itertimer(self, interval: Union[datetime.timedelta, float, str], *, max_drift_correction: float = 0.1, loop: asyncio.events.AbstractEventLoop = None, sleep: Callable[..., Awaitable] = None, clock: Callable[[], float] = <built-in function perf_counter>, name: str = '') -> AsyncIterator[float]\n",
      "     |      Sleep ``interval`` seconds for every iteration.\n",
      "     |      \n",
      "     |      This is an async iterator that takes advantage\n",
      "     |      of :func:`~mode.timers.Timer` to monitor drift and timer\n",
      "     |      oerlap.\n",
      "     |      \n",
      "     |      Uses ``Service.sleep`` so exits fast when the service is\n",
      "     |      stopped.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          Will sleep the full `interval` seconds before returning\n",
      "     |          from first iteration.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |          >>> async for sleep_time in self.itertimer(1.0):\n",
      "     |          ...   print('another second passed, just woke up...')\n",
      "     |          ...   await perform_some_http_request()\n",
      "     |  \n",
      "     |  async join_services(self, services: Sequence[mode.types.services.ServiceT]) -> None\n",
      "     |  \n",
      "     |  async maybe_start(self) -> bool\n",
      "     |      Start the service, if it has not already been started.\n",
      "     |  \n",
      "     |  on_init(self) -> None\n",
      "     |  \n",
      "     |  on_init_dependencies(self) -> Iterable[mode.types.services.ServiceT]\n",
      "     |      Return list of service dependencies for this service.\n",
      "     |  \n",
      "     |  async remove_dependency(self, service: mode.types.services.ServiceT) -> mode.types.services.ServiceT\n",
      "     |      Stop and remove dependency of this service.\n",
      "     |  \n",
      "     |  async restart(self) -> None\n",
      "     |      Restart this service.\n",
      "     |  \n",
      "     |  service_reset(self) -> None\n",
      "     |  \n",
      "     |  set_shutdown(self) -> None\n",
      "     |      Set the shutdown signal.\n",
      "     |      \n",
      "     |      Notes:\n",
      "     |          If :attr:`wait_for_shutdown` is set, stopping the service\n",
      "     |          will wait for this flag to be set.\n",
      "     |  \n",
      "     |  async sleep(self, n: Union[datetime.timedelta, float, str], *, loop: asyncio.events.AbstractEventLoop = None) -> None\n",
      "     |      Sleep for ``n`` seconds, or until service stopped.\n",
      "     |  \n",
      "     |  async start(self) -> None\n",
      "     |  \n",
      "     |  async stop(self) -> None\n",
      "     |      Stop the service.\n",
      "     |  \n",
      "     |  async transition_with(self, flag: str, fut: Awaitable, *args: Any, **kwargs: Any) -> Any\n",
      "     |  \n",
      "     |  async wait(self, *coros: Union[_asyncio.Future, Generator[Any, NoneType, Any], Awaitable, asyncio.locks.Event, mode.utils.locks.Event], timeout: Union[datetime.timedelta, float, str] = None) -> mode.services.WaitResult\n",
      "     |      Wait for coroutines to complete, or until the service stops.\n",
      "     |  \n",
      "     |  async wait_first(self, *coros: Union[_asyncio.Future, Generator[Any, NoneType, Any], Awaitable, asyncio.locks.Event, mode.utils.locks.Event], timeout: Union[datetime.timedelta, float, str] = None) -> mode.services.WaitResults\n",
      "     |  \n",
      "     |  async wait_for_stopped(self, *coros: Union[_asyncio.Future, Generator[Any, NoneType, Any], Awaitable, asyncio.locks.Event, mode.utils.locks.Event], timeout: Union[datetime.timedelta, float, str] = None) -> bool\n",
      "     |  \n",
      "     |  async wait_many(self, coros: Iterable[Union[_asyncio.Future, Generator[Any, NoneType, Any], Awaitable, asyncio.locks.Event, mode.utils.locks.Event]], *, timeout: Union[datetime.timedelta, float, str] = None) -> mode.services.WaitResult\n",
      "     |  \n",
      "     |  async wait_until_stopped(self) -> None\n",
      "     |      Wait until the service is signalled to stop.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  __init_subclass__() -> None from abc.ABCMeta\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  from_awaitable(coro: Awaitable, *, name: str = None, **kwargs: Any) -> mode.types.services.ServiceT from abc.ABCMeta\n",
      "     |  \n",
      "     |  task(fun: Callable[[Any], Awaitable[NoneType]]) -> mode.services.ServiceTask from abc.ABCMeta\n",
      "     |      Decorate function to be used as background task.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> class S(Service):\n",
      "     |          ...\n",
      "     |          ...     @Service.task\n",
      "     |          ...     async def background_task(self):\n",
      "     |          ...         while not self.should_stop:\n",
      "     |          ...             await self.sleep(1.0)\n",
      "     |          ...             print('Waking up')\n",
      "     |  \n",
      "     |  timer(interval: Union[datetime.timedelta, float, str]) -> Callable[[Callable], mode.services.ServiceTask] from abc.ABCMeta\n",
      "     |      Background timer executing every ``n`` seconds.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> class S(Service):\n",
      "     |          ...\n",
      "     |          ...     @Service.timer(1.0)\n",
      "     |          ...     async def background_timer(self):\n",
      "     |          ...         print('Waking up')\n",
      "     |  \n",
      "     |  transitions_to(flag: str) -> Callable from abc.ABCMeta\n",
      "     |      Decorate function to set and reset diagnostic flag.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  crashed\n",
      "     |  \n",
      "     |  label\n",
      "     |      Label used for graphs.\n",
      "     |  \n",
      "     |  shortlabel\n",
      "     |      Label used for logging.\n",
      "     |  \n",
      "     |  should_stop\n",
      "     |      Return :const:`True` if the service must stop.\n",
      "     |  \n",
      "     |  started\n",
      "     |      Return :const:`True` if the service was started.\n",
      "     |  \n",
      "     |  state\n",
      "     |      Service state - as a human readable string.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  beacon\n",
      "     |      Beacon used to track services in a dependency graph.\n",
      "     |  \n",
      "     |  crash_reason\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  Diag = <class 'mode.services.Diag'>\n",
      "     |      Service diagnostics.\n",
      "     |      \n",
      "     |      This can be used to track what your service is doing.\n",
      "     |      For example if your service is a Kafka consumer with a background\n",
      "     |      thread that commits the offset every 30 seconds, you may want to\n",
      "     |      see when this happens::\n",
      "     |      \n",
      "     |          DIAG_COMMITTING = 'committing'\n",
      "     |      \n",
      "     |          class Consumer(Service):\n",
      "     |      \n",
      "     |              @Service.task\n",
      "     |              async def _background_commit(self) -> None:\n",
      "     |                  while not self.should_stop:\n",
      "     |                      await self.sleep(30.0)\n",
      "     |                      self.diag.set_flag(DIAG_COMITTING)\n",
      "     |                      try:\n",
      "     |                          await self._consumer.commit()\n",
      "     |                      finally:\n",
      "     |                          self.diag.unset_flag(DIAG_COMMITTING)\n",
      "     |      \n",
      "     |      The above code is setting the flag manually, but you can also use\n",
      "     |      a decorator to accomplish the same thing::\n",
      "     |      \n",
      "     |          @Service.timer(30.0)\n",
      "     |          async def _background_commit(self) -> None:\n",
      "     |              await self.commit()\n",
      "     |      \n",
      "     |          @Service.transitions_with(DIAG_COMITTING)\n",
      "     |          async def commit(self) -> None:\n",
      "     |              await self._consumer.commit()\n",
      "     |  \n",
      "     |  abstract = False\n",
      "     |  \n",
      "     |  mundane_level = 'info'\n",
      "     |  \n",
      "     |  restart_count = 0\n",
      "     |  \n",
      "     |  shutdown_timeout = 60.0\n",
      "     |  \n",
      "     |  wait_for_shutdown = False\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mode.services.ServiceBase:\n",
      "     |  \n",
      "     |  async __aenter__(self) -> mode.types.services.ServiceT\n",
      "     |      Return `self` upon entering the runtime context.\n",
      "     |  \n",
      "     |  async __aexit__(self, exc_type: Type[BaseException] = None, exc_val: BaseException = None, exc_tb: traceback = None) -> Union[bool, NoneType]\n",
      "     |      Raise any exception triggered within the runtime context.\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from mode.services.ServiceBase:\n",
      "     |  \n",
      "     |  loop\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from mode.types.services.ServiceT:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.AbstractAsyncContextManager,)\n",
      "     |  \n",
      "     |  supervisor = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from contextlib.AbstractAsyncContextManager:\n",
      "     |  \n",
      "     |  __subclasshook__(C) from abc.ABCMeta\n",
      "     |      Abstract classes can override this to customize issubclass().\n",
      "     |      \n",
      "     |      This is invoked early on by abc.ABCMeta.__subclasscheck__().\n",
      "     |      It should return True, False or NotImplemented.  If it returns\n",
      "     |      NotImplemented, the normal algorithm is used.  Otherwise, it\n",
      "     |      overrides the normal algorithm (and the outcome is cached).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from abc.ABCMeta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mode.services.ServiceCallbacks:\n",
      "     |  \n",
      "     |  async on_first_start(self) -> None\n",
      "     |      Service started for the first time in this process.\n",
      "     |  \n",
      "     |  async on_restart(self) -> None\n",
      "     |      Service is being restarted.\n",
      "     |  \n",
      "     |  async on_shutdown(self) -> None\n",
      "     |      Service is being stopped/restarted.\n",
      "     |  \n",
      "     |  async on_start(self) -> None\n",
      "     |      Service is starting.\n",
      "     |  \n",
      "     |  async on_started(self) -> None\n",
      "     |      Service has started.\n",
      "     |  \n",
      "     |  async on_stop(self) -> None\n",
      "     |      Service is being stopped/restarted.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mode.utils.objects.KeywordReduce:\n",
      "     |  \n",
      "     |  __reduce__(self) -> Tuple\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __reduce_keywords__(self) -> Mapping\n",
      "    \n",
      "    class Record(faust.models.base.Model)\n",
      "     |  Record() -> None\n",
      "     |  \n",
      "     |  Describes a model type that is a record (Mapping).\n",
      "     |  \n",
      "     |  Examples:\n",
      "     |      >>> class LogEvent(Record, serializer='json'):\n",
      "     |      ...     severity: str\n",
      "     |      ...     message: str\n",
      "     |      ...     timestamp: float\n",
      "     |      ...     optional_field: str = 'default value'\n",
      "     |  \n",
      "     |      >>> event = LogEvent(\n",
      "     |      ...     severity='error',\n",
      "     |      ...     message='Broken pact',\n",
      "     |      ...     timestamp=666.0,\n",
      "     |      ... )\n",
      "     |  \n",
      "     |      >>> event.severity\n",
      "     |      'error'\n",
      "     |  \n",
      "     |      >>> serialized = event.dumps()\n",
      "     |      '{\"severity\": \"error\", \"message\": \"Broken pact\", \"timestamp\": 666.0}'\n",
      "     |  \n",
      "     |      >>> restored = LogEvent.loads(serialized)\n",
      "     |      <LogEvent: severity='error', message='Broken pact', timestamp=666.0>\n",
      "     |  \n",
      "     |      >>> # You can also subclass a Record to create a new record\n",
      "     |      >>> # with additional fields\n",
      "     |      >>> class RemoteLogEvent(LogEvent):\n",
      "     |      ...     url: str\n",
      "     |  \n",
      "     |      >>> # You can also refer to record fields and pass them around:\n",
      "     |      >>> LogEvent.severity\n",
      "     |      >>> <FieldDescriptor: LogEvent.severity (str)>\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Record\n",
      "     |      faust.models.base.Model\n",
      "     |      faust.types.models.ModelT\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, other: 'Record') -> bool\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __gt__(self, other: 'Record') -> bool\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__ = __abstract_init__(self) -> None\n",
      "     |  \n",
      "     |  __json__(self) -> Any\n",
      "     |  \n",
      "     |  __le__(self, other: 'Record') -> bool\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, other: 'Record') -> bool\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, other: Any) -> bool\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  asdict(self) -> Dict[str, Any]\n",
      "     |      Convert record to Python dictionary.\n",
      "     |  \n",
      "     |  to_representation(self) -> Mapping[str, Any]\n",
      "     |      Convert model to its Python generic counterpart.\n",
      "     |      \n",
      "     |      Records will be converted to dictionary.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  __init_subclass__(serializer: str = None, namespace: str = None, include_metadata: bool = None, isodates: bool = None, abstract: bool = False, allow_blessed_key: bool = None, decimals: bool = None, coerce: bool = None, coercions: MutableMapping[Union[Type, Tuple[Type, ...]], Callable[[Any], Any]] = None, polymorphic_fields: bool = None, validation: bool = None, date_parser: Callable[[Any], datetime.datetime] = None, lazy_creation: bool = False, **kwargs: Any) -> None from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  from_data(data: Mapping, *, preferred_type: Type[faust.types.models.ModelT] = None) -> 'Record' from builtins.type\n",
      "     |      Create model object from Python dictionary.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __is_abstract__ = True\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from faust.models.base.Model:\n",
      "     |  \n",
      "     |  __abstract_init__(self) -> None\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  derive(self, *objects: faust.types.models.ModelT, **fields: Any) -> faust.types.models.ModelT\n",
      "     |      Derive new model with certain fields changed.\n",
      "     |  \n",
      "     |  dumps(self, *, serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None) -> bytes\n",
      "     |      Serialize object to the target serialization format.\n",
      "     |  \n",
      "     |  is_valid(self) -> bool\n",
      "     |  \n",
      "     |  validate(self) -> List[faust.exceptions.ValidationError]\n",
      "     |  \n",
      "     |  validate_or_raise(self) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from faust.models.base.Model:\n",
      "     |  \n",
      "     |  loads(s: bytes, *, default_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None) -> faust.types.models.ModelT from builtins.type\n",
      "     |      Deserialize model object from bytes.\n",
      "     |      \n",
      "     |      Keyword Arguments:\n",
      "     |          serializer (CodecArg): Default serializer to use\n",
      "     |              if no custom serializer was set for this model subclass.\n",
      "     |  \n",
      "     |  make_final() -> None from builtins.type\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from faust.models.base.Model:\n",
      "     |  \n",
      "     |  validation_errors\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from faust.models.base.Model:\n",
      "     |  \n",
      "     |  __annotations__ = {'__is_abstract__': typing.ClassVar[bool], '_pending...\n",
      "     |  \n",
      "     |  __validation_errors__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from faust.types.models.ModelT:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from faust.types.models.ModelT:\n",
      "     |  \n",
      "     |  __evaluated_fields__ = None\n",
      "     |  \n",
      "     |  __is_model__ = True\n",
      "    \n",
      "    class SASLCredentials(Credentials)\n",
      "     |  SASLCredentials(*, username: str = None, password: str = None, ssl_context: ssl.SSLContext = None, mechanism: Union[str, faust.types.auth.SASLMechanism] = None) -> None\n",
      "     |  \n",
      "     |  Describe SASL credentials.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SASLCredentials\n",
      "     |      Credentials\n",
      "     |      faust.types.auth.CredentialsT\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *, username: str = None, password: str = None, ssl_context: ssl.SSLContext = None, mechanism: Union[str, faust.types.auth.SASLMechanism] = None) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {'mechanism': <enum 'SASLMechanism'>, 'password': ty...\n",
      "     |  \n",
      "     |  mechanism = <SASLMechanism.PLAIN: 'PLAIN'>\n",
      "     |  \n",
      "     |  protocol = <AuthProtocol.SASL_PLAINTEXT: 'SASL_PLAINTEXT'>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from faust.types.auth.CredentialsT:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class SSLCredentials(Credentials)\n",
      "     |  SSLCredentials(context: ssl.SSLContext = None, *, purpose: Any = None, cafile: Union[str, NoneType] = None, capath: Union[str, NoneType] = None, cadata: Union[str, NoneType] = None) -> None\n",
      "     |  \n",
      "     |  Describe SSL credentials/settings.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SSLCredentials\n",
      "     |      Credentials\n",
      "     |      faust.types.auth.CredentialsT\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, context: ssl.SSLContext = None, *, purpose: Any = None, cafile: Union[str, NoneType] = None, capath: Union[str, NoneType] = None, cadata: Union[str, NoneType] = None) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {'context': <class 'ssl.SSLContext'>}\n",
      "     |  \n",
      "     |  protocol = <AuthProtocol.SSL: 'SSL'>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from faust.types.auth.CredentialsT:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Schema(faust.types.serializers.SchemaT)\n",
      "     |  Schema(*args, **kwds)\n",
      "     |  \n",
      "     |  Abstract base class for generic types.\n",
      "     |  \n",
      "     |  A generic type is typically declared by inheriting from\n",
      "     |  this class parameterized with one or more type variables.\n",
      "     |  For example, a generic mapping type might be defined as::\n",
      "     |  \n",
      "     |    class Mapping(Generic[KT, VT]):\n",
      "     |        def __getitem__(self, key: KT) -> VT:\n",
      "     |            ...\n",
      "     |        # Etc.\n",
      "     |  \n",
      "     |  This class can then be used as follows::\n",
      "     |  \n",
      "     |    def lookup_name(mapping: Mapping[KT, VT], key: KT, default: VT) -> VT:\n",
      "     |        try:\n",
      "     |            return mapping[key]\n",
      "     |        except KeyError:\n",
      "     |            return default\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Schema\n",
      "     |      faust.types.serializers.SchemaT\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *, key_type: Union[Type[faust.types.models.ModelT], Type[bytes], Type[str]] = None, value_type: Union[Type[faust.types.models.ModelT], Type[bytes], Type[str]] = None, key_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, value_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, allow_empty: bool = None) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  compile(self, app: faust.types.app.AppT, *, on_key_decode_error: Callable[[Exception, faust.types.tuples.Message], Awaitable[NoneType]] = <function _noop_decode_error at 0x7fc52ad32af0>, on_value_decode_error: Callable[[Exception, faust.types.tuples.Message], Awaitable[NoneType]] = <function _noop_decode_error at 0x7fc52ad32af0>, default_propagate: bool = False) -> Callable[..., Awaitable[faust.types.events.EventT]]\n",
      "     |      Compile function used to decode event.\n",
      "     |  \n",
      "     |  async decode(self, app: faust.types.app.AppT, message: faust.types.tuples.Message, *, propagate: bool = False) -> faust.types.events.EventT\n",
      "     |      Decode message from topic (compiled function not cached).\n",
      "     |  \n",
      "     |  dumps_key(self, app: faust.types.app.AppT, key: Union[bytes, faust.types.core._ModelT, Any, NoneType], *, serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, headers: Union[List[Tuple[str, bytes]], MutableMapping[str, bytes], NoneType]) -> Tuple[Any, Union[List[Tuple[str, bytes]], MutableMapping[str, bytes], NoneType]]\n",
      "     |  \n",
      "     |  dumps_value(self, app: faust.types.app.AppT, value: Union[bytes, faust.types.core._ModelT, Any], *, serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, headers: Union[List[Tuple[str, bytes]], MutableMapping[str, bytes], NoneType]) -> Tuple[Any, Union[List[Tuple[str, bytes]], MutableMapping[str, bytes], NoneType]]\n",
      "     |  \n",
      "     |  loads_key(self, app: faust.types.app.AppT, message: faust.types.tuples.Message, *, loads: Callable = None, serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None) -> ~KT\n",
      "     |  \n",
      "     |  loads_value(self, app: faust.types.app.AppT, message: faust.types.tuples.Message, *, loads: Callable = None, serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None) -> ~VT\n",
      "     |  \n",
      "     |  on_dumps_key_prepare_headers(self, key: Union[bytes, faust.types.core._ModelT, Any], headers: Union[List[Tuple[str, bytes]], MutableMapping[str, bytes], NoneType]) -> Union[List[Tuple[str, bytes]], MutableMapping[str, bytes], NoneType]\n",
      "     |  \n",
      "     |  on_dumps_value_prepare_headers(self, value: Union[bytes, faust.types.core._ModelT, Any], headers: Union[List[Tuple[str, bytes]], MutableMapping[str, bytes], NoneType]) -> Union[List[Tuple[str, bytes]], MutableMapping[str, bytes], NoneType]\n",
      "     |  \n",
      "     |  update(self, *, key_type: Union[Type[faust.types.models.ModelT], Type[bytes], Type[str]] = None, value_type: Union[Type[faust.types.models.ModelT], Type[bytes], Type[str]] = None, key_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, value_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, allow_empty: bool = None) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from faust.types.serializers.SchemaT:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from faust.types.serializers.SchemaT:\n",
      "     |  \n",
      "     |  __annotations__ = {'allow_empty': <class 'bool'>, 'key_serializer': ty...\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[~KT, ~VT],)\n",
      "     |  \n",
      "     |  allow_empty = False\n",
      "     |  \n",
      "     |  key_serializer = None\n",
      "     |  \n",
      "     |  key_type = None\n",
      "     |  \n",
      "     |  value_serializer = None\n",
      "     |  \n",
      "     |  value_type = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Sensor(faust.types.sensors.SensorT, mode.services.Service)\n",
      "     |  Sensor(*args, **kwds)\n",
      "     |  \n",
      "     |  Base class for sensors.\n",
      "     |  \n",
      "     |  This sensor does not do anything at all, but can be subclassed\n",
      "     |  to create new monitors.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Sensor\n",
      "     |      faust.types.sensors.SensorT\n",
      "     |      faust.types.sensors.SensorInterfaceT\n",
      "     |      mode.services.Service\n",
      "     |      mode.services.ServiceBase\n",
      "     |      mode.types.services.ServiceT\n",
      "     |      contextlib.AbstractAsyncContextManager\n",
      "     |      abc.ABC\n",
      "     |      typing.Generic\n",
      "     |      mode.services.ServiceCallbacks\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  asdict(self) -> Mapping\n",
      "     |      Convert sensor state to dictionary.\n",
      "     |  \n",
      "     |  on_assignment_completed(self, assignor: faust.types.assignor.PartitionAssignorT, state: Dict) -> None\n",
      "     |      Partition assignor completed assignment.\n",
      "     |  \n",
      "     |  on_assignment_error(self, assignor: faust.types.assignor.PartitionAssignorT, state: Dict, exc: BaseException) -> None\n",
      "     |      Partition assignor did not complete assignor due to error.\n",
      "     |  \n",
      "     |  on_assignment_start(self, assignor: faust.types.assignor.PartitionAssignorT) -> Dict\n",
      "     |      Partition assignor is starting to assign partitions.\n",
      "     |  \n",
      "     |  on_commit_completed(self, consumer: faust.types.transports.ConsumerT, state: Any) -> None\n",
      "     |      Consumer finished committing topic offset.\n",
      "     |  \n",
      "     |  on_commit_initiated(self, consumer: faust.types.transports.ConsumerT) -> Any\n",
      "     |      Consumer is about to commit topic offset.\n",
      "     |  \n",
      "     |  on_message_in(self, tp: faust.types.tuples.TP, offset: int, message: faust.types.tuples.Message) -> None\n",
      "     |      Message received by a consumer.\n",
      "     |  \n",
      "     |  on_message_out(self, tp: faust.types.tuples.TP, offset: int, message: faust.types.tuples.Message) -> None\n",
      "     |      All streams finished processing message.\n",
      "     |  \n",
      "     |  on_rebalance_end(self, app: faust.types.app.AppT, state: Dict) -> None\n",
      "     |      Cluster rebalance fully completed (including recovery).\n",
      "     |  \n",
      "     |  on_rebalance_return(self, app: faust.types.app.AppT, state: Dict) -> None\n",
      "     |      Consumer replied assignment is done to broker.\n",
      "     |  \n",
      "     |  on_rebalance_start(self, app: faust.types.app.AppT) -> Dict\n",
      "     |      Cluster rebalance in progress.\n",
      "     |  \n",
      "     |  on_send_completed(self, producer: faust.types.transports.ProducerT, state: Any, metadata: faust.types.tuples.RecordMetadata) -> None\n",
      "     |      Message successfully sent.\n",
      "     |  \n",
      "     |  on_send_error(self, producer: faust.types.transports.ProducerT, exc: BaseException, state: Any) -> None\n",
      "     |      Error while sending message.\n",
      "     |  \n",
      "     |  on_send_initiated(self, producer: faust.types.transports.ProducerT, topic: str, message: faust.types.tuples.PendingMessage, keysize: int, valsize: int) -> Any\n",
      "     |      About to send a message.\n",
      "     |  \n",
      "     |  on_stream_event_in(self, tp: faust.types.tuples.TP, offset: int, stream: faust.types.streams.StreamT, event: faust.types.events.EventT) -> Union[Dict, NoneType]\n",
      "     |      Message sent to a stream as an event.\n",
      "     |  \n",
      "     |  on_stream_event_out(self, tp: faust.types.tuples.TP, offset: int, stream: faust.types.streams.StreamT, event: faust.types.events.EventT, state: Dict = None) -> None\n",
      "     |      Event was acknowledged by stream.\n",
      "     |      \n",
      "     |      Notes:\n",
      "     |          Acknowledged means a stream finished processing the event, but\n",
      "     |          given that multiple streams may be handling the same event,\n",
      "     |          the message cannot be committed before all streams have\n",
      "     |          processed it.  When all streams have acknowledged the event,\n",
      "     |          it will go through :meth:`on_message_out` just before offsets\n",
      "     |          are committed.\n",
      "     |  \n",
      "     |  on_table_del(self, table: faust.types.tables.CollectionT, key: Any) -> None\n",
      "     |      Key deleted from table.\n",
      "     |  \n",
      "     |  on_table_get(self, table: faust.types.tables.CollectionT, key: Any) -> None\n",
      "     |      Key retrieved from table.\n",
      "     |  \n",
      "     |  on_table_set(self, table: faust.types.tables.CollectionT, key: Any, value: Any) -> None\n",
      "     |      Value set for key in table.\n",
      "     |  \n",
      "     |  on_topic_buffer_full(self, topic: faust.types.topics.TopicT) -> None\n",
      "     |      Topic buffer full so conductor had to wait.\n",
      "     |  \n",
      "     |  on_web_request_end(self, app: faust.types.app.AppT, request: faust.web.base.Request, response: Union[faust.web.base.Response, NoneType], state: Dict, *, view: faust.web.views.View = None) -> None\n",
      "     |      Web server finished working on request.\n",
      "     |  \n",
      "     |  on_web_request_start(self, app: faust.types.app.AppT, request: faust.web.base.Request, *, view: faust.web.views.View = None) -> Dict\n",
      "     |      Web server started working on request.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  logger = <Logger faust.sensors.base (INFO)>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from faust.types.sensors.SensorT:\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from faust.types.sensors.SensorInterfaceT:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  __init__(self, *, beacon: mode.utils.types.trees.NodeT = None, loop: asyncio.events.AbstractEventLoop = None) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __post_init__(self) -> None\n",
      "     |      Additional user initialization.\n",
      "     |  \n",
      "     |  async add_async_context(self, context: AbstractAsyncContextManager) -> Any\n",
      "     |  \n",
      "     |  add_context(self, context: AbstractContextManager) -> Any\n",
      "     |  \n",
      "     |  add_dependency(self, service: mode.types.services.ServiceT) -> mode.types.services.ServiceT\n",
      "     |      Add dependency to other service.\n",
      "     |      \n",
      "     |      The service will be started/stopped with this service.\n",
      "     |  \n",
      "     |  add_future(self, coro: Awaitable) -> _asyncio.Future\n",
      "     |      Add relationship to asyncio.Future.\n",
      "     |      \n",
      "     |      The future will be joined when this service is stopped.\n",
      "     |  \n",
      "     |  async add_runtime_dependency(self, service: mode.types.services.ServiceT) -> mode.types.services.ServiceT\n",
      "     |  \n",
      "     |  async crash(self, reason: BaseException) -> None\n",
      "     |      Crash the service and all child services.\n",
      "     |  \n",
      "     |  async itertimer(self, interval: Union[datetime.timedelta, float, str], *, max_drift_correction: float = 0.1, loop: asyncio.events.AbstractEventLoop = None, sleep: Callable[..., Awaitable] = None, clock: Callable[[], float] = <built-in function perf_counter>, name: str = '') -> AsyncIterator[float]\n",
      "     |      Sleep ``interval`` seconds for every iteration.\n",
      "     |      \n",
      "     |      This is an async iterator that takes advantage\n",
      "     |      of :func:`~mode.timers.Timer` to monitor drift and timer\n",
      "     |      oerlap.\n",
      "     |      \n",
      "     |      Uses ``Service.sleep`` so exits fast when the service is\n",
      "     |      stopped.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          Will sleep the full `interval` seconds before returning\n",
      "     |          from first iteration.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |          >>> async for sleep_time in self.itertimer(1.0):\n",
      "     |          ...   print('another second passed, just woke up...')\n",
      "     |          ...   await perform_some_http_request()\n",
      "     |  \n",
      "     |  async join_services(self, services: Sequence[mode.types.services.ServiceT]) -> None\n",
      "     |  \n",
      "     |  async maybe_start(self) -> bool\n",
      "     |      Start the service, if it has not already been started.\n",
      "     |  \n",
      "     |  on_init(self) -> None\n",
      "     |  \n",
      "     |  on_init_dependencies(self) -> Iterable[mode.types.services.ServiceT]\n",
      "     |      Return list of service dependencies for this service.\n",
      "     |  \n",
      "     |  async remove_dependency(self, service: mode.types.services.ServiceT) -> mode.types.services.ServiceT\n",
      "     |      Stop and remove dependency of this service.\n",
      "     |  \n",
      "     |  async restart(self) -> None\n",
      "     |      Restart this service.\n",
      "     |  \n",
      "     |  service_reset(self) -> None\n",
      "     |  \n",
      "     |  set_shutdown(self) -> None\n",
      "     |      Set the shutdown signal.\n",
      "     |      \n",
      "     |      Notes:\n",
      "     |          If :attr:`wait_for_shutdown` is set, stopping the service\n",
      "     |          will wait for this flag to be set.\n",
      "     |  \n",
      "     |  async sleep(self, n: Union[datetime.timedelta, float, str], *, loop: asyncio.events.AbstractEventLoop = None) -> None\n",
      "     |      Sleep for ``n`` seconds, or until service stopped.\n",
      "     |  \n",
      "     |  async start(self) -> None\n",
      "     |  \n",
      "     |  async stop(self) -> None\n",
      "     |      Stop the service.\n",
      "     |  \n",
      "     |  async transition_with(self, flag: str, fut: Awaitable, *args: Any, **kwargs: Any) -> Any\n",
      "     |  \n",
      "     |  async wait(self, *coros: Union[_asyncio.Future, Generator[Any, NoneType, Any], Awaitable, asyncio.locks.Event, mode.utils.locks.Event], timeout: Union[datetime.timedelta, float, str] = None) -> mode.services.WaitResult\n",
      "     |      Wait for coroutines to complete, or until the service stops.\n",
      "     |  \n",
      "     |  async wait_first(self, *coros: Union[_asyncio.Future, Generator[Any, NoneType, Any], Awaitable, asyncio.locks.Event, mode.utils.locks.Event], timeout: Union[datetime.timedelta, float, str] = None) -> mode.services.WaitResults\n",
      "     |  \n",
      "     |  async wait_for_stopped(self, *coros: Union[_asyncio.Future, Generator[Any, NoneType, Any], Awaitable, asyncio.locks.Event, mode.utils.locks.Event], timeout: Union[datetime.timedelta, float, str] = None) -> bool\n",
      "     |  \n",
      "     |  async wait_many(self, coros: Iterable[Union[_asyncio.Future, Generator[Any, NoneType, Any], Awaitable, asyncio.locks.Event, mode.utils.locks.Event]], *, timeout: Union[datetime.timedelta, float, str] = None) -> mode.services.WaitResult\n",
      "     |  \n",
      "     |  async wait_until_stopped(self) -> None\n",
      "     |      Wait until the service is signalled to stop.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  __init_subclass__() -> None from abc.ABCMeta\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  from_awaitable(coro: Awaitable, *, name: str = None, **kwargs: Any) -> mode.types.services.ServiceT from abc.ABCMeta\n",
      "     |  \n",
      "     |  task(fun: Callable[[Any], Awaitable[NoneType]]) -> mode.services.ServiceTask from abc.ABCMeta\n",
      "     |      Decorate function to be used as background task.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> class S(Service):\n",
      "     |          ...\n",
      "     |          ...     @Service.task\n",
      "     |          ...     async def background_task(self):\n",
      "     |          ...         while not self.should_stop:\n",
      "     |          ...             await self.sleep(1.0)\n",
      "     |          ...             print('Waking up')\n",
      "     |  \n",
      "     |  timer(interval: Union[datetime.timedelta, float, str]) -> Callable[[Callable], mode.services.ServiceTask] from abc.ABCMeta\n",
      "     |      Background timer executing every ``n`` seconds.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> class S(Service):\n",
      "     |          ...\n",
      "     |          ...     @Service.timer(1.0)\n",
      "     |          ...     async def background_timer(self):\n",
      "     |          ...         print('Waking up')\n",
      "     |  \n",
      "     |  transitions_to(flag: str) -> Callable from abc.ABCMeta\n",
      "     |      Decorate function to set and reset diagnostic flag.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  crashed\n",
      "     |  \n",
      "     |  label\n",
      "     |      Label used for graphs.\n",
      "     |  \n",
      "     |  shortlabel\n",
      "     |      Label used for logging.\n",
      "     |  \n",
      "     |  should_stop\n",
      "     |      Return :const:`True` if the service must stop.\n",
      "     |  \n",
      "     |  started\n",
      "     |      Return :const:`True` if the service was started.\n",
      "     |  \n",
      "     |  state\n",
      "     |      Service state - as a human readable string.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  beacon\n",
      "     |      Beacon used to track services in a dependency graph.\n",
      "     |  \n",
      "     |  crash_reason\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  Diag = <class 'mode.services.Diag'>\n",
      "     |      Service diagnostics.\n",
      "     |      \n",
      "     |      This can be used to track what your service is doing.\n",
      "     |      For example if your service is a Kafka consumer with a background\n",
      "     |      thread that commits the offset every 30 seconds, you may want to\n",
      "     |      see when this happens::\n",
      "     |      \n",
      "     |          DIAG_COMMITTING = 'committing'\n",
      "     |      \n",
      "     |          class Consumer(Service):\n",
      "     |      \n",
      "     |              @Service.task\n",
      "     |              async def _background_commit(self) -> None:\n",
      "     |                  while not self.should_stop:\n",
      "     |                      await self.sleep(30.0)\n",
      "     |                      self.diag.set_flag(DIAG_COMITTING)\n",
      "     |                      try:\n",
      "     |                          await self._consumer.commit()\n",
      "     |                      finally:\n",
      "     |                          self.diag.unset_flag(DIAG_COMMITTING)\n",
      "     |      \n",
      "     |      The above code is setting the flag manually, but you can also use\n",
      "     |      a decorator to accomplish the same thing::\n",
      "     |      \n",
      "     |          @Service.timer(30.0)\n",
      "     |          async def _background_commit(self) -> None:\n",
      "     |              await self.commit()\n",
      "     |      \n",
      "     |          @Service.transitions_with(DIAG_COMITTING)\n",
      "     |          async def commit(self) -> None:\n",
      "     |              await self._consumer.commit()\n",
      "     |  \n",
      "     |  __annotations__ = {'Diag': typing.Type[mode.types.services.DiagT], '_b...\n",
      "     |  \n",
      "     |  abstract = False\n",
      "     |  \n",
      "     |  mundane_level = 'info'\n",
      "     |  \n",
      "     |  restart_count = 0\n",
      "     |  \n",
      "     |  shutdown_timeout = 60.0\n",
      "     |  \n",
      "     |  wait_for_shutdown = False\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mode.services.ServiceBase:\n",
      "     |  \n",
      "     |  async __aenter__(self) -> mode.types.services.ServiceT\n",
      "     |      Return `self` upon entering the runtime context.\n",
      "     |  \n",
      "     |  async __aexit__(self, exc_type: Type[BaseException] = None, exc_val: BaseException = None, exc_tb: traceback = None) -> Union[bool, NoneType]\n",
      "     |      Raise any exception triggered within the runtime context.\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from mode.services.ServiceBase:\n",
      "     |  \n",
      "     |  loop\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from mode.types.services.ServiceT:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.AbstractAsyncContextManager,)\n",
      "     |  \n",
      "     |  supervisor = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from contextlib.AbstractAsyncContextManager:\n",
      "     |  \n",
      "     |  __subclasshook__(C) from abc.ABCMeta\n",
      "     |      Abstract classes can override this to customize issubclass().\n",
      "     |      \n",
      "     |      This is invoked early on by abc.ABCMeta.__subclasscheck__().\n",
      "     |      It should return True, False or NotImplemented.  If it returns\n",
      "     |      NotImplemented, the normal algorithm is used.  Otherwise, it\n",
      "     |      overrides the normal algorithm (and the outcome is cached).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from abc.ABCMeta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mode.services.ServiceCallbacks:\n",
      "     |  \n",
      "     |  async on_first_start(self) -> None\n",
      "     |      Service started for the first time in this process.\n",
      "     |  \n",
      "     |  async on_restart(self) -> None\n",
      "     |      Service is being restarted.\n",
      "     |  \n",
      "     |  async on_shutdown(self) -> None\n",
      "     |      Service is being stopped/restarted.\n",
      "     |  \n",
      "     |  async on_start(self) -> None\n",
      "     |      Service is starting.\n",
      "     |  \n",
      "     |  async on_started(self) -> None\n",
      "     |      Service has started.\n",
      "     |  \n",
      "     |  async on_stop(self) -> None\n",
      "     |      Service is being stopped/restarted.\n",
      "    \n",
      "    class Service(ServiceBase, ServiceCallbacks)\n",
      "     |  Service(*args, **kwds)\n",
      "     |  \n",
      "     |  An asyncio service that can be started/stopped/restarted.\n",
      "     |  \n",
      "     |  Keyword Arguments:\n",
      "     |      beacon (NodeT): Beacon used to track services in a graph.\n",
      "     |      loop (asyncio.AbstractEventLoop): Event loop object.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Service\n",
      "     |      ServiceBase\n",
      "     |      mode.types.services.ServiceT\n",
      "     |      contextlib.AbstractAsyncContextManager\n",
      "     |      abc.ABC\n",
      "     |      typing.Generic\n",
      "     |      ServiceCallbacks\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *, beacon: mode.utils.types.trees.NodeT = None, loop: asyncio.events.AbstractEventLoop = None) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __post_init__(self) -> None\n",
      "     |      Additional user initialization.\n",
      "     |  \n",
      "     |  async add_async_context(self, context: AbstractAsyncContextManager) -> Any\n",
      "     |  \n",
      "     |  add_context(self, context: AbstractContextManager) -> Any\n",
      "     |  \n",
      "     |  add_dependency(self, service: mode.types.services.ServiceT) -> mode.types.services.ServiceT\n",
      "     |      Add dependency to other service.\n",
      "     |      \n",
      "     |      The service will be started/stopped with this service.\n",
      "     |  \n",
      "     |  add_future(self, coro: Awaitable) -> _asyncio.Future\n",
      "     |      Add relationship to asyncio.Future.\n",
      "     |      \n",
      "     |      The future will be joined when this service is stopped.\n",
      "     |  \n",
      "     |  async add_runtime_dependency(self, service: mode.types.services.ServiceT) -> mode.types.services.ServiceT\n",
      "     |  \n",
      "     |  async crash(self, reason: BaseException) -> None\n",
      "     |      Crash the service and all child services.\n",
      "     |  \n",
      "     |  async itertimer(self, interval: Union[datetime.timedelta, float, str], *, max_drift_correction: float = 0.1, loop: asyncio.events.AbstractEventLoop = None, sleep: Callable[..., Awaitable] = None, clock: Callable[[], float] = <built-in function perf_counter>, name: str = '') -> AsyncIterator[float]\n",
      "     |      Sleep ``interval`` seconds for every iteration.\n",
      "     |      \n",
      "     |      This is an async iterator that takes advantage\n",
      "     |      of :func:`~mode.timers.Timer` to monitor drift and timer\n",
      "     |      oerlap.\n",
      "     |      \n",
      "     |      Uses ``Service.sleep`` so exits fast when the service is\n",
      "     |      stopped.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          Will sleep the full `interval` seconds before returning\n",
      "     |          from first iteration.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |          >>> async for sleep_time in self.itertimer(1.0):\n",
      "     |          ...   print('another second passed, just woke up...')\n",
      "     |          ...   await perform_some_http_request()\n",
      "     |  \n",
      "     |  async join_services(self, services: Sequence[mode.types.services.ServiceT]) -> None\n",
      "     |  \n",
      "     |  async maybe_start(self) -> bool\n",
      "     |      Start the service, if it has not already been started.\n",
      "     |  \n",
      "     |  on_init(self) -> None\n",
      "     |  \n",
      "     |  on_init_dependencies(self) -> Iterable[mode.types.services.ServiceT]\n",
      "     |      Return list of service dependencies for this service.\n",
      "     |  \n",
      "     |  async remove_dependency(self, service: mode.types.services.ServiceT) -> mode.types.services.ServiceT\n",
      "     |      Stop and remove dependency of this service.\n",
      "     |  \n",
      "     |  async restart(self) -> None\n",
      "     |      Restart this service.\n",
      "     |  \n",
      "     |  service_reset(self) -> None\n",
      "     |  \n",
      "     |  set_shutdown(self) -> None\n",
      "     |      Set the shutdown signal.\n",
      "     |      \n",
      "     |      Notes:\n",
      "     |          If :attr:`wait_for_shutdown` is set, stopping the service\n",
      "     |          will wait for this flag to be set.\n",
      "     |  \n",
      "     |  async sleep(self, n: Union[datetime.timedelta, float, str], *, loop: asyncio.events.AbstractEventLoop = None) -> None\n",
      "     |      Sleep for ``n`` seconds, or until service stopped.\n",
      "     |  \n",
      "     |  async start(self) -> None\n",
      "     |  \n",
      "     |  async stop(self) -> None\n",
      "     |      Stop the service.\n",
      "     |  \n",
      "     |  async transition_with(self, flag: str, fut: Awaitable, *args: Any, **kwargs: Any) -> Any\n",
      "     |  \n",
      "     |  async wait(self, *coros: Union[_asyncio.Future, Generator[Any, NoneType, Any], Awaitable, asyncio.locks.Event, mode.utils.locks.Event], timeout: Union[datetime.timedelta, float, str] = None) -> mode.services.WaitResult\n",
      "     |      Wait for coroutines to complete, or until the service stops.\n",
      "     |  \n",
      "     |  async wait_first(self, *coros: Union[_asyncio.Future, Generator[Any, NoneType, Any], Awaitable, asyncio.locks.Event, mode.utils.locks.Event], timeout: Union[datetime.timedelta, float, str] = None) -> mode.services.WaitResults\n",
      "     |  \n",
      "     |  async wait_for_stopped(self, *coros: Union[_asyncio.Future, Generator[Any, NoneType, Any], Awaitable, asyncio.locks.Event, mode.utils.locks.Event], timeout: Union[datetime.timedelta, float, str] = None) -> bool\n",
      "     |  \n",
      "     |  async wait_many(self, coros: Iterable[Union[_asyncio.Future, Generator[Any, NoneType, Any], Awaitable, asyncio.locks.Event, mode.utils.locks.Event]], *, timeout: Union[datetime.timedelta, float, str] = None) -> mode.services.WaitResult\n",
      "     |  \n",
      "     |  async wait_until_stopped(self) -> None\n",
      "     |      Wait until the service is signalled to stop.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  __init_subclass__() -> None from abc.ABCMeta\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  from_awaitable(coro: Awaitable, *, name: str = None, **kwargs: Any) -> mode.types.services.ServiceT from abc.ABCMeta\n",
      "     |  \n",
      "     |  task(fun: Callable[[Any], Awaitable[NoneType]]) -> mode.services.ServiceTask from abc.ABCMeta\n",
      "     |      Decorate function to be used as background task.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> class S(Service):\n",
      "     |          ...\n",
      "     |          ...     @Service.task\n",
      "     |          ...     async def background_task(self):\n",
      "     |          ...         while not self.should_stop:\n",
      "     |          ...             await self.sleep(1.0)\n",
      "     |          ...             print('Waking up')\n",
      "     |  \n",
      "     |  timer(interval: Union[datetime.timedelta, float, str]) -> Callable[[Callable], mode.services.ServiceTask] from abc.ABCMeta\n",
      "     |      Background timer executing every ``n`` seconds.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> class S(Service):\n",
      "     |          ...\n",
      "     |          ...     @Service.timer(1.0)\n",
      "     |          ...     async def background_timer(self):\n",
      "     |          ...         print('Waking up')\n",
      "     |  \n",
      "     |  transitions_to(flag: str) -> Callable from abc.ABCMeta\n",
      "     |      Decorate function to set and reset diagnostic flag.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  crashed\n",
      "     |  \n",
      "     |  label\n",
      "     |      Label used for graphs.\n",
      "     |  \n",
      "     |  shortlabel\n",
      "     |      Label used for logging.\n",
      "     |  \n",
      "     |  should_stop\n",
      "     |      Return :const:`True` if the service must stop.\n",
      "     |  \n",
      "     |  started\n",
      "     |      Return :const:`True` if the service was started.\n",
      "     |  \n",
      "     |  state\n",
      "     |      Service state - as a human readable string.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  beacon\n",
      "     |      Beacon used to track services in a dependency graph.\n",
      "     |  \n",
      "     |  crash_reason\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  Diag = <class 'mode.services.Diag'>\n",
      "     |      Service diagnostics.\n",
      "     |      \n",
      "     |      This can be used to track what your service is doing.\n",
      "     |      For example if your service is a Kafka consumer with a background\n",
      "     |      thread that commits the offset every 30 seconds, you may want to\n",
      "     |      see when this happens::\n",
      "     |      \n",
      "     |          DIAG_COMMITTING = 'committing'\n",
      "     |      \n",
      "     |          class Consumer(Service):\n",
      "     |      \n",
      "     |              @Service.task\n",
      "     |              async def _background_commit(self) -> None:\n",
      "     |                  while not self.should_stop:\n",
      "     |                      await self.sleep(30.0)\n",
      "     |                      self.diag.set_flag(DIAG_COMITTING)\n",
      "     |                      try:\n",
      "     |                          await self._consumer.commit()\n",
      "     |                      finally:\n",
      "     |                          self.diag.unset_flag(DIAG_COMMITTING)\n",
      "     |      \n",
      "     |      The above code is setting the flag manually, but you can also use\n",
      "     |      a decorator to accomplish the same thing::\n",
      "     |      \n",
      "     |          @Service.timer(30.0)\n",
      "     |          async def _background_commit(self) -> None:\n",
      "     |              await self.commit()\n",
      "     |      \n",
      "     |          @Service.transitions_with(DIAG_COMITTING)\n",
      "     |          async def commit(self) -> None:\n",
      "     |              await self._consumer.commit()\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'Diag': typing.Type[mode.types.services.DiagT], '_b...\n",
      "     |  \n",
      "     |  abstract = False\n",
      "     |  \n",
      "     |  logger = <Logger mode.services (INFO)>\n",
      "     |  \n",
      "     |  mundane_level = 'info'\n",
      "     |  \n",
      "     |  restart_count = 0\n",
      "     |  \n",
      "     |  shutdown_timeout = 60.0\n",
      "     |  \n",
      "     |  wait_for_shutdown = False\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ServiceBase:\n",
      "     |  \n",
      "     |  async __aenter__(self) -> mode.types.services.ServiceT\n",
      "     |      Return `self` upon entering the runtime context.\n",
      "     |  \n",
      "     |  async __aexit__(self, exc_type: Type[BaseException] = None, exc_val: BaseException = None, exc_tb: traceback = None) -> Union[bool, NoneType]\n",
      "     |      Raise any exception triggered within the runtime context.\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ServiceBase:\n",
      "     |  \n",
      "     |  loop\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from ServiceBase:\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from mode.types.services.ServiceT:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.AbstractAsyncContextManager,)\n",
      "     |  \n",
      "     |  supervisor = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from contextlib.AbstractAsyncContextManager:\n",
      "     |  \n",
      "     |  __subclasshook__(C) from abc.ABCMeta\n",
      "     |      Abstract classes can override this to customize issubclass().\n",
      "     |      \n",
      "     |      This is invoked early on by abc.ABCMeta.__subclasscheck__().\n",
      "     |      It should return True, False or NotImplemented.  If it returns\n",
      "     |      NotImplemented, the normal algorithm is used.  Otherwise, it\n",
      "     |      overrides the normal algorithm (and the outcome is cached).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from contextlib.AbstractAsyncContextManager:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from abc.ABCMeta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ServiceCallbacks:\n",
      "     |  \n",
      "     |  async on_first_start(self) -> None\n",
      "     |      Service started for the first time in this process.\n",
      "     |  \n",
      "     |  async on_restart(self) -> None\n",
      "     |      Service is being restarted.\n",
      "     |  \n",
      "     |  async on_shutdown(self) -> None\n",
      "     |      Service is being stopped/restarted.\n",
      "     |  \n",
      "     |  async on_start(self) -> None\n",
      "     |      Service is starting.\n",
      "     |  \n",
      "     |  async on_started(self) -> None\n",
      "     |      Service has started.\n",
      "     |  \n",
      "     |  async on_stop(self) -> None\n",
      "     |      Service is being stopped/restarted.\n",
      "    \n",
      "    class ServiceT(contextlib.AbstractAsyncContextManager, typing.Generic)\n",
      "     |  ServiceT(*args, **kwds)\n",
      "     |  \n",
      "     |  Abstract type for an asynchronous service that can be started/stopped.\n",
      "     |  \n",
      "     |  See Also:\n",
      "     |      :class:`mode.Service`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ServiceT\n",
      "     |      contextlib.AbstractAsyncContextManager\n",
      "     |      abc.ABC\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *, beacon: mode.utils.types.trees.NodeT = None, loop: asyncio.events.AbstractEventLoop = None) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  async add_async_context(self, context: AbstractAsyncContextManager) -> Any\n",
      "     |  \n",
      "     |  add_context(self, context: AbstractContextManager) -> Any\n",
      "     |  \n",
      "     |  add_dependency(self, service: 'ServiceT') -> 'ServiceT'\n",
      "     |  \n",
      "     |  async add_runtime_dependency(self, service: 'ServiceT') -> 'ServiceT'\n",
      "     |  \n",
      "     |  async crash(self, reason: BaseException) -> None\n",
      "     |  \n",
      "     |  async maybe_start(self) -> bool\n",
      "     |  \n",
      "     |  async restart(self) -> None\n",
      "     |  \n",
      "     |  service_reset(self) -> None\n",
      "     |  \n",
      "     |  set_shutdown(self) -> None\n",
      "     |  \n",
      "     |  async start(self) -> None\n",
      "     |  \n",
      "     |  async stop(self) -> None\n",
      "     |  \n",
      "     |  async wait_until_stopped(self) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  crashed\n",
      "     |  \n",
      "     |  label\n",
      "     |  \n",
      "     |  shortlabel\n",
      "     |  \n",
      "     |  should_stop\n",
      "     |  \n",
      "     |  started\n",
      "     |  \n",
      "     |  state\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  beacon\n",
      "     |  \n",
      "     |  crash_reason\n",
      "     |  \n",
      "     |  loop\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset({'__aexit__', '__init__', '_crash', '_...\n",
      "     |  \n",
      "     |  __annotations__ = {'Diag': typing.Type[mode.types.services.DiagT], '_l...\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.AbstractAsyncContextManager,)\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  restart_count = 0\n",
      "     |  \n",
      "     |  supervisor = None\n",
      "     |  \n",
      "     |  wait_for_shutdown = False\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from contextlib.AbstractAsyncContextManager:\n",
      "     |  \n",
      "     |  async __aenter__(self)\n",
      "     |      Return `self` upon entering the runtime context.\n",
      "     |  \n",
      "     |  async __aexit__(self, exc_type, exc_value, traceback)\n",
      "     |      Raise any exception triggered within the runtime context.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from contextlib.AbstractAsyncContextManager:\n",
      "     |  \n",
      "     |  __subclasshook__(C) from abc.ABCMeta\n",
      "     |      Abstract classes can override this to customize issubclass().\n",
      "     |      \n",
      "     |      This is invoked early on by abc.ABCMeta.__subclasscheck__().\n",
      "     |      It should return True, False or NotImplemented.  If it returns\n",
      "     |      NotImplemented, the normal algorithm is used.  Otherwise, it\n",
      "     |      overrides the normal algorithm (and the outcome is cached).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from contextlib.AbstractAsyncContextManager:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from abc.ABCMeta\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from abc.ABCMeta\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class SetGlobalTable(SetTable, faust.types.tables.GlobalTableT)\n",
      "     |  SetGlobalTable(*args, **kwds)\n",
      "     |  \n",
      "     |  Table that maintains a dictionary of sets.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SetGlobalTable\n",
      "     |      SetTable\n",
      "     |      faust.tables.table.Table\n",
      "     |      faust.types.tables.GlobalTableT\n",
      "     |      faust.types.tables.TableT\n",
      "     |      faust.tables.base.Collection\n",
      "     |      mode.services.Service\n",
      "     |      mode.services.ServiceBase\n",
      "     |      faust.types.tables.CollectionT\n",
      "     |      mode.types.services.ServiceT\n",
      "     |      contextlib.AbstractAsyncContextManager\n",
      "     |      faust.types.streams.JoinableT\n",
      "     |      abc.ABC\n",
      "     |      mode.utils.collections.ManagedUserDict\n",
      "     |      mode.utils.collections.FastUserDict\n",
      "     |      collections.abc.MutableMapping\n",
      "     |      collections.abc.Mapping\n",
      "     |      collections.abc.Collection\n",
      "     |      collections.abc.Sized\n",
      "     |      collections.abc.Iterable\n",
      "     |      collections.abc.Container\n",
      "     |      typing.Generic\n",
      "     |      mode.services.ServiceCallbacks\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  logger = <Logger faust.tables.sets (INFO)>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from SetTable:\n",
      "     |  \n",
      "     |  __getitem__(self, key: ~KT) -> faust.tables.sets.ChangeloggedSet[~VT]\n",
      "     |  \n",
      "     |  __init__(self, app: faust.types.app.AppT, *, start_manager: bool = False, manager_topic_name: str = None, manager_topic_suffix: str = None, **kwargs: Any) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  async on_start(self) -> None\n",
      "     |      Call when set table starts.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from SetTable:\n",
      "     |  \n",
      "     |  Manager = <class 'faust.tables.sets.SetTableManager'>\n",
      "     |      Manager used to perform operations on :class:`SetTable`.\n",
      "     |      \n",
      "     |      Used when set table is configured with ``SetTable('name',\n",
      "     |      start_manager=True)``.\n",
      "     |      \n",
      "     |      The workers will start an additional agent used to process\n",
      "     |      incoming set operations, and you can communicate with this\n",
      "     |      agent to modify your sets.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |          >>> set_table = SetTable('sets', start_manager=True)\n",
      "     |      \n",
      "     |          >>> await set_table.manager.add('active_orders', Order)\n",
      "     |          >>> await set_table.manager.discard('active_orders', Order)\n",
      "     |      \n",
      "     |      The manager methods can be used from HTTP views and other agents\n",
      "     |      to safely route set operations to the correct worker.\n",
      "     |  \n",
      "     |  WindowWrapper = <class 'faust.tables.sets.SetWindowWrapper'>\n",
      "     |      Window wrapper for sets.\n",
      "     |  \n",
      "     |  __annotations__ = {'Manager': typing.ClassVar[typing.Type[faust.tables...\n",
      "     |  \n",
      "     |  __orig_bases__ = (faust.tables.table.Table[~KT, faust.tables.sets.Chan...\n",
      "     |  \n",
      "     |  manager_topic_suffix = '-setmanager'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from faust.tables.table.Table:\n",
      "     |  \n",
      "     |  __missing__(self, key: ~KT) -> ~VT\n",
      "     |  \n",
      "     |  as_ansitable(self, title: str = '{table.name}', **kwargs: Any) -> str\n",
      "     |      Draw table as a a terminal ANSI table.\n",
      "     |  \n",
      "     |  hopping(self, size: Union[datetime.timedelta, float, str], step: Union[datetime.timedelta, float, str], expires: Union[datetime.timedelta, float, str] = None, key_index: bool = False) -> faust.types.tables.WindowWrapperT\n",
      "     |      Wrap table in a hopping window.\n",
      "     |  \n",
      "     |  on_key_del(self, key: ~KT) -> None\n",
      "     |      Call when a key in this table is removed.\n",
      "     |  \n",
      "     |  on_key_get(self, key: ~KT) -> None\n",
      "     |      Call when the value for a key in this table is retrieved.\n",
      "     |  \n",
      "     |  on_key_set(self, key: ~KT, value: ~VT) -> None\n",
      "     |      Call when the value for a key in this table is set.\n",
      "     |  \n",
      "     |  tumbling(self, size: Union[datetime.timedelta, float, str], expires: Union[datetime.timedelta, float, str] = None, key_index: bool = False) -> faust.types.tables.WindowWrapperT\n",
      "     |      Wrap table in a tumbling window.\n",
      "     |  \n",
      "     |  using_window(self, window: faust.types.windows.WindowT, *, key_index: bool = False) -> faust.types.tables.WindowWrapperT\n",
      "     |      Wrap table using a specific window type.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from faust.types.tables.GlobalTableT:\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from faust.tables.base.Collection:\n",
      "     |  \n",
      "     |  __and__(self, other: Any) -> Any\n",
      "     |  \n",
      "     |  __copy__(self) -> Any\n",
      "     |  \n",
      "     |  __hash__(self) -> int\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  apply_changelog_batch(self, batch: Iterable[faust.types.events.EventT]) -> None\n",
      "     |      Apply batch of events from changelog topic local table storage.\n",
      "     |  \n",
      "     |  async call_recover_callbacks(self) -> None\n",
      "     |      Call any configured recovery callbacks after rebalancing.\n",
      "     |  \n",
      "     |  clone(self, **kwargs: Any) -> Any\n",
      "     |      Clone table instance.\n",
      "     |  \n",
      "     |  combine(self, *nodes: faust.types.streams.JoinableT, **kwargs: Any) -> faust.types.streams.StreamT\n",
      "     |      Combine tables and streams.\n",
      "     |  \n",
      "     |  contribute_to_stream(self, active: faust.types.streams.StreamT) -> None\n",
      "     |      Contribute table to stream join.\n",
      "     |  \n",
      "     |  info(self) -> Mapping[str, Any]\n",
      "     |      Return table attributes as dictionary.\n",
      "     |  \n",
      "     |  inner_join(self, *fields: faust.types.models.FieldDescriptorT) -> faust.types.streams.StreamT\n",
      "     |      Inner join of this table and another stream/table.\n",
      "     |  \n",
      "     |  join(self, *fields: faust.types.models.FieldDescriptorT) -> faust.types.streams.StreamT\n",
      "     |      Right join of this table and another stream/table.\n",
      "     |  \n",
      "     |  left_join(self, *fields: faust.types.models.FieldDescriptorT) -> faust.types.streams.StreamT\n",
      "     |      Left join of this table and another stream/table.\n",
      "     |  \n",
      "     |  async need_active_standby_for(self, tp: faust.types.tuples.TP) -> bool\n",
      "     |      Return :const:`False` if we have access to partition data.\n",
      "     |  \n",
      "     |  async on_changelog_event(self, event: faust.types.events.EventT) -> None\n",
      "     |      Call when a new changelog event is received.\n",
      "     |  \n",
      "     |  async on_rebalance(self, assigned: Set[faust.types.tuples.TP], revoked: Set[faust.types.tuples.TP], newly_assigned: Set[faust.types.tuples.TP]) -> None\n",
      "     |      Call when cluster is rebalancing.\n",
      "     |  \n",
      "     |  on_recover(self, fun: Callable[[], Awaitable[NoneType]]) -> Callable[[], Awaitable[NoneType]]\n",
      "     |      Add function as callback to be called on table recovery.\n",
      "     |  \n",
      "     |  async on_recovery_completed(self, active_tps: Set[faust.types.tuples.TP], standby_tps: Set[faust.types.tuples.TP]) -> None\n",
      "     |      Call when recovery has completed after rebalancing.\n",
      "     |  \n",
      "     |  on_window_close(self, key: Any, value: Any) -> None\n",
      "     |  \n",
      "     |  outer_join(self, *fields: faust.types.models.FieldDescriptorT) -> faust.types.streams.StreamT\n",
      "     |      Outer join of this table and another stream/table.\n",
      "     |  \n",
      "     |  partition_for_key(self, key: Any) -> Union[int, NoneType]\n",
      "     |      Return partition number for table key.\n",
      "     |      \n",
      "     |      Always returns :const:`None` when :attr:`use_partitioner`\n",
      "     |      is enabled.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Optional[int]: specific partition or :const:`None` if\n",
      "     |              the producer should select partition using its partitioner.\n",
      "     |  \n",
      "     |  persisted_offset(self, tp: faust.types.tuples.TP) -> Union[int, NoneType]\n",
      "     |      Return the last persisted offset for topic partition.\n",
      "     |  \n",
      "     |  async remove_from_stream(self, stream: faust.types.streams.StreamT) -> None\n",
      "     |      Remove table from stream join after stream stopped.\n",
      "     |  \n",
      "     |  reset_state(self) -> None\n",
      "     |      Reset local state.\n",
      "     |  \n",
      "     |  send_changelog(self, partition: Union[int, NoneType], key: Any, value: Any, key_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, value_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None) -> faust.types.tuples.FutureMessage\n",
      "     |      Send modification event to changelog topic.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from faust.tables.base.Collection:\n",
      "     |  \n",
      "     |  changelog_topic_name\n",
      "     |  \n",
      "     |  data\n",
      "     |      Underlying table storage.\n",
      "     |  \n",
      "     |  label\n",
      "     |      Return human-readable label used to represent this table.\n",
      "     |  \n",
      "     |  shortlabel\n",
      "     |      Return short label used to represent this table in logs.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from faust.tables.base.Collection:\n",
      "     |  \n",
      "     |  changelog_topic\n",
      "     |      Return the changelog topic used by this table.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  __post_init__(self) -> None\n",
      "     |      Additional user initialization.\n",
      "     |  \n",
      "     |  async add_async_context(self, context: AbstractAsyncContextManager) -> Any\n",
      "     |  \n",
      "     |  add_context(self, context: AbstractContextManager) -> Any\n",
      "     |  \n",
      "     |  add_dependency(self, service: mode.types.services.ServiceT) -> mode.types.services.ServiceT\n",
      "     |      Add dependency to other service.\n",
      "     |      \n",
      "     |      The service will be started/stopped with this service.\n",
      "     |  \n",
      "     |  add_future(self, coro: Awaitable) -> _asyncio.Future\n",
      "     |      Add relationship to asyncio.Future.\n",
      "     |      \n",
      "     |      The future will be joined when this service is stopped.\n",
      "     |  \n",
      "     |  async add_runtime_dependency(self, service: mode.types.services.ServiceT) -> mode.types.services.ServiceT\n",
      "     |  \n",
      "     |  async crash(self, reason: BaseException) -> None\n",
      "     |      Crash the service and all child services.\n",
      "     |  \n",
      "     |  async itertimer(self, interval: Union[datetime.timedelta, float, str], *, max_drift_correction: float = 0.1, loop: asyncio.events.AbstractEventLoop = None, sleep: Callable[..., Awaitable] = None, clock: Callable[[], float] = <built-in function perf_counter>, name: str = '') -> AsyncIterator[float]\n",
      "     |      Sleep ``interval`` seconds for every iteration.\n",
      "     |      \n",
      "     |      This is an async iterator that takes advantage\n",
      "     |      of :func:`~mode.timers.Timer` to monitor drift and timer\n",
      "     |      oerlap.\n",
      "     |      \n",
      "     |      Uses ``Service.sleep`` so exits fast when the service is\n",
      "     |      stopped.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          Will sleep the full `interval` seconds before returning\n",
      "     |          from first iteration.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |          >>> async for sleep_time in self.itertimer(1.0):\n",
      "     |          ...   print('another second passed, just woke up...')\n",
      "     |          ...   await perform_some_http_request()\n",
      "     |  \n",
      "     |  async join_services(self, services: Sequence[mode.types.services.ServiceT]) -> None\n",
      "     |  \n",
      "     |  async maybe_start(self) -> bool\n",
      "     |      Start the service, if it has not already been started.\n",
      "     |  \n",
      "     |  on_init(self) -> None\n",
      "     |  \n",
      "     |  on_init_dependencies(self) -> Iterable[mode.types.services.ServiceT]\n",
      "     |      Return list of service dependencies for this service.\n",
      "     |  \n",
      "     |  async remove_dependency(self, service: mode.types.services.ServiceT) -> mode.types.services.ServiceT\n",
      "     |      Stop and remove dependency of this service.\n",
      "     |  \n",
      "     |  async restart(self) -> None\n",
      "     |      Restart this service.\n",
      "     |  \n",
      "     |  service_reset(self) -> None\n",
      "     |  \n",
      "     |  set_shutdown(self) -> None\n",
      "     |      Set the shutdown signal.\n",
      "     |      \n",
      "     |      Notes:\n",
      "     |          If :attr:`wait_for_shutdown` is set, stopping the service\n",
      "     |          will wait for this flag to be set.\n",
      "     |  \n",
      "     |  async sleep(self, n: Union[datetime.timedelta, float, str], *, loop: asyncio.events.AbstractEventLoop = None) -> None\n",
      "     |      Sleep for ``n`` seconds, or until service stopped.\n",
      "     |  \n",
      "     |  async start(self) -> None\n",
      "     |  \n",
      "     |  async stop(self) -> None\n",
      "     |      Stop the service.\n",
      "     |  \n",
      "     |  async transition_with(self, flag: str, fut: Awaitable, *args: Any, **kwargs: Any) -> Any\n",
      "     |  \n",
      "     |  async wait(self, *coros: Union[_asyncio.Future, Generator[Any, NoneType, Any], Awaitable, asyncio.locks.Event, mode.utils.locks.Event], timeout: Union[datetime.timedelta, float, str] = None) -> mode.services.WaitResult\n",
      "     |      Wait for coroutines to complete, or until the service stops.\n",
      "     |  \n",
      "     |  async wait_first(self, *coros: Union[_asyncio.Future, Generator[Any, NoneType, Any], Awaitable, asyncio.locks.Event, mode.utils.locks.Event], timeout: Union[datetime.timedelta, float, str] = None) -> mode.services.WaitResults\n",
      "     |  \n",
      "     |  async wait_for_stopped(self, *coros: Union[_asyncio.Future, Generator[Any, NoneType, Any], Awaitable, asyncio.locks.Event, mode.utils.locks.Event], timeout: Union[datetime.timedelta, float, str] = None) -> bool\n",
      "     |  \n",
      "     |  async wait_many(self, coros: Iterable[Union[_asyncio.Future, Generator[Any, NoneType, Any], Awaitable, asyncio.locks.Event, mode.utils.locks.Event]], *, timeout: Union[datetime.timedelta, float, str] = None) -> mode.services.WaitResult\n",
      "     |  \n",
      "     |  async wait_until_stopped(self) -> None\n",
      "     |      Wait until the service is signalled to stop.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  __init_subclass__() -> None from abc.ABCMeta\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  from_awaitable(coro: Awaitable, *, name: str = None, **kwargs: Any) -> mode.types.services.ServiceT from abc.ABCMeta\n",
      "     |  \n",
      "     |  task(fun: Callable[[Any], Awaitable[NoneType]]) -> mode.services.ServiceTask from abc.ABCMeta\n",
      "     |      Decorate function to be used as background task.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> class S(Service):\n",
      "     |          ...\n",
      "     |          ...     @Service.task\n",
      "     |          ...     async def background_task(self):\n",
      "     |          ...         while not self.should_stop:\n",
      "     |          ...             await self.sleep(1.0)\n",
      "     |          ...             print('Waking up')\n",
      "     |  \n",
      "     |  timer(interval: Union[datetime.timedelta, float, str]) -> Callable[[Callable], mode.services.ServiceTask] from abc.ABCMeta\n",
      "     |      Background timer executing every ``n`` seconds.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> class S(Service):\n",
      "     |          ...\n",
      "     |          ...     @Service.timer(1.0)\n",
      "     |          ...     async def background_timer(self):\n",
      "     |          ...         print('Waking up')\n",
      "     |  \n",
      "     |  transitions_to(flag: str) -> Callable from abc.ABCMeta\n",
      "     |      Decorate function to set and reset diagnostic flag.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  crashed\n",
      "     |  \n",
      "     |  should_stop\n",
      "     |      Return :const:`True` if the service must stop.\n",
      "     |  \n",
      "     |  started\n",
      "     |      Return :const:`True` if the service was started.\n",
      "     |  \n",
      "     |  state\n",
      "     |      Service state - as a human readable string.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  beacon\n",
      "     |      Beacon used to track services in a dependency graph.\n",
      "     |  \n",
      "     |  crash_reason\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  Diag = <class 'mode.services.Diag'>\n",
      "     |      Service diagnostics.\n",
      "     |      \n",
      "     |      This can be used to track what your service is doing.\n",
      "     |      For example if your service is a Kafka consumer with a background\n",
      "     |      thread that commits the offset every 30 seconds, you may want to\n",
      "     |      see when this happens::\n",
      "     |      \n",
      "     |          DIAG_COMMITTING = 'committing'\n",
      "     |      \n",
      "     |          class Consumer(Service):\n",
      "     |      \n",
      "     |              @Service.task\n",
      "     |              async def _background_commit(self) -> None:\n",
      "     |                  while not self.should_stop:\n",
      "     |                      await self.sleep(30.0)\n",
      "     |                      self.diag.set_flag(DIAG_COMITTING)\n",
      "     |                      try:\n",
      "     |                          await self._consumer.commit()\n",
      "     |                      finally:\n",
      "     |                          self.diag.unset_flag(DIAG_COMMITTING)\n",
      "     |      \n",
      "     |      The above code is setting the flag manually, but you can also use\n",
      "     |      a decorator to accomplish the same thing::\n",
      "     |      \n",
      "     |          @Service.timer(30.0)\n",
      "     |          async def _background_commit(self) -> None:\n",
      "     |              await self.commit()\n",
      "     |      \n",
      "     |          @Service.transitions_with(DIAG_COMITTING)\n",
      "     |          async def commit(self) -> None:\n",
      "     |              await self._consumer.commit()\n",
      "     |  \n",
      "     |  abstract = False\n",
      "     |  \n",
      "     |  mundane_level = 'info'\n",
      "     |  \n",
      "     |  restart_count = 0\n",
      "     |  \n",
      "     |  shutdown_timeout = 60.0\n",
      "     |  \n",
      "     |  wait_for_shutdown = False\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mode.services.ServiceBase:\n",
      "     |  \n",
      "     |  async __aenter__(self) -> mode.types.services.ServiceT\n",
      "     |      Return `self` upon entering the runtime context.\n",
      "     |  \n",
      "     |  async __aexit__(self, exc_type: Type[BaseException] = None, exc_val: BaseException = None, exc_tb: traceback = None) -> Union[bool, NoneType]\n",
      "     |      Raise any exception triggered within the runtime context.\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from mode.services.ServiceBase:\n",
      "     |  \n",
      "     |  loop\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from faust.types.tables.CollectionT:\n",
      "     |  \n",
      "     |  is_global = False\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from mode.types.services.ServiceT:\n",
      "     |  \n",
      "     |  supervisor = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from contextlib.AbstractAsyncContextManager:\n",
      "     |  \n",
      "     |  __subclasshook__(C) from abc.ABCMeta\n",
      "     |      Abstract classes can override this to customize issubclass().\n",
      "     |      \n",
      "     |      This is invoked early on by abc.ABCMeta.__subclasscheck__().\n",
      "     |      It should return True, False or NotImplemented.  If it returns\n",
      "     |      NotImplemented, the normal algorithm is used.  Otherwise, it\n",
      "     |      overrides the normal algorithm (and the outcome is cached).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from contextlib.AbstractAsyncContextManager:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mode.utils.collections.ManagedUserDict:\n",
      "     |  \n",
      "     |  __delitem__(self, key: ~KT) -> None\n",
      "     |  \n",
      "     |  __setitem__(self, key: ~KT, value: ~VT) -> None\n",
      "     |  \n",
      "     |  clear(self) -> None\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |  \n",
      "     |  on_clear(self) -> None\n",
      "     |      Handle that the mapping is being cleared.\n",
      "     |  \n",
      "     |  raw_update(self, *args: Any, **kwargs: Any) -> None\n",
      "     |  \n",
      "     |  update(self, *args: Any, **kwargs: Any) -> None\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E present and has a .keys() method, does:     for k in E: D[k] = E[k]\n",
      "     |      If E present and lacks .keys() method, does:     for (k, v) in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k, v in F.items(): D[k] = v\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mode.utils.collections.FastUserDict:\n",
      "     |  \n",
      "     |  __contains__(self, key: object) -> bool\n",
      "     |  \n",
      "     |  __iter__(self) -> Iterator[~KT]\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  copy(self) -> dict\n",
      "     |  \n",
      "     |  items(self) -> ItemsView\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |  \n",
      "     |  keys(self) -> KeysView\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |  \n",
      "     |  values(self) -> ValuesView\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from mode.utils.collections.FastUserDict:\n",
      "     |  \n",
      "     |  fromkeys(iterable: Iterable[~KT], value: ~VT = None) -> 'FastUserDict' from abc.ABCMeta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from collections.abc.MutableMapping:\n",
      "     |  \n",
      "     |  pop(self, key, default=<object object at 0x7fc595cbb150>)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |      If key is not found, d is returned if given, otherwise KeyError is raised.\n",
      "     |  \n",
      "     |  popitem(self)\n",
      "     |      D.popitem() -> (k, v), remove and return some (key, value) pair\n",
      "     |      as a 2-tuple; but raise KeyError if D is empty.\n",
      "     |  \n",
      "     |  setdefault(self, key, default=None)\n",
      "     |      D.setdefault(k[,d]) -> D.get(k,d), also set D[k]=d if k not in D\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from collections.abc.Mapping:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  get(self, key, default=None)\n",
      "     |      D.get(k[,d]) -> D[k] if k in D, else d.  d defaults to None.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from collections.abc.Mapping:\n",
      "     |  \n",
      "     |  __reversed__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from abc.ABCMeta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mode.services.ServiceCallbacks:\n",
      "     |  \n",
      "     |  async on_first_start(self) -> None\n",
      "     |      Service started for the first time in this process.\n",
      "     |  \n",
      "     |  async on_restart(self) -> None\n",
      "     |      Service is being restarted.\n",
      "     |  \n",
      "     |  async on_shutdown(self) -> None\n",
      "     |      Service is being stopped/restarted.\n",
      "     |  \n",
      "     |  async on_started(self) -> None\n",
      "     |      Service has started.\n",
      "     |  \n",
      "     |  async on_stop(self) -> None\n",
      "     |      Service is being stopped/restarted.\n",
      "    \n",
      "    class SetTable(faust.tables.table.Table)\n",
      "     |  SetTable(*args, **kwds)\n",
      "     |  \n",
      "     |  Table that maintains a dictionary of sets.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SetTable\n",
      "     |      faust.tables.table.Table\n",
      "     |      faust.types.tables.TableT\n",
      "     |      faust.tables.base.Collection\n",
      "     |      mode.services.Service\n",
      "     |      mode.services.ServiceBase\n",
      "     |      faust.types.tables.CollectionT\n",
      "     |      mode.types.services.ServiceT\n",
      "     |      contextlib.AbstractAsyncContextManager\n",
      "     |      faust.types.streams.JoinableT\n",
      "     |      abc.ABC\n",
      "     |      mode.utils.collections.ManagedUserDict\n",
      "     |      mode.utils.collections.FastUserDict\n",
      "     |      collections.abc.MutableMapping\n",
      "     |      collections.abc.Mapping\n",
      "     |      collections.abc.Collection\n",
      "     |      collections.abc.Sized\n",
      "     |      collections.abc.Iterable\n",
      "     |      collections.abc.Container\n",
      "     |      typing.Generic\n",
      "     |      mode.services.ServiceCallbacks\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, key: ~KT) -> faust.tables.sets.ChangeloggedSet[~VT]\n",
      "     |  \n",
      "     |  __init__(self, app: faust.types.app.AppT, *, start_manager: bool = False, manager_topic_name: str = None, manager_topic_suffix: str = None, **kwargs: Any) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  async on_start(self) -> None\n",
      "     |      Call when set table starts.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  Manager = <class 'faust.tables.sets.SetTableManager'>\n",
      "     |      Manager used to perform operations on :class:`SetTable`.\n",
      "     |      \n",
      "     |      Used when set table is configured with ``SetTable('name',\n",
      "     |      start_manager=True)``.\n",
      "     |      \n",
      "     |      The workers will start an additional agent used to process\n",
      "     |      incoming set operations, and you can communicate with this\n",
      "     |      agent to modify your sets.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |          >>> set_table = SetTable('sets', start_manager=True)\n",
      "     |      \n",
      "     |          >>> await set_table.manager.add('active_orders', Order)\n",
      "     |          >>> await set_table.manager.discard('active_orders', Order)\n",
      "     |      \n",
      "     |      The manager methods can be used from HTTP views and other agents\n",
      "     |      to safely route set operations to the correct worker.\n",
      "     |  \n",
      "     |  WindowWrapper = <class 'faust.tables.sets.SetWindowWrapper'>\n",
      "     |      Window wrapper for sets.\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'Manager': typing.ClassVar[typing.Type[faust.tables...\n",
      "     |  \n",
      "     |  __orig_bases__ = (faust.tables.table.Table[~KT, faust.tables.sets.Chan...\n",
      "     |  \n",
      "     |  logger = <Logger faust.tables.sets (INFO)>\n",
      "     |  \n",
      "     |  manager_topic_suffix = '-setmanager'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from faust.tables.table.Table:\n",
      "     |  \n",
      "     |  __missing__(self, key: ~KT) -> ~VT\n",
      "     |  \n",
      "     |  as_ansitable(self, title: str = '{table.name}', **kwargs: Any) -> str\n",
      "     |      Draw table as a a terminal ANSI table.\n",
      "     |  \n",
      "     |  hopping(self, size: Union[datetime.timedelta, float, str], step: Union[datetime.timedelta, float, str], expires: Union[datetime.timedelta, float, str] = None, key_index: bool = False) -> faust.types.tables.WindowWrapperT\n",
      "     |      Wrap table in a hopping window.\n",
      "     |  \n",
      "     |  on_key_del(self, key: ~KT) -> None\n",
      "     |      Call when a key in this table is removed.\n",
      "     |  \n",
      "     |  on_key_get(self, key: ~KT) -> None\n",
      "     |      Call when the value for a key in this table is retrieved.\n",
      "     |  \n",
      "     |  on_key_set(self, key: ~KT, value: ~VT) -> None\n",
      "     |      Call when the value for a key in this table is set.\n",
      "     |  \n",
      "     |  tumbling(self, size: Union[datetime.timedelta, float, str], expires: Union[datetime.timedelta, float, str] = None, key_index: bool = False) -> faust.types.tables.WindowWrapperT\n",
      "     |      Wrap table in a tumbling window.\n",
      "     |  \n",
      "     |  using_window(self, window: faust.types.windows.WindowT, *, key_index: bool = False) -> faust.types.tables.WindowWrapperT\n",
      "     |      Wrap table using a specific window type.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from faust.types.tables.TableT:\n",
      "     |  \n",
      "     |  __parameters__ = (~KT, ~VT)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from faust.tables.base.Collection:\n",
      "     |  \n",
      "     |  __and__(self, other: Any) -> Any\n",
      "     |  \n",
      "     |  __copy__(self) -> Any\n",
      "     |  \n",
      "     |  __hash__(self) -> int\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  apply_changelog_batch(self, batch: Iterable[faust.types.events.EventT]) -> None\n",
      "     |      Apply batch of events from changelog topic local table storage.\n",
      "     |  \n",
      "     |  async call_recover_callbacks(self) -> None\n",
      "     |      Call any configured recovery callbacks after rebalancing.\n",
      "     |  \n",
      "     |  clone(self, **kwargs: Any) -> Any\n",
      "     |      Clone table instance.\n",
      "     |  \n",
      "     |  combine(self, *nodes: faust.types.streams.JoinableT, **kwargs: Any) -> faust.types.streams.StreamT\n",
      "     |      Combine tables and streams.\n",
      "     |  \n",
      "     |  contribute_to_stream(self, active: faust.types.streams.StreamT) -> None\n",
      "     |      Contribute table to stream join.\n",
      "     |  \n",
      "     |  info(self) -> Mapping[str, Any]\n",
      "     |      Return table attributes as dictionary.\n",
      "     |  \n",
      "     |  inner_join(self, *fields: faust.types.models.FieldDescriptorT) -> faust.types.streams.StreamT\n",
      "     |      Inner join of this table and another stream/table.\n",
      "     |  \n",
      "     |  join(self, *fields: faust.types.models.FieldDescriptorT) -> faust.types.streams.StreamT\n",
      "     |      Right join of this table and another stream/table.\n",
      "     |  \n",
      "     |  left_join(self, *fields: faust.types.models.FieldDescriptorT) -> faust.types.streams.StreamT\n",
      "     |      Left join of this table and another stream/table.\n",
      "     |  \n",
      "     |  async need_active_standby_for(self, tp: faust.types.tuples.TP) -> bool\n",
      "     |      Return :const:`False` if we have access to partition data.\n",
      "     |  \n",
      "     |  async on_changelog_event(self, event: faust.types.events.EventT) -> None\n",
      "     |      Call when a new changelog event is received.\n",
      "     |  \n",
      "     |  async on_rebalance(self, assigned: Set[faust.types.tuples.TP], revoked: Set[faust.types.tuples.TP], newly_assigned: Set[faust.types.tuples.TP]) -> None\n",
      "     |      Call when cluster is rebalancing.\n",
      "     |  \n",
      "     |  on_recover(self, fun: Callable[[], Awaitable[NoneType]]) -> Callable[[], Awaitable[NoneType]]\n",
      "     |      Add function as callback to be called on table recovery.\n",
      "     |  \n",
      "     |  async on_recovery_completed(self, active_tps: Set[faust.types.tuples.TP], standby_tps: Set[faust.types.tuples.TP]) -> None\n",
      "     |      Call when recovery has completed after rebalancing.\n",
      "     |  \n",
      "     |  on_window_close(self, key: Any, value: Any) -> None\n",
      "     |  \n",
      "     |  outer_join(self, *fields: faust.types.models.FieldDescriptorT) -> faust.types.streams.StreamT\n",
      "     |      Outer join of this table and another stream/table.\n",
      "     |  \n",
      "     |  partition_for_key(self, key: Any) -> Union[int, NoneType]\n",
      "     |      Return partition number for table key.\n",
      "     |      \n",
      "     |      Always returns :const:`None` when :attr:`use_partitioner`\n",
      "     |      is enabled.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Optional[int]: specific partition or :const:`None` if\n",
      "     |              the producer should select partition using its partitioner.\n",
      "     |  \n",
      "     |  persisted_offset(self, tp: faust.types.tuples.TP) -> Union[int, NoneType]\n",
      "     |      Return the last persisted offset for topic partition.\n",
      "     |  \n",
      "     |  async remove_from_stream(self, stream: faust.types.streams.StreamT) -> None\n",
      "     |      Remove table from stream join after stream stopped.\n",
      "     |  \n",
      "     |  reset_state(self) -> None\n",
      "     |      Reset local state.\n",
      "     |  \n",
      "     |  send_changelog(self, partition: Union[int, NoneType], key: Any, value: Any, key_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, value_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None) -> faust.types.tuples.FutureMessage\n",
      "     |      Send modification event to changelog topic.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from faust.tables.base.Collection:\n",
      "     |  \n",
      "     |  changelog_topic_name\n",
      "     |  \n",
      "     |  data\n",
      "     |      Underlying table storage.\n",
      "     |  \n",
      "     |  label\n",
      "     |      Return human-readable label used to represent this table.\n",
      "     |  \n",
      "     |  shortlabel\n",
      "     |      Return short label used to represent this table in logs.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from faust.tables.base.Collection:\n",
      "     |  \n",
      "     |  changelog_topic\n",
      "     |      Return the changelog topic used by this table.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  __post_init__(self) -> None\n",
      "     |      Additional user initialization.\n",
      "     |  \n",
      "     |  async add_async_context(self, context: AbstractAsyncContextManager) -> Any\n",
      "     |  \n",
      "     |  add_context(self, context: AbstractContextManager) -> Any\n",
      "     |  \n",
      "     |  add_dependency(self, service: mode.types.services.ServiceT) -> mode.types.services.ServiceT\n",
      "     |      Add dependency to other service.\n",
      "     |      \n",
      "     |      The service will be started/stopped with this service.\n",
      "     |  \n",
      "     |  add_future(self, coro: Awaitable) -> _asyncio.Future\n",
      "     |      Add relationship to asyncio.Future.\n",
      "     |      \n",
      "     |      The future will be joined when this service is stopped.\n",
      "     |  \n",
      "     |  async add_runtime_dependency(self, service: mode.types.services.ServiceT) -> mode.types.services.ServiceT\n",
      "     |  \n",
      "     |  async crash(self, reason: BaseException) -> None\n",
      "     |      Crash the service and all child services.\n",
      "     |  \n",
      "     |  async itertimer(self, interval: Union[datetime.timedelta, float, str], *, max_drift_correction: float = 0.1, loop: asyncio.events.AbstractEventLoop = None, sleep: Callable[..., Awaitable] = None, clock: Callable[[], float] = <built-in function perf_counter>, name: str = '') -> AsyncIterator[float]\n",
      "     |      Sleep ``interval`` seconds for every iteration.\n",
      "     |      \n",
      "     |      This is an async iterator that takes advantage\n",
      "     |      of :func:`~mode.timers.Timer` to monitor drift and timer\n",
      "     |      oerlap.\n",
      "     |      \n",
      "     |      Uses ``Service.sleep`` so exits fast when the service is\n",
      "     |      stopped.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          Will sleep the full `interval` seconds before returning\n",
      "     |          from first iteration.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |          >>> async for sleep_time in self.itertimer(1.0):\n",
      "     |          ...   print('another second passed, just woke up...')\n",
      "     |          ...   await perform_some_http_request()\n",
      "     |  \n",
      "     |  async join_services(self, services: Sequence[mode.types.services.ServiceT]) -> None\n",
      "     |  \n",
      "     |  async maybe_start(self) -> bool\n",
      "     |      Start the service, if it has not already been started.\n",
      "     |  \n",
      "     |  on_init(self) -> None\n",
      "     |  \n",
      "     |  on_init_dependencies(self) -> Iterable[mode.types.services.ServiceT]\n",
      "     |      Return list of service dependencies for this service.\n",
      "     |  \n",
      "     |  async remove_dependency(self, service: mode.types.services.ServiceT) -> mode.types.services.ServiceT\n",
      "     |      Stop and remove dependency of this service.\n",
      "     |  \n",
      "     |  async restart(self) -> None\n",
      "     |      Restart this service.\n",
      "     |  \n",
      "     |  service_reset(self) -> None\n",
      "     |  \n",
      "     |  set_shutdown(self) -> None\n",
      "     |      Set the shutdown signal.\n",
      "     |      \n",
      "     |      Notes:\n",
      "     |          If :attr:`wait_for_shutdown` is set, stopping the service\n",
      "     |          will wait for this flag to be set.\n",
      "     |  \n",
      "     |  async sleep(self, n: Union[datetime.timedelta, float, str], *, loop: asyncio.events.AbstractEventLoop = None) -> None\n",
      "     |      Sleep for ``n`` seconds, or until service stopped.\n",
      "     |  \n",
      "     |  async start(self) -> None\n",
      "     |  \n",
      "     |  async stop(self) -> None\n",
      "     |      Stop the service.\n",
      "     |  \n",
      "     |  async transition_with(self, flag: str, fut: Awaitable, *args: Any, **kwargs: Any) -> Any\n",
      "     |  \n",
      "     |  async wait(self, *coros: Union[_asyncio.Future, Generator[Any, NoneType, Any], Awaitable, asyncio.locks.Event, mode.utils.locks.Event], timeout: Union[datetime.timedelta, float, str] = None) -> mode.services.WaitResult\n",
      "     |      Wait for coroutines to complete, or until the service stops.\n",
      "     |  \n",
      "     |  async wait_first(self, *coros: Union[_asyncio.Future, Generator[Any, NoneType, Any], Awaitable, asyncio.locks.Event, mode.utils.locks.Event], timeout: Union[datetime.timedelta, float, str] = None) -> mode.services.WaitResults\n",
      "     |  \n",
      "     |  async wait_for_stopped(self, *coros: Union[_asyncio.Future, Generator[Any, NoneType, Any], Awaitable, asyncio.locks.Event, mode.utils.locks.Event], timeout: Union[datetime.timedelta, float, str] = None) -> bool\n",
      "     |  \n",
      "     |  async wait_many(self, coros: Iterable[Union[_asyncio.Future, Generator[Any, NoneType, Any], Awaitable, asyncio.locks.Event, mode.utils.locks.Event]], *, timeout: Union[datetime.timedelta, float, str] = None) -> mode.services.WaitResult\n",
      "     |  \n",
      "     |  async wait_until_stopped(self) -> None\n",
      "     |      Wait until the service is signalled to stop.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  __init_subclass__() -> None from abc.ABCMeta\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  from_awaitable(coro: Awaitable, *, name: str = None, **kwargs: Any) -> mode.types.services.ServiceT from abc.ABCMeta\n",
      "     |  \n",
      "     |  task(fun: Callable[[Any], Awaitable[NoneType]]) -> mode.services.ServiceTask from abc.ABCMeta\n",
      "     |      Decorate function to be used as background task.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> class S(Service):\n",
      "     |          ...\n",
      "     |          ...     @Service.task\n",
      "     |          ...     async def background_task(self):\n",
      "     |          ...         while not self.should_stop:\n",
      "     |          ...             await self.sleep(1.0)\n",
      "     |          ...             print('Waking up')\n",
      "     |  \n",
      "     |  timer(interval: Union[datetime.timedelta, float, str]) -> Callable[[Callable], mode.services.ServiceTask] from abc.ABCMeta\n",
      "     |      Background timer executing every ``n`` seconds.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> class S(Service):\n",
      "     |          ...\n",
      "     |          ...     @Service.timer(1.0)\n",
      "     |          ...     async def background_timer(self):\n",
      "     |          ...         print('Waking up')\n",
      "     |  \n",
      "     |  transitions_to(flag: str) -> Callable from abc.ABCMeta\n",
      "     |      Decorate function to set and reset diagnostic flag.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  crashed\n",
      "     |  \n",
      "     |  should_stop\n",
      "     |      Return :const:`True` if the service must stop.\n",
      "     |  \n",
      "     |  started\n",
      "     |      Return :const:`True` if the service was started.\n",
      "     |  \n",
      "     |  state\n",
      "     |      Service state - as a human readable string.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  beacon\n",
      "     |      Beacon used to track services in a dependency graph.\n",
      "     |  \n",
      "     |  crash_reason\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  Diag = <class 'mode.services.Diag'>\n",
      "     |      Service diagnostics.\n",
      "     |      \n",
      "     |      This can be used to track what your service is doing.\n",
      "     |      For example if your service is a Kafka consumer with a background\n",
      "     |      thread that commits the offset every 30 seconds, you may want to\n",
      "     |      see when this happens::\n",
      "     |      \n",
      "     |          DIAG_COMMITTING = 'committing'\n",
      "     |      \n",
      "     |          class Consumer(Service):\n",
      "     |      \n",
      "     |              @Service.task\n",
      "     |              async def _background_commit(self) -> None:\n",
      "     |                  while not self.should_stop:\n",
      "     |                      await self.sleep(30.0)\n",
      "     |                      self.diag.set_flag(DIAG_COMITTING)\n",
      "     |                      try:\n",
      "     |                          await self._consumer.commit()\n",
      "     |                      finally:\n",
      "     |                          self.diag.unset_flag(DIAG_COMMITTING)\n",
      "     |      \n",
      "     |      The above code is setting the flag manually, but you can also use\n",
      "     |      a decorator to accomplish the same thing::\n",
      "     |      \n",
      "     |          @Service.timer(30.0)\n",
      "     |          async def _background_commit(self) -> None:\n",
      "     |              await self.commit()\n",
      "     |      \n",
      "     |          @Service.transitions_with(DIAG_COMITTING)\n",
      "     |          async def commit(self) -> None:\n",
      "     |              await self._consumer.commit()\n",
      "     |  \n",
      "     |  abstract = False\n",
      "     |  \n",
      "     |  mundane_level = 'info'\n",
      "     |  \n",
      "     |  restart_count = 0\n",
      "     |  \n",
      "     |  shutdown_timeout = 60.0\n",
      "     |  \n",
      "     |  wait_for_shutdown = False\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mode.services.ServiceBase:\n",
      "     |  \n",
      "     |  async __aenter__(self) -> mode.types.services.ServiceT\n",
      "     |      Return `self` upon entering the runtime context.\n",
      "     |  \n",
      "     |  async __aexit__(self, exc_type: Type[BaseException] = None, exc_val: BaseException = None, exc_tb: traceback = None) -> Union[bool, NoneType]\n",
      "     |      Raise any exception triggered within the runtime context.\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from mode.services.ServiceBase:\n",
      "     |  \n",
      "     |  loop\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from faust.types.tables.CollectionT:\n",
      "     |  \n",
      "     |  is_global = False\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from mode.types.services.ServiceT:\n",
      "     |  \n",
      "     |  supervisor = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from contextlib.AbstractAsyncContextManager:\n",
      "     |  \n",
      "     |  __subclasshook__(C) from abc.ABCMeta\n",
      "     |      Abstract classes can override this to customize issubclass().\n",
      "     |      \n",
      "     |      This is invoked early on by abc.ABCMeta.__subclasscheck__().\n",
      "     |      It should return True, False or NotImplemented.  If it returns\n",
      "     |      NotImplemented, the normal algorithm is used.  Otherwise, it\n",
      "     |      overrides the normal algorithm (and the outcome is cached).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from contextlib.AbstractAsyncContextManager:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mode.utils.collections.ManagedUserDict:\n",
      "     |  \n",
      "     |  __delitem__(self, key: ~KT) -> None\n",
      "     |  \n",
      "     |  __setitem__(self, key: ~KT, value: ~VT) -> None\n",
      "     |  \n",
      "     |  clear(self) -> None\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |  \n",
      "     |  on_clear(self) -> None\n",
      "     |      Handle that the mapping is being cleared.\n",
      "     |  \n",
      "     |  raw_update(self, *args: Any, **kwargs: Any) -> None\n",
      "     |  \n",
      "     |  update(self, *args: Any, **kwargs: Any) -> None\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E present and has a .keys() method, does:     for k in E: D[k] = E[k]\n",
      "     |      If E present and lacks .keys() method, does:     for (k, v) in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k, v in F.items(): D[k] = v\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mode.utils.collections.FastUserDict:\n",
      "     |  \n",
      "     |  __contains__(self, key: object) -> bool\n",
      "     |  \n",
      "     |  __iter__(self) -> Iterator[~KT]\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  copy(self) -> dict\n",
      "     |  \n",
      "     |  items(self) -> ItemsView\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |  \n",
      "     |  keys(self) -> KeysView\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |  \n",
      "     |  values(self) -> ValuesView\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from mode.utils.collections.FastUserDict:\n",
      "     |  \n",
      "     |  fromkeys(iterable: Iterable[~KT], value: ~VT = None) -> 'FastUserDict' from abc.ABCMeta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from collections.abc.MutableMapping:\n",
      "     |  \n",
      "     |  pop(self, key, default=<object object at 0x7fc595cbb150>)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |      If key is not found, d is returned if given, otherwise KeyError is raised.\n",
      "     |  \n",
      "     |  popitem(self)\n",
      "     |      D.popitem() -> (k, v), remove and return some (key, value) pair\n",
      "     |      as a 2-tuple; but raise KeyError if D is empty.\n",
      "     |  \n",
      "     |  setdefault(self, key, default=None)\n",
      "     |      D.setdefault(k[,d]) -> D.get(k,d), also set D[k]=d if k not in D\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from collections.abc.Mapping:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  get(self, key, default=None)\n",
      "     |      D.get(k[,d]) -> D[k] if k in D, else d.  d defaults to None.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from collections.abc.Mapping:\n",
      "     |  \n",
      "     |  __reversed__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from abc.ABCMeta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mode.services.ServiceCallbacks:\n",
      "     |  \n",
      "     |  async on_first_start(self) -> None\n",
      "     |      Service started for the first time in this process.\n",
      "     |  \n",
      "     |  async on_restart(self) -> None\n",
      "     |      Service is being restarted.\n",
      "     |  \n",
      "     |  async on_shutdown(self) -> None\n",
      "     |      Service is being stopped/restarted.\n",
      "     |  \n",
      "     |  async on_started(self) -> None\n",
      "     |      Service has started.\n",
      "     |  \n",
      "     |  async on_stop(self) -> None\n",
      "     |      Service is being stopped/restarted.\n",
      "    \n",
      "    class Settings(abc.ABC)\n",
      "     |  Settings(id: str, *, debug: bool = None, version: int = None, broker: Union[str, yarl.URL, List[yarl.URL]] = None, broker_api_version: str = None, broker_client_id: str = None, broker_request_timeout: Union[datetime.timedelta, float, str] = None, broker_credentials: Union[faust.types.auth.CredentialsT, ssl.SSLContext] = None, broker_commit_every: int = None, broker_commit_interval: Union[datetime.timedelta, float, str] = None, broker_commit_livelock_soft_timeout: Union[datetime.timedelta, float, str] = None, broker_session_timeout: Union[datetime.timedelta, float, str] = None, broker_rebalance_timeout: Union[datetime.timedelta, float, str] = None, broker_heartbeat_interval: Union[datetime.timedelta, float, str] = None, broker_check_crcs: bool = None, broker_max_poll_records: int = None, broker_max_poll_interval: int = None, broker_consumer: Union[str, yarl.URL, List[yarl.URL]] = None, broker_producer: Union[str, yarl.URL, List[yarl.URL]] = None, agent_supervisor: Union[Type[mode.types.supervisors.SupervisorStrategyT], str] = None, store: Union[str, yarl.URL] = None, cache: Union[str, yarl.URL] = None, web: Union[str, yarl.URL] = None, web_enabled: bool = True, processing_guarantee: Union[str, faust.types.enums.ProcessingGuarantee] = None, timezone: datetime.tzinfo = None, autodiscover: Union[bool, Iterable[str], Callable[[], Iterable[str]]] = None, origin: str = None, canonical_url: Union[str, yarl.URL] = None, datadir: Union[pathlib.Path, str] = None, tabledir: Union[pathlib.Path, str] = None, key_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, value_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, logging_config: Dict = None, loghandlers: List[logging.Handler] = None, table_cleanup_interval: Union[datetime.timedelta, float, str] = None, table_standby_replicas: int = None, table_key_index_size: int = None, topic_replication_factor: int = None, topic_partitions: int = None, topic_allow_declare: bool = None, topic_disable_leader: bool = None, id_format: str = None, reply_to: str = None, reply_to_prefix: str = None, reply_create_topic: bool = None, reply_expires: Union[datetime.timedelta, float, str] = None, ssl_context: ssl.SSLContext = None, stream_buffer_maxsize: int = None, stream_wait_empty: bool = None, stream_ack_cancelled_tasks: bool = None, stream_ack_exceptions: bool = None, stream_publish_on_commit: bool = None, stream_recovery_delay: Union[datetime.timedelta, float, str] = None, stream_processing_timeout: Union[datetime.timedelta, float, str] = None, producer_linger_ms: int = None, producer_max_batch_size: int = None, producer_acks: int = None, producer_max_request_size: int = None, producer_compression_type: str = None, producer_partitioner: Union[Callable[[Union[bytes, NoneType], Sequence[int], Sequence[int]], int], str] = None, producer_request_timeout: Union[datetime.timedelta, float, str] = None, producer_api_version: str = None, consumer_api_version: str = None, consumer_max_fetch_size: int = None, consumer_auto_offset_reset: str = None, web_bind: str = None, web_port: int = None, web_host: str = None, web_transport: Union[str, yarl.URL] = None, web_in_thread: bool = None, web_cors_options: Mapping[str, faust.types.web.ResourceOptions] = None, worker_redirect_stdouts: bool = None, worker_redirect_stdouts_level: Union[int, str] = None, Agent: Union[Type[faust.types.agents.AgentT], str] = None, ConsumerScheduler: Union[Type[faust.types.transports.SchedulingStrategyT], str] = None, Event: Union[Type[faust.types.events.EventT], str] = None, Schema: Union[Type[faust.types.serializers.SchemaT], str] = None, Stream: Union[Type[faust.types.streams.StreamT], str] = None, Table: Union[Type[faust.types.tables.TableT], str] = None, SetTable: Union[Type[faust.types.tables.TableT], str] = None, GlobalTable: Union[Type[faust.types.tables.GlobalTableT], str] = None, SetGlobalTable: Union[Type[faust.types.tables.GlobalTableT], str] = None, TableManager: Union[Type[faust.types.tables.TableManagerT], str] = None, Serializers: Union[Type[faust.types.serializers.RegistryT], str] = None, Worker: Union[Type[faust.types.settings._WorkerT], str] = None, PartitionAssignor: Union[Type[faust.types.assignor.PartitionAssignorT], str] = None, LeaderAssignor: Union[Type[faust.types.assignor.LeaderAssignorT], str] = None, Router: Union[Type[faust.types.router.RouterT], str] = None, Topic: Union[Type[faust.types.topics.TopicT], str] = None, HttpClient: Union[Type[aiohttp.client.ClientSession], str] = None, Monitor: Union[Type[faust.types.sensors.SensorT], str] = None, url: Union[str, yarl.URL] = None, **kwargs: Any) -> None\n",
      "     |  \n",
      "     |  Helper class that provides a standard way to create an ABC using\n",
      "     |  inheritance.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Settings\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getattribute__(self, key: str) -> Any\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __init__(self, id: str, *, debug: bool = None, version: int = None, broker: Union[str, yarl.URL, List[yarl.URL]] = None, broker_api_version: str = None, broker_client_id: str = None, broker_request_timeout: Union[datetime.timedelta, float, str] = None, broker_credentials: Union[faust.types.auth.CredentialsT, ssl.SSLContext] = None, broker_commit_every: int = None, broker_commit_interval: Union[datetime.timedelta, float, str] = None, broker_commit_livelock_soft_timeout: Union[datetime.timedelta, float, str] = None, broker_session_timeout: Union[datetime.timedelta, float, str] = None, broker_rebalance_timeout: Union[datetime.timedelta, float, str] = None, broker_heartbeat_interval: Union[datetime.timedelta, float, str] = None, broker_check_crcs: bool = None, broker_max_poll_records: int = None, broker_max_poll_interval: int = None, broker_consumer: Union[str, yarl.URL, List[yarl.URL]] = None, broker_producer: Union[str, yarl.URL, List[yarl.URL]] = None, agent_supervisor: Union[Type[mode.types.supervisors.SupervisorStrategyT], str] = None, store: Union[str, yarl.URL] = None, cache: Union[str, yarl.URL] = None, web: Union[str, yarl.URL] = None, web_enabled: bool = True, processing_guarantee: Union[str, faust.types.enums.ProcessingGuarantee] = None, timezone: datetime.tzinfo = None, autodiscover: Union[bool, Iterable[str], Callable[[], Iterable[str]]] = None, origin: str = None, canonical_url: Union[str, yarl.URL] = None, datadir: Union[pathlib.Path, str] = None, tabledir: Union[pathlib.Path, str] = None, key_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, value_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, logging_config: Dict = None, loghandlers: List[logging.Handler] = None, table_cleanup_interval: Union[datetime.timedelta, float, str] = None, table_standby_replicas: int = None, table_key_index_size: int = None, topic_replication_factor: int = None, topic_partitions: int = None, topic_allow_declare: bool = None, topic_disable_leader: bool = None, id_format: str = None, reply_to: str = None, reply_to_prefix: str = None, reply_create_topic: bool = None, reply_expires: Union[datetime.timedelta, float, str] = None, ssl_context: ssl.SSLContext = None, stream_buffer_maxsize: int = None, stream_wait_empty: bool = None, stream_ack_cancelled_tasks: bool = None, stream_ack_exceptions: bool = None, stream_publish_on_commit: bool = None, stream_recovery_delay: Union[datetime.timedelta, float, str] = None, stream_processing_timeout: Union[datetime.timedelta, float, str] = None, producer_linger_ms: int = None, producer_max_batch_size: int = None, producer_acks: int = None, producer_max_request_size: int = None, producer_compression_type: str = None, producer_partitioner: Union[Callable[[Union[bytes, NoneType], Sequence[int], Sequence[int]], int], str] = None, producer_request_timeout: Union[datetime.timedelta, float, str] = None, producer_api_version: str = None, consumer_api_version: str = None, consumer_max_fetch_size: int = None, consumer_auto_offset_reset: str = None, web_bind: str = None, web_port: int = None, web_host: str = None, web_transport: Union[str, yarl.URL] = None, web_in_thread: bool = None, web_cors_options: Mapping[str, faust.types.web.ResourceOptions] = None, worker_redirect_stdouts: bool = None, worker_redirect_stdouts_level: Union[int, str] = None, Agent: Union[Type[faust.types.agents.AgentT], str] = None, ConsumerScheduler: Union[Type[faust.types.transports.SchedulingStrategyT], str] = None, Event: Union[Type[faust.types.events.EventT], str] = None, Schema: Union[Type[faust.types.serializers.SchemaT], str] = None, Stream: Union[Type[faust.types.streams.StreamT], str] = None, Table: Union[Type[faust.types.tables.TableT], str] = None, SetTable: Union[Type[faust.types.tables.TableT], str] = None, GlobalTable: Union[Type[faust.types.tables.GlobalTableT], str] = None, SetGlobalTable: Union[Type[faust.types.tables.GlobalTableT], str] = None, TableManager: Union[Type[faust.types.tables.TableManagerT], str] = None, Serializers: Union[Type[faust.types.serializers.RegistryT], str] = None, Worker: Union[Type[faust.types.settings._WorkerT], str] = None, PartitionAssignor: Union[Type[faust.types.assignor.PartitionAssignorT], str] = None, LeaderAssignor: Union[Type[faust.types.assignor.LeaderAssignorT], str] = None, Router: Union[Type[faust.types.router.RouterT], str] = None, Topic: Union[Type[faust.types.topics.TopicT], str] = None, HttpClient: Union[Type[aiohttp.client.ClientSession], str] = None, Monitor: Union[Type[faust.types.sensors.SensorT], str] = None, url: Union[str, yarl.URL] = None, **kwargs: Any) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __setattr__(self, key: str, value: Any) -> None\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  find_old_versiondirs(self) -> Iterable[pathlib.Path]\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  setting_names() -> Set[str] from abc.ABCMeta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  appdir\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  Agent\n",
      "     |  \n",
      "     |  ConsumerScheduler\n",
      "     |  \n",
      "     |  Event\n",
      "     |  \n",
      "     |  GlobalTable\n",
      "     |  \n",
      "     |  HttpClient\n",
      "     |  \n",
      "     |  LeaderAssignor\n",
      "     |  \n",
      "     |  Monitor\n",
      "     |  \n",
      "     |  PartitionAssignor\n",
      "     |  \n",
      "     |  Router\n",
      "     |  \n",
      "     |  Schema\n",
      "     |  \n",
      "     |  Serializers\n",
      "     |  \n",
      "     |  SetGlobalTable\n",
      "     |  \n",
      "     |  SetTable\n",
      "     |  \n",
      "     |  Stream\n",
      "     |  \n",
      "     |  Table\n",
      "     |  \n",
      "     |  TableManager\n",
      "     |  \n",
      "     |  Topic\n",
      "     |  \n",
      "     |  Worker\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  agent_supervisor\n",
      "     |  \n",
      "     |  broker\n",
      "     |  \n",
      "     |  broker_commit_interval\n",
      "     |  \n",
      "     |  broker_commit_livelock_soft_timeout\n",
      "     |  \n",
      "     |  broker_consumer\n",
      "     |  \n",
      "     |  broker_credentials\n",
      "     |  \n",
      "     |  broker_heartbeat_interval\n",
      "     |  \n",
      "     |  broker_max_poll_records\n",
      "     |  \n",
      "     |  broker_producer\n",
      "     |  \n",
      "     |  broker_rebalance_timeout\n",
      "     |  \n",
      "     |  broker_request_timeout\n",
      "     |  \n",
      "     |  broker_session_timeout\n",
      "     |  \n",
      "     |  cache\n",
      "     |  \n",
      "     |  canonical_url\n",
      "     |  \n",
      "     |  consumer_api_version\n",
      "     |  \n",
      "     |  datadir\n",
      "     |  \n",
      "     |  id\n",
      "     |  \n",
      "     |  origin\n",
      "     |  \n",
      "     |  processing_guarantee\n",
      "     |  \n",
      "     |  producer_api_version\n",
      "     |  \n",
      "     |  producer_partitioner\n",
      "     |  \n",
      "     |  producer_request_timeout\n",
      "     |  \n",
      "     |  reply_expires\n",
      "     |  \n",
      "     |  store\n",
      "     |  \n",
      "     |  stream_processing_timeout\n",
      "     |  \n",
      "     |  stream_recovery_delay\n",
      "     |  \n",
      "     |  table_cleanup_interval\n",
      "     |  \n",
      "     |  tabledir\n",
      "     |  \n",
      "     |  version\n",
      "     |  \n",
      "     |  web\n",
      "     |  \n",
      "     |  web_transport\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'_Agent': typing.Type[faust.types.agents.AgentT], '...\n",
      "     |  \n",
      "     |  autodiscover = False\n",
      "     |  \n",
      "     |  broker_api_version = 'auto'\n",
      "     |  \n",
      "     |  broker_check_crcs = True\n",
      "     |  \n",
      "     |  broker_client_id = 'faust-1.10.4'\n",
      "     |  \n",
      "     |  broker_commit_every = 10000\n",
      "     |  \n",
      "     |  broker_max_poll_interval = 1000.0\n",
      "     |  \n",
      "     |  consumer_auto_offset_reset = 'earliest'\n",
      "     |  \n",
      "     |  consumer_max_fetch_size = 1048576\n",
      "     |  \n",
      "     |  debug = False\n",
      "     |  \n",
      "     |  id_format = '{id}-v{self.version}'\n",
      "     |  \n",
      "     |  key_serializer = 'raw'\n",
      "     |  \n",
      "     |  logging_config = None\n",
      "     |  \n",
      "     |  producer_acks = -1\n",
      "     |  \n",
      "     |  producer_compression_type = None\n",
      "     |  \n",
      "     |  producer_linger_ms = 0\n",
      "     |  \n",
      "     |  producer_max_batch_size = 16384\n",
      "     |  \n",
      "     |  producer_max_request_size = 1000000\n",
      "     |  \n",
      "     |  reply_create_topic = False\n",
      "     |  \n",
      "     |  reply_to_prefix = 'f-reply-'\n",
      "     |  \n",
      "     |  ssl_context = None\n",
      "     |  \n",
      "     |  stream_ack_cancelled_tasks = True\n",
      "     |  \n",
      "     |  stream_ack_exceptions = True\n",
      "     |  \n",
      "     |  stream_buffer_maxsize = 4096\n",
      "     |  \n",
      "     |  stream_publish_on_commit = False\n",
      "     |  \n",
      "     |  stream_wait_empty = True\n",
      "     |  \n",
      "     |  table_key_index_size = 1000\n",
      "     |  \n",
      "     |  table_standby_replicas = 1\n",
      "     |  \n",
      "     |  timezone = datetime.timezone.utc\n",
      "     |  \n",
      "     |  topic_allow_declare = True\n",
      "     |  \n",
      "     |  topic_disable_leader = False\n",
      "     |  \n",
      "     |  topic_partitions = 8\n",
      "     |  \n",
      "     |  topic_replication_factor = 1\n",
      "     |  \n",
      "     |  value_serializer = 'json'\n",
      "     |  \n",
      "     |  web_bind = '0.0.0.0'\n",
      "     |  \n",
      "     |  web_cors_options = None\n",
      "     |  \n",
      "     |  web_host = 'user-ThinkPad-T490s'\n",
      "     |  \n",
      "     |  web_in_thread = False\n",
      "     |  \n",
      "     |  web_port = 6066\n",
      "     |  \n",
      "     |  worker_redirect_stdouts = True\n",
      "     |  \n",
      "     |  worker_redirect_stdouts_level = 'WARN'\n",
      "    \n",
      "    SlidingWindow = class _PySlidingWindow(Window)\n",
      "     |  SlidingWindow(before: Union[datetime.timedelta, float, str], after: Union[datetime.timedelta, float, str], expires: Union[datetime.timedelta, float, str]) -> None\n",
      "     |  \n",
      "     |  Sliding window type.\n",
      "     |  \n",
      "     |  Notes:\n",
      "     |      Fixed-size, overlapping windows that work on differences between\n",
      "     |      record timestamps\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      _PySlidingWindow\n",
      "     |      Window\n",
      "     |      faust.types.windows.WindowT\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, before: Union[datetime.timedelta, float, str], after: Union[datetime.timedelta, float, str], expires: Union[datetime.timedelta, float, str]) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  current(self, timestamp: float) -> Tuple[float, float]\n",
      "     |      Get the latest window range for a given timestamp.\n",
      "     |  \n",
      "     |  delta(self, timestamp: float, d: Union[datetime.timedelta, float, str]) -> Tuple[float, float]\n",
      "     |  \n",
      "     |  earliest(self, timestamp: float) -> Tuple[float, float]\n",
      "     |  \n",
      "     |  ranges(self, timestamp: float) -> List[Tuple[float, float]]\n",
      "     |      Return list of windows from timestamp.\n",
      "     |      \n",
      "     |      Notes:\n",
      "     |          .. sourcecode:: sql\n",
      "     |      \n",
      "     |              SELECT *\n",
      "     |                FROM s1, s2\n",
      "     |              WHERE\n",
      "     |                  s1.key = s2.key\n",
      "     |              AND\n",
      "     |              s1.ts - before <= s2.ts AND s2.ts <= s1.ts + after\n",
      "     |  \n",
      "     |  stale(self, timestamp: float, latest_timestamp: float) -> bool\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'after': <class 'float'>, 'before': <class 'float'>...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from faust.types.windows.WindowT:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from faust.types.windows.WindowT:\n",
      "     |  \n",
      "     |  expires = None\n",
      "     |  \n",
      "     |  tz = None\n",
      "    \n",
      "    class Stream(faust.types.streams.StreamT, mode.services.Service)\n",
      "     |  Stream(*args, **kwds)\n",
      "     |  \n",
      "     |  A stream: async iterator processing events in channels/topics.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Stream\n",
      "     |      faust.types.streams.StreamT\n",
      "     |      collections.abc.AsyncIterable\n",
      "     |      faust.types.streams.JoinableT\n",
      "     |      mode.services.Service\n",
      "     |      mode.services.ServiceBase\n",
      "     |      mode.types.services.ServiceT\n",
      "     |      contextlib.AbstractAsyncContextManager\n",
      "     |      abc.ABC\n",
      "     |      typing.Generic\n",
      "     |      mode.services.ServiceCallbacks\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __aiter__(self) -> AsyncIterator[+T_co]\n",
      "     |  \n",
      "     |  __and__(self, other: Any) -> Any\n",
      "     |  \n",
      "     |  async __anext__(self) -> ~T\n",
      "     |  \n",
      "     |  __copy__(self) -> Any\n",
      "     |  \n",
      "     |  __init__(self, channel: AsyncIterator[+T_co], *, app: faust.types.app.AppT, processors: Iterable[Callable[[~T], Union[~T, Awaitable[~T]]]] = None, combined: List[faust.types.streams.JoinableT] = None, on_start: Callable = None, join_strategy: faust.types.joins.JoinT = None, beacon: mode.utils.types.trees.NodeT = None, concurrency_index: int = None, prev: faust.types.streams.StreamT = None, active_partitions: Set[faust.types.tuples.TP] = None, enable_acks: bool = True, prefix: str = '', loop: asyncio.events.AbstractEventLoop = None) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __iter__(self) -> Any\n",
      "     |  \n",
      "     |  __next__(self) -> ~T\n",
      "     |  \n",
      "     |  async ack(self, event: faust.types.events.EventT) -> bool\n",
      "     |      Ack event.\n",
      "     |      \n",
      "     |      This will decrease the reference count of the event message by one,\n",
      "     |      and when the reference count reaches zero, the worker will\n",
      "     |      commit the offset so that the message will not be seen by a worker\n",
      "     |      again.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          event: Event to ack.\n",
      "     |  \n",
      "     |  add_processor(self, processor: Callable[[~T], Union[~T, Awaitable[~T]]]) -> None\n",
      "     |      Add processor callback executed whenever a new event is received.\n",
      "     |      \n",
      "     |      Processor functions can be async or non-async, must accept\n",
      "     |      a single argument, and should return the value, mutated or not.\n",
      "     |      \n",
      "     |      For example a processor handling a stream of numbers may modify\n",
      "     |      the value::\n",
      "     |      \n",
      "     |          def double(value: int) -> int:\n",
      "     |              return value * 2\n",
      "     |      \n",
      "     |          stream.add_processor(double)\n",
      "     |  \n",
      "     |  clone(self, **kwargs: Any) -> faust.types.streams.StreamT\n",
      "     |      Create a clone of this stream.\n",
      "     |      \n",
      "     |      Notes:\n",
      "     |          If the cloned stream is supposed to supersede this stream,\n",
      "     |          like in ``group_by``/``through``/etc., you should use\n",
      "     |          :meth:`_chain` instead so `stream._next = cloned_stream`\n",
      "     |          is set and :meth:`get_active_stream` returns the cloned stream.\n",
      "     |  \n",
      "     |  combine(self, *nodes: faust.types.streams.JoinableT, **kwargs: Any) -> faust.types.streams.StreamT\n",
      "     |      Combine streams and tables into joined stream.\n",
      "     |  \n",
      "     |  contribute_to_stream(self, active: faust.types.streams.StreamT) -> None\n",
      "     |      Add stream as node in joined stream.\n",
      "     |  \n",
      "     |  derive_topic(self, name: str, *, schema: faust.types.serializers.SchemaT = None, key_type: Union[Type[faust.types.models.ModelT], Type[bytes], Type[str]] = None, value_type: Union[Type[faust.types.models.ModelT], Type[bytes], Type[str]] = None, prefix: str = '', suffix: str = '') -> faust.types.topics.TopicT\n",
      "     |      Create Topic description derived from the K/V type of this stream.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          name: Topic name.\n",
      "     |      \n",
      "     |          key_type: Specific key type to use for this topic.\n",
      "     |              If not set, the key type of this stream will be used.\n",
      "     |          value_type: Specific value type to use for this topic.\n",
      "     |              If not set, the value type of this stream will be used.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          ValueError: if the stream channel is not a topic.\n",
      "     |  \n",
      "     |  echo(self, *channels: Union[str, faust.types.channels.ChannelT]) -> faust.types.streams.StreamT\n",
      "     |      Forward values to one or more channels.\n",
      "     |      \n",
      "     |      Unlike :meth:`through`, we don't consume from these channels.\n",
      "     |  \n",
      "     |  enumerate(self, start: int = 0) -> AsyncIterable[Tuple[int, +T_co]]\n",
      "     |      Enumerate values received on this stream.\n",
      "     |      \n",
      "     |      Unlike Python's built-in ``enumerate``, this works with\n",
      "     |      async generators.\n",
      "     |  \n",
      "     |  async events(self) -> AsyncIterable[faust.types.events.EventT]\n",
      "     |      Iterate over the stream as events exclusively.\n",
      "     |      \n",
      "     |      This means the stream must be iterating over a channel,\n",
      "     |      or at least an iterable of event objects.\n",
      "     |  \n",
      "     |  filter(self, fun: Callable[[~T], Union[~T, Awaitable[~T]]]) -> faust.types.streams.StreamT\n",
      "     |      Filter values from stream using callback.\n",
      "     |      \n",
      "     |      The callback may be a traditional function, lambda function,\n",
      "     |      or an `async def` function.\n",
      "     |      \n",
      "     |      This method is useful for filtering events before repartitioning\n",
      "     |      a stream.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |          >>> async for v in stream.filter(lambda: v > 1000).group_by(...):\n",
      "     |          ...     # do something\n",
      "     |  \n",
      "     |  get_active_stream(self) -> faust.types.streams.StreamT\n",
      "     |      Return the currently active stream.\n",
      "     |      \n",
      "     |      A stream can be derived using ``Stream.group_by`` etc,\n",
      "     |      so if this stream was used to create another derived\n",
      "     |      stream, this function will return the stream being actively\n",
      "     |      consumed from.  E.g. in the example::\n",
      "     |      \n",
      "     |          >>> @app.agent()\n",
      "     |          ... async def agent(a):\n",
      "     |          ..      a = a\n",
      "     |          ...     b = a.group_by(Withdrawal.account_id)\n",
      "     |          ...     c = b.through('backup_topic')\n",
      "     |          ...     async for value in c:\n",
      "     |          ...         ...\n",
      "     |      \n",
      "     |      The return value of ``a.get_active_stream()`` would be ``c``.\n",
      "     |      \n",
      "     |      Notes:\n",
      "     |          The chain of streams that leads to the active stream\n",
      "     |          is decided by the :attr:`_next` attribute. To get\n",
      "     |          to the active stream we just traverse this linked-list::\n",
      "     |      \n",
      "     |              >>> def get_active_stream(self):\n",
      "     |              ...     node = self\n",
      "     |              ...     while node._next:\n",
      "     |              ...         node = node._next\n",
      "     |  \n",
      "     |  get_root_stream(self) -> faust.types.streams.StreamT\n",
      "     |      Get the root stream that this stream was derived from.\n",
      "     |  \n",
      "     |  group_by(self, key: Union[faust.types.models.FieldDescriptorT, Callable[[~T], Union[bytes, faust.types.core._ModelT, Any, NoneType]]], *, name: str = None, topic: faust.types.topics.TopicT = None, partitions: int = None) -> faust.types.streams.StreamT\n",
      "     |      Create new stream that repartitions the stream using a new key.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          key: The key argument decides how the new key is generated,\n",
      "     |              it can be a field descriptor, a callable, or an async\n",
      "     |              callable.\n",
      "     |      \n",
      "     |              Note: The ``name`` argument must be provided if the key\n",
      "     |                  argument is a callable.\n",
      "     |      \n",
      "     |          name: Suffix to use for repartitioned topics.\n",
      "     |              This argument is required if `key` is a callable.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |          Using a field descriptor to use a field in the event as the new\n",
      "     |          key:\n",
      "     |      \n",
      "     |          .. sourcecode:: python\n",
      "     |      \n",
      "     |              s = withdrawals_topic.stream()\n",
      "     |              # values in this stream are of type Withdrawal\n",
      "     |              async for event in s.group_by(Withdrawal.account_id):\n",
      "     |                  ...\n",
      "     |      \n",
      "     |          Using an async callable to extract a new key:\n",
      "     |      \n",
      "     |          .. sourcecode:: python\n",
      "     |      \n",
      "     |              s = withdrawals_topic.stream()\n",
      "     |      \n",
      "     |              async def get_key(withdrawal):\n",
      "     |                  return await aiohttp.get(\n",
      "     |                      f'http://e.com/resolve_account/{withdrawal.account_id}')\n",
      "     |      \n",
      "     |              async for event in s.group_by(get_key):\n",
      "     |                  ...\n",
      "     |      \n",
      "     |          Using a regular callable to extract a new key:\n",
      "     |      \n",
      "     |          .. sourcecode:: python\n",
      "     |      \n",
      "     |              s = withdrawals_topic.stream()\n",
      "     |      \n",
      "     |              def get_key(withdrawal):\n",
      "     |                  return withdrawal.account_id.upper()\n",
      "     |      \n",
      "     |              async for event in s.group_by(get_key):\n",
      "     |                  ...\n",
      "     |  \n",
      "     |  info(self) -> Mapping[str, Any]\n",
      "     |      Return stream settings as a dictionary.\n",
      "     |  \n",
      "     |  inner_join(self, *fields: faust.types.models.FieldDescriptorT) -> faust.types.streams.StreamT\n",
      "     |      Create stream where events are joined by INNER JOIN.\n",
      "     |  \n",
      "     |  async items(self) -> AsyncIterator[Tuple[Union[bytes, faust.types.core._ModelT, Any, NoneType], +T_co]]\n",
      "     |      Iterate over the stream as ``key, value`` pairs.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |          .. sourcecode:: python\n",
      "     |      \n",
      "     |              @app.agent(topic)\n",
      "     |              async def mytask(stream):\n",
      "     |                  async for key, value in stream.items():\n",
      "     |                      print(key, value)\n",
      "     |  \n",
      "     |  join(self, *fields: faust.types.models.FieldDescriptorT) -> faust.types.streams.StreamT\n",
      "     |      Create stream where events are joined.\n",
      "     |  \n",
      "     |  left_join(self, *fields: faust.types.models.FieldDescriptorT) -> faust.types.streams.StreamT\n",
      "     |      Create stream where events are joined by LEFT JOIN.\n",
      "     |  \n",
      "     |  noack(self) -> 'StreamT'\n",
      "     |      Create new stream where acks are manual.\n",
      "     |  \n",
      "     |  async on_merge(self, value: ~T = None) -> Union[~T, NoneType]\n",
      "     |      Signal called when an event is to be joined.\n",
      "     |  \n",
      "     |  async on_start(self) -> None\n",
      "     |      Signal called when the stream starts.\n",
      "     |  \n",
      "     |  async on_stop(self) -> None\n",
      "     |      Signal that the stream is stopping.\n",
      "     |  \n",
      "     |  outer_join(self, *fields: faust.types.models.FieldDescriptorT) -> faust.types.streams.StreamT\n",
      "     |      Create stream where events are joined by OUTER JOIN.\n",
      "     |  \n",
      "     |  async remove_from_stream(self, stream: faust.types.streams.StreamT) -> None\n",
      "     |      Remove as node in a joined stream.\n",
      "     |  \n",
      "     |  async stop(self) -> None\n",
      "     |      Stop this stream.\n",
      "     |  \n",
      "     |  async take(self, max_: int, within: Union[datetime.timedelta, float, str]) -> AsyncIterable[Sequence[+T_co]]\n",
      "     |      Buffer n values at a time and yield a list of buffered values.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          max_: Max number of messages to receive. When more than this\n",
      "     |              number of messages are received within the specified number of\n",
      "     |              seconds then we flush the buffer immediately.\n",
      "     |          within: Timeout for when we give up waiting for another value,\n",
      "     |              and process the values we have.\n",
      "     |              Warning: If there's no timeout (i.e. `timeout=None`),\n",
      "     |              the agent is likely to stall and block buffered events for an\n",
      "     |              unreasonable length of time(!).\n",
      "     |  \n",
      "     |  through(self, channel: Union[str, faust.types.channels.ChannelT]) -> faust.types.streams.StreamT\n",
      "     |      Forward values to in this stream to channel.\n",
      "     |      \n",
      "     |      Send messages received on this stream to another channel,\n",
      "     |      and return a new stream that consumes from that channel.\n",
      "     |      \n",
      "     |      Notes:\n",
      "     |          The messages are forwarded after any processors have been\n",
      "     |          applied.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. sourcecode:: python\n",
      "     |      \n",
      "     |              topic = app.topic('foo')\n",
      "     |      \n",
      "     |              @app.agent(topic)\n",
      "     |              async def mytask(stream):\n",
      "     |                  async for value in stream.through(app.topic('bar')):\n",
      "     |                      # value was first received in topic 'foo',\n",
      "     |                      # then forwarded and consumed from topic 'bar'\n",
      "     |                      print(value)\n",
      "     |  \n",
      "     |  async throw(self, exc: BaseException) -> None\n",
      "     |      Send exception to stream iteration.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  label\n",
      "     |      Return description of stream, used in graphs and logs.\n",
      "     |  \n",
      "     |  shortlabel\n",
      "     |      Return short description of stream.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'_passive_started': <class 'asyncio.locks.Event'>, ...\n",
      "     |  \n",
      "     |  __orig_bases__ = (faust.types.streams.StreamT[+T_co], <class 'mode.ser...\n",
      "     |  \n",
      "     |  events_total = 0\n",
      "     |  \n",
      "     |  logger = <Logger faust.streams (INFO)>\n",
      "     |  \n",
      "     |  mundane_level = 'debug'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from faust.types.streams.StreamT:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from faust.types.streams.StreamT:\n",
      "     |  \n",
      "     |  __parameters__ = (+T_co,)\n",
      "     |  \n",
      "     |  active_partitions = None\n",
      "     |  \n",
      "     |  concurrency_index = None\n",
      "     |  \n",
      "     |  current_event = None\n",
      "     |  \n",
      "     |  enable_acks = True\n",
      "     |  \n",
      "     |  join_strategy = None\n",
      "     |  \n",
      "     |  outbox = None\n",
      "     |  \n",
      "     |  prefix = ''\n",
      "     |  \n",
      "     |  task_owner = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from collections.abc.AsyncIterable:\n",
      "     |  \n",
      "     |  __subclasshook__(C) from abc.ABCMeta\n",
      "     |      Abstract classes can override this to customize issubclass().\n",
      "     |      \n",
      "     |      This is invoked early on by abc.ABCMeta.__subclasscheck__().\n",
      "     |      It should return True, False or NotImplemented.  If it returns\n",
      "     |      NotImplemented, the normal algorithm is used.  Otherwise, it\n",
      "     |      overrides the normal algorithm (and the outcome is cached).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  __post_init__(self) -> None\n",
      "     |      Additional user initialization.\n",
      "     |  \n",
      "     |  async add_async_context(self, context: AbstractAsyncContextManager) -> Any\n",
      "     |  \n",
      "     |  add_context(self, context: AbstractContextManager) -> Any\n",
      "     |  \n",
      "     |  add_dependency(self, service: mode.types.services.ServiceT) -> mode.types.services.ServiceT\n",
      "     |      Add dependency to other service.\n",
      "     |      \n",
      "     |      The service will be started/stopped with this service.\n",
      "     |  \n",
      "     |  add_future(self, coro: Awaitable) -> _asyncio.Future\n",
      "     |      Add relationship to asyncio.Future.\n",
      "     |      \n",
      "     |      The future will be joined when this service is stopped.\n",
      "     |  \n",
      "     |  async add_runtime_dependency(self, service: mode.types.services.ServiceT) -> mode.types.services.ServiceT\n",
      "     |  \n",
      "     |  async crash(self, reason: BaseException) -> None\n",
      "     |      Crash the service and all child services.\n",
      "     |  \n",
      "     |  async itertimer(self, interval: Union[datetime.timedelta, float, str], *, max_drift_correction: float = 0.1, loop: asyncio.events.AbstractEventLoop = None, sleep: Callable[..., Awaitable] = None, clock: Callable[[], float] = <built-in function perf_counter>, name: str = '') -> AsyncIterator[float]\n",
      "     |      Sleep ``interval`` seconds for every iteration.\n",
      "     |      \n",
      "     |      This is an async iterator that takes advantage\n",
      "     |      of :func:`~mode.timers.Timer` to monitor drift and timer\n",
      "     |      oerlap.\n",
      "     |      \n",
      "     |      Uses ``Service.sleep`` so exits fast when the service is\n",
      "     |      stopped.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          Will sleep the full `interval` seconds before returning\n",
      "     |          from first iteration.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |          >>> async for sleep_time in self.itertimer(1.0):\n",
      "     |          ...   print('another second passed, just woke up...')\n",
      "     |          ...   await perform_some_http_request()\n",
      "     |  \n",
      "     |  async join_services(self, services: Sequence[mode.types.services.ServiceT]) -> None\n",
      "     |  \n",
      "     |  async maybe_start(self) -> bool\n",
      "     |      Start the service, if it has not already been started.\n",
      "     |  \n",
      "     |  on_init(self) -> None\n",
      "     |  \n",
      "     |  on_init_dependencies(self) -> Iterable[mode.types.services.ServiceT]\n",
      "     |      Return list of service dependencies for this service.\n",
      "     |  \n",
      "     |  async remove_dependency(self, service: mode.types.services.ServiceT) -> mode.types.services.ServiceT\n",
      "     |      Stop and remove dependency of this service.\n",
      "     |  \n",
      "     |  async restart(self) -> None\n",
      "     |      Restart this service.\n",
      "     |  \n",
      "     |  service_reset(self) -> None\n",
      "     |  \n",
      "     |  set_shutdown(self) -> None\n",
      "     |      Set the shutdown signal.\n",
      "     |      \n",
      "     |      Notes:\n",
      "     |          If :attr:`wait_for_shutdown` is set, stopping the service\n",
      "     |          will wait for this flag to be set.\n",
      "     |  \n",
      "     |  async sleep(self, n: Union[datetime.timedelta, float, str], *, loop: asyncio.events.AbstractEventLoop = None) -> None\n",
      "     |      Sleep for ``n`` seconds, or until service stopped.\n",
      "     |  \n",
      "     |  async start(self) -> None\n",
      "     |  \n",
      "     |  async transition_with(self, flag: str, fut: Awaitable, *args: Any, **kwargs: Any) -> Any\n",
      "     |  \n",
      "     |  async wait(self, *coros: Union[_asyncio.Future, Generator[Any, NoneType, Any], Awaitable, asyncio.locks.Event, mode.utils.locks.Event], timeout: Union[datetime.timedelta, float, str] = None) -> mode.services.WaitResult\n",
      "     |      Wait for coroutines to complete, or until the service stops.\n",
      "     |  \n",
      "     |  async wait_first(self, *coros: Union[_asyncio.Future, Generator[Any, NoneType, Any], Awaitable, asyncio.locks.Event, mode.utils.locks.Event], timeout: Union[datetime.timedelta, float, str] = None) -> mode.services.WaitResults\n",
      "     |  \n",
      "     |  async wait_for_stopped(self, *coros: Union[_asyncio.Future, Generator[Any, NoneType, Any], Awaitable, asyncio.locks.Event, mode.utils.locks.Event], timeout: Union[datetime.timedelta, float, str] = None) -> bool\n",
      "     |  \n",
      "     |  async wait_many(self, coros: Iterable[Union[_asyncio.Future, Generator[Any, NoneType, Any], Awaitable, asyncio.locks.Event, mode.utils.locks.Event]], *, timeout: Union[datetime.timedelta, float, str] = None) -> mode.services.WaitResult\n",
      "     |  \n",
      "     |  async wait_until_stopped(self) -> None\n",
      "     |      Wait until the service is signalled to stop.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  __init_subclass__() -> None from abc.ABCMeta\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  from_awaitable(coro: Awaitable, *, name: str = None, **kwargs: Any) -> mode.types.services.ServiceT from abc.ABCMeta\n",
      "     |  \n",
      "     |  task(fun: Callable[[Any], Awaitable[NoneType]]) -> mode.services.ServiceTask from abc.ABCMeta\n",
      "     |      Decorate function to be used as background task.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> class S(Service):\n",
      "     |          ...\n",
      "     |          ...     @Service.task\n",
      "     |          ...     async def background_task(self):\n",
      "     |          ...         while not self.should_stop:\n",
      "     |          ...             await self.sleep(1.0)\n",
      "     |          ...             print('Waking up')\n",
      "     |  \n",
      "     |  timer(interval: Union[datetime.timedelta, float, str]) -> Callable[[Callable], mode.services.ServiceTask] from abc.ABCMeta\n",
      "     |      Background timer executing every ``n`` seconds.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> class S(Service):\n",
      "     |          ...\n",
      "     |          ...     @Service.timer(1.0)\n",
      "     |          ...     async def background_timer(self):\n",
      "     |          ...         print('Waking up')\n",
      "     |  \n",
      "     |  transitions_to(flag: str) -> Callable from abc.ABCMeta\n",
      "     |      Decorate function to set and reset diagnostic flag.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  crashed\n",
      "     |  \n",
      "     |  should_stop\n",
      "     |      Return :const:`True` if the service must stop.\n",
      "     |  \n",
      "     |  started\n",
      "     |      Return :const:`True` if the service was started.\n",
      "     |  \n",
      "     |  state\n",
      "     |      Service state - as a human readable string.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  beacon\n",
      "     |      Beacon used to track services in a dependency graph.\n",
      "     |  \n",
      "     |  crash_reason\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  Diag = <class 'mode.services.Diag'>\n",
      "     |      Service diagnostics.\n",
      "     |      \n",
      "     |      This can be used to track what your service is doing.\n",
      "     |      For example if your service is a Kafka consumer with a background\n",
      "     |      thread that commits the offset every 30 seconds, you may want to\n",
      "     |      see when this happens::\n",
      "     |      \n",
      "     |          DIAG_COMMITTING = 'committing'\n",
      "     |      \n",
      "     |          class Consumer(Service):\n",
      "     |      \n",
      "     |              @Service.task\n",
      "     |              async def _background_commit(self) -> None:\n",
      "     |                  while not self.should_stop:\n",
      "     |                      await self.sleep(30.0)\n",
      "     |                      self.diag.set_flag(DIAG_COMITTING)\n",
      "     |                      try:\n",
      "     |                          await self._consumer.commit()\n",
      "     |                      finally:\n",
      "     |                          self.diag.unset_flag(DIAG_COMMITTING)\n",
      "     |      \n",
      "     |      The above code is setting the flag manually, but you can also use\n",
      "     |      a decorator to accomplish the same thing::\n",
      "     |      \n",
      "     |          @Service.timer(30.0)\n",
      "     |          async def _background_commit(self) -> None:\n",
      "     |              await self.commit()\n",
      "     |      \n",
      "     |          @Service.transitions_with(DIAG_COMITTING)\n",
      "     |          async def commit(self) -> None:\n",
      "     |              await self._consumer.commit()\n",
      "     |  \n",
      "     |  abstract = False\n",
      "     |  \n",
      "     |  restart_count = 0\n",
      "     |  \n",
      "     |  shutdown_timeout = 60.0\n",
      "     |  \n",
      "     |  wait_for_shutdown = False\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mode.services.ServiceBase:\n",
      "     |  \n",
      "     |  async __aenter__(self) -> mode.types.services.ServiceT\n",
      "     |      Return `self` upon entering the runtime context.\n",
      "     |  \n",
      "     |  async __aexit__(self, exc_type: Type[BaseException] = None, exc_val: BaseException = None, exc_tb: traceback = None) -> Union[bool, NoneType]\n",
      "     |      Raise any exception triggered within the runtime context.\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from mode.services.ServiceBase:\n",
      "     |  \n",
      "     |  loop\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from mode.types.services.ServiceT:\n",
      "     |  \n",
      "     |  supervisor = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from abc.ABCMeta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mode.services.ServiceCallbacks:\n",
      "     |  \n",
      "     |  async on_first_start(self) -> None\n",
      "     |      Service started for the first time in this process.\n",
      "     |  \n",
      "     |  async on_restart(self) -> None\n",
      "     |      Service is being restarted.\n",
      "     |  \n",
      "     |  async on_shutdown(self) -> None\n",
      "     |      Service is being stopped/restarted.\n",
      "     |  \n",
      "     |  async on_started(self) -> None\n",
      "     |      Service has started.\n",
      "    \n",
      "    class StreamT(collections.abc.AsyncIterable, JoinableT, mode.types.services.ServiceT)\n",
      "     |  StreamT(*args, **kwds)\n",
      "     |  \n",
      "     |  Abstract type for an asynchronous service that can be started/stopped.\n",
      "     |  \n",
      "     |  See Also:\n",
      "     |      :class:`mode.Service`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      StreamT\n",
      "     |      collections.abc.AsyncIterable\n",
      "     |      JoinableT\n",
      "     |      mode.types.services.ServiceT\n",
      "     |      contextlib.AbstractAsyncContextManager\n",
      "     |      abc.ABC\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __aiter__(self) -> AsyncIterator[+T_co]\n",
      "     |  \n",
      "     |  __copy__(self) -> 'StreamT'\n",
      "     |  \n",
      "     |  __init__(self, channel: AsyncIterator[+T_co] = None, *, app: faust.types.streams._AppT = None, processors: Iterable[Callable[[~T], Union[~T, Awaitable[~T]]]] = None, combined: List[faust.types.streams.JoinableT] = None, on_start: Callable = None, join_strategy: faust.types.streams._JoinT = None, beacon: mode.utils.types.trees.NodeT = None, concurrency_index: int = None, prev: 'StreamT' = None, active_partitions: Set[faust.types.tuples.TP] = None, enable_acks: bool = True, prefix: str = '', loop: asyncio.events.AbstractEventLoop = None) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __iter__(self) -> Any\n",
      "     |  \n",
      "     |  __next__(self) -> ~T\n",
      "     |  \n",
      "     |  async ack(self, event: faust.types.events.EventT) -> bool\n",
      "     |  \n",
      "     |  add_processor(self, processor: Callable[[~T], Union[~T, Awaitable[~T]]]) -> None\n",
      "     |  \n",
      "     |  clone(self, **kwargs: Any) -> 'StreamT'\n",
      "     |  \n",
      "     |  derive_topic(self, name: str, *, schema: faust.types.streams._SchemaT = None, key_type: Union[Type[faust.types.models.ModelT], Type[bytes], Type[str]] = None, value_type: Union[Type[faust.types.models.ModelT], Type[bytes], Type[str]] = None, prefix: str = '', suffix: str = '') -> faust.types.topics.TopicT\n",
      "     |  \n",
      "     |  echo(self, *channels: Union[str, faust.types.channels.ChannelT]) -> 'StreamT'\n",
      "     |  \n",
      "     |  enumerate(self, start: int = 0) -> AsyncIterable[Tuple[int, +T_co]]\n",
      "     |  \n",
      "     |  async events(self) -> AsyncIterable[faust.types.events.EventT]\n",
      "     |  \n",
      "     |  get_active_stream(self) -> 'StreamT'\n",
      "     |  \n",
      "     |  group_by(self, key: Union[faust.types.models.FieldDescriptorT, Callable[[~T], Union[bytes, faust.types.core._ModelT, Any, NoneType]]], *, name: str = None, topic: faust.types.topics.TopicT = None) -> 'StreamT'\n",
      "     |  \n",
      "     |  info(self) -> Mapping[str, Any]\n",
      "     |  \n",
      "     |  async items(self) -> AsyncIterator[Tuple[Union[bytes, faust.types.core._ModelT, Any, NoneType], +T_co]]\n",
      "     |  \n",
      "     |  async take(self, max_: int, within: Union[datetime.timedelta, float, str]) -> AsyncIterable[Sequence[+T_co]]\n",
      "     |  \n",
      "     |  through(self, channel: Union[str, faust.types.channels.ChannelT]) -> 'StreamT'\n",
      "     |  \n",
      "     |  async throw(self, exc: BaseException) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset({'__aexit__', '__aiter__', '__and__', ...\n",
      "     |  \n",
      "     |  __annotations__ = {'_next': typing.Union[ForwardRef('StreamT'), NoneTy...\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.AsyncIterable[+T_co], <class 'faust.types.str...\n",
      "     |  \n",
      "     |  __parameters__ = (+T_co,)\n",
      "     |  \n",
      "     |  active_partitions = None\n",
      "     |  \n",
      "     |  concurrency_index = None\n",
      "     |  \n",
      "     |  current_event = None\n",
      "     |  \n",
      "     |  enable_acks = True\n",
      "     |  \n",
      "     |  join_strategy = None\n",
      "     |  \n",
      "     |  outbox = None\n",
      "     |  \n",
      "     |  prefix = ''\n",
      "     |  \n",
      "     |  task_owner = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from collections.abc.AsyncIterable:\n",
      "     |  \n",
      "     |  __subclasshook__(C) from abc.ABCMeta\n",
      "     |      Abstract classes can override this to customize issubclass().\n",
      "     |      \n",
      "     |      This is invoked early on by abc.ABCMeta.__subclasscheck__().\n",
      "     |      It should return True, False or NotImplemented.  If it returns\n",
      "     |      NotImplemented, the normal algorithm is used.  Otherwise, it\n",
      "     |      overrides the normal algorithm (and the outcome is cached).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from JoinableT:\n",
      "     |  \n",
      "     |  __and__(self, other: Any) -> Any\n",
      "     |  \n",
      "     |  combine(self, *nodes: 'JoinableT', **kwargs: Any) -> 'StreamT'\n",
      "     |  \n",
      "     |  contribute_to_stream(self, active: 'StreamT') -> None\n",
      "     |  \n",
      "     |  inner_join(self, *fields: faust.types.models.FieldDescriptorT) -> 'StreamT'\n",
      "     |  \n",
      "     |  join(self, *fields: faust.types.models.FieldDescriptorT) -> 'StreamT'\n",
      "     |  \n",
      "     |  left_join(self, *fields: faust.types.models.FieldDescriptorT) -> 'StreamT'\n",
      "     |  \n",
      "     |  outer_join(self, *fields: faust.types.models.FieldDescriptorT) -> 'StreamT'\n",
      "     |  \n",
      "     |  async remove_from_stream(self, stream: 'StreamT') -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mode.types.services.ServiceT:\n",
      "     |  \n",
      "     |  async add_async_context(self, context: AbstractAsyncContextManager) -> Any\n",
      "     |  \n",
      "     |  add_context(self, context: AbstractContextManager) -> Any\n",
      "     |  \n",
      "     |  add_dependency(self, service: 'ServiceT') -> 'ServiceT'\n",
      "     |  \n",
      "     |  async add_runtime_dependency(self, service: 'ServiceT') -> 'ServiceT'\n",
      "     |  \n",
      "     |  async crash(self, reason: BaseException) -> None\n",
      "     |  \n",
      "     |  async maybe_start(self) -> bool\n",
      "     |  \n",
      "     |  async restart(self) -> None\n",
      "     |  \n",
      "     |  service_reset(self) -> None\n",
      "     |  \n",
      "     |  set_shutdown(self) -> None\n",
      "     |  \n",
      "     |  async start(self) -> None\n",
      "     |  \n",
      "     |  async stop(self) -> None\n",
      "     |  \n",
      "     |  async wait_until_stopped(self) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from mode.types.services.ServiceT:\n",
      "     |  \n",
      "     |  crashed\n",
      "     |  \n",
      "     |  label\n",
      "     |  \n",
      "     |  shortlabel\n",
      "     |  \n",
      "     |  should_stop\n",
      "     |  \n",
      "     |  started\n",
      "     |  \n",
      "     |  state\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from mode.types.services.ServiceT:\n",
      "     |  \n",
      "     |  beacon\n",
      "     |  \n",
      "     |  crash_reason\n",
      "     |  \n",
      "     |  loop\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from mode.types.services.ServiceT:\n",
      "     |  \n",
      "     |  restart_count = 0\n",
      "     |  \n",
      "     |  supervisor = None\n",
      "     |  \n",
      "     |  wait_for_shutdown = False\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from contextlib.AbstractAsyncContextManager:\n",
      "     |  \n",
      "     |  async __aenter__(self)\n",
      "     |      Return `self` upon entering the runtime context.\n",
      "     |  \n",
      "     |  async __aexit__(self, exc_type, exc_value, traceback)\n",
      "     |      Raise any exception triggered within the runtime context.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from abc.ABCMeta\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from abc.ABCMeta\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Table(faust.types.tables.TableT, faust.tables.base.Collection)\n",
      "     |  Table(*args, **kwds)\n",
      "     |  \n",
      "     |  Table (non-windowed).\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Table\n",
      "     |      faust.types.tables.TableT\n",
      "     |      faust.tables.base.Collection\n",
      "     |      mode.services.Service\n",
      "     |      mode.services.ServiceBase\n",
      "     |      faust.types.tables.CollectionT\n",
      "     |      mode.types.services.ServiceT\n",
      "     |      contextlib.AbstractAsyncContextManager\n",
      "     |      faust.types.streams.JoinableT\n",
      "     |      abc.ABC\n",
      "     |      mode.utils.collections.ManagedUserDict\n",
      "     |      mode.utils.collections.FastUserDict\n",
      "     |      collections.abc.MutableMapping\n",
      "     |      collections.abc.Mapping\n",
      "     |      collections.abc.Collection\n",
      "     |      collections.abc.Sized\n",
      "     |      collections.abc.Iterable\n",
      "     |      collections.abc.Container\n",
      "     |      typing.Generic\n",
      "     |      mode.services.ServiceCallbacks\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __missing__(self, key: ~KT) -> ~VT\n",
      "     |  \n",
      "     |  as_ansitable(self, title: str = '{table.name}', **kwargs: Any) -> str\n",
      "     |      Draw table as a a terminal ANSI table.\n",
      "     |  \n",
      "     |  hopping(self, size: Union[datetime.timedelta, float, str], step: Union[datetime.timedelta, float, str], expires: Union[datetime.timedelta, float, str] = None, key_index: bool = False) -> faust.types.tables.WindowWrapperT\n",
      "     |      Wrap table in a hopping window.\n",
      "     |  \n",
      "     |  on_key_del(self, key: ~KT) -> None\n",
      "     |      Call when a key in this table is removed.\n",
      "     |  \n",
      "     |  on_key_get(self, key: ~KT) -> None\n",
      "     |      Call when the value for a key in this table is retrieved.\n",
      "     |  \n",
      "     |  on_key_set(self, key: ~KT, value: ~VT) -> None\n",
      "     |      Call when the value for a key in this table is set.\n",
      "     |  \n",
      "     |  tumbling(self, size: Union[datetime.timedelta, float, str], expires: Union[datetime.timedelta, float, str] = None, key_index: bool = False) -> faust.types.tables.WindowWrapperT\n",
      "     |      Wrap table in a tumbling window.\n",
      "     |  \n",
      "     |  using_window(self, window: faust.types.windows.WindowT, *, key_index: bool = False) -> faust.types.tables.WindowWrapperT\n",
      "     |      Wrap table using a specific window type.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  WindowWrapper = <class 'faust.tables.wrappers.WindowWrapper'>\n",
      "     |      Windowed table wrapper.\n",
      "     |      \n",
      "     |      A windowed table does not return concrete values when keys are\n",
      "     |      accessed, instead :class:`WindowSet` is returned so that\n",
      "     |      the values can be further reduced to the wanted time period.\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'WindowWrapper': typing.ClassVar[typing.Type[faust....\n",
      "     |  \n",
      "     |  __orig_bases__ = (faust.types.tables.TableT[~KT, ~VT], <class 'faust.t...\n",
      "     |  \n",
      "     |  logger = <Logger faust.tables.table (INFO)>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from faust.types.tables.TableT:\n",
      "     |  \n",
      "     |  __parameters__ = (~KT, ~VT)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from faust.tables.base.Collection:\n",
      "     |  \n",
      "     |  __and__(self, other: Any) -> Any\n",
      "     |  \n",
      "     |  __copy__(self) -> Any\n",
      "     |  \n",
      "     |  __hash__(self) -> int\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __init__(self, app: faust.types.app.AppT, *, name: str = None, default: Callable[[], Any] = None, store: Union[str, yarl.URL] = None, schema: faust.types.serializers.SchemaT = None, key_type: Union[Type[faust.types.models.ModelT], Type[bytes], Type[str]] = None, value_type: Union[Type[faust.types.models.ModelT], Type[bytes], Type[str]] = None, partitions: int = None, window: faust.types.windows.WindowT = None, changelog_topic: faust.types.topics.TopicT = None, help: str = None, on_recover: Callable[[], Awaitable[NoneType]] = None, on_changelog_event: Callable[[faust.types.events.EventT], Awaitable[NoneType]] = None, recovery_buffer_size: int = 1000, standby_buffer_size: int = None, extra_topic_configs: Mapping[str, Any] = None, recover_callbacks: Set[Callable[[], Awaitable[NoneType]]] = None, options: Mapping[str, Any] = None, use_partitioner: bool = False, on_window_close: Callable[[Any, Any], NoneType] = None, is_global: bool = False, **kwargs: Any) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  apply_changelog_batch(self, batch: Iterable[faust.types.events.EventT]) -> None\n",
      "     |      Apply batch of events from changelog topic local table storage.\n",
      "     |  \n",
      "     |  async call_recover_callbacks(self) -> None\n",
      "     |      Call any configured recovery callbacks after rebalancing.\n",
      "     |  \n",
      "     |  clone(self, **kwargs: Any) -> Any\n",
      "     |      Clone table instance.\n",
      "     |  \n",
      "     |  combine(self, *nodes: faust.types.streams.JoinableT, **kwargs: Any) -> faust.types.streams.StreamT\n",
      "     |      Combine tables and streams.\n",
      "     |  \n",
      "     |  contribute_to_stream(self, active: faust.types.streams.StreamT) -> None\n",
      "     |      Contribute table to stream join.\n",
      "     |  \n",
      "     |  info(self) -> Mapping[str, Any]\n",
      "     |      Return table attributes as dictionary.\n",
      "     |  \n",
      "     |  inner_join(self, *fields: faust.types.models.FieldDescriptorT) -> faust.types.streams.StreamT\n",
      "     |      Inner join of this table and another stream/table.\n",
      "     |  \n",
      "     |  join(self, *fields: faust.types.models.FieldDescriptorT) -> faust.types.streams.StreamT\n",
      "     |      Right join of this table and another stream/table.\n",
      "     |  \n",
      "     |  left_join(self, *fields: faust.types.models.FieldDescriptorT) -> faust.types.streams.StreamT\n",
      "     |      Left join of this table and another stream/table.\n",
      "     |  \n",
      "     |  async need_active_standby_for(self, tp: faust.types.tuples.TP) -> bool\n",
      "     |      Return :const:`False` if we have access to partition data.\n",
      "     |  \n",
      "     |  async on_changelog_event(self, event: faust.types.events.EventT) -> None\n",
      "     |      Call when a new changelog event is received.\n",
      "     |  \n",
      "     |  async on_rebalance(self, assigned: Set[faust.types.tuples.TP], revoked: Set[faust.types.tuples.TP], newly_assigned: Set[faust.types.tuples.TP]) -> None\n",
      "     |      Call when cluster is rebalancing.\n",
      "     |  \n",
      "     |  on_recover(self, fun: Callable[[], Awaitable[NoneType]]) -> Callable[[], Awaitable[NoneType]]\n",
      "     |      Add function as callback to be called on table recovery.\n",
      "     |  \n",
      "     |  async on_recovery_completed(self, active_tps: Set[faust.types.tuples.TP], standby_tps: Set[faust.types.tuples.TP]) -> None\n",
      "     |      Call when recovery has completed after rebalancing.\n",
      "     |  \n",
      "     |  async on_start(self) -> None\n",
      "     |      Call when table starts.\n",
      "     |  \n",
      "     |  on_window_close(self, key: Any, value: Any) -> None\n",
      "     |  \n",
      "     |  outer_join(self, *fields: faust.types.models.FieldDescriptorT) -> faust.types.streams.StreamT\n",
      "     |      Outer join of this table and another stream/table.\n",
      "     |  \n",
      "     |  partition_for_key(self, key: Any) -> Union[int, NoneType]\n",
      "     |      Return partition number for table key.\n",
      "     |      \n",
      "     |      Always returns :const:`None` when :attr:`use_partitioner`\n",
      "     |      is enabled.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Optional[int]: specific partition or :const:`None` if\n",
      "     |              the producer should select partition using its partitioner.\n",
      "     |  \n",
      "     |  persisted_offset(self, tp: faust.types.tuples.TP) -> Union[int, NoneType]\n",
      "     |      Return the last persisted offset for topic partition.\n",
      "     |  \n",
      "     |  async remove_from_stream(self, stream: faust.types.streams.StreamT) -> None\n",
      "     |      Remove table from stream join after stream stopped.\n",
      "     |  \n",
      "     |  reset_state(self) -> None\n",
      "     |      Reset local state.\n",
      "     |  \n",
      "     |  send_changelog(self, partition: Union[int, NoneType], key: Any, value: Any, key_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, value_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None) -> faust.types.tuples.FutureMessage\n",
      "     |      Send modification event to changelog topic.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from faust.tables.base.Collection:\n",
      "     |  \n",
      "     |  changelog_topic_name\n",
      "     |  \n",
      "     |  data\n",
      "     |      Underlying table storage.\n",
      "     |  \n",
      "     |  label\n",
      "     |      Return human-readable label used to represent this table.\n",
      "     |  \n",
      "     |  shortlabel\n",
      "     |      Return short label used to represent this table in logs.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from faust.tables.base.Collection:\n",
      "     |  \n",
      "     |  changelog_topic\n",
      "     |      Return the changelog topic used by this table.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  __post_init__(self) -> None\n",
      "     |      Additional user initialization.\n",
      "     |  \n",
      "     |  async add_async_context(self, context: AbstractAsyncContextManager) -> Any\n",
      "     |  \n",
      "     |  add_context(self, context: AbstractContextManager) -> Any\n",
      "     |  \n",
      "     |  add_dependency(self, service: mode.types.services.ServiceT) -> mode.types.services.ServiceT\n",
      "     |      Add dependency to other service.\n",
      "     |      \n",
      "     |      The service will be started/stopped with this service.\n",
      "     |  \n",
      "     |  add_future(self, coro: Awaitable) -> _asyncio.Future\n",
      "     |      Add relationship to asyncio.Future.\n",
      "     |      \n",
      "     |      The future will be joined when this service is stopped.\n",
      "     |  \n",
      "     |  async add_runtime_dependency(self, service: mode.types.services.ServiceT) -> mode.types.services.ServiceT\n",
      "     |  \n",
      "     |  async crash(self, reason: BaseException) -> None\n",
      "     |      Crash the service and all child services.\n",
      "     |  \n",
      "     |  async itertimer(self, interval: Union[datetime.timedelta, float, str], *, max_drift_correction: float = 0.1, loop: asyncio.events.AbstractEventLoop = None, sleep: Callable[..., Awaitable] = None, clock: Callable[[], float] = <built-in function perf_counter>, name: str = '') -> AsyncIterator[float]\n",
      "     |      Sleep ``interval`` seconds for every iteration.\n",
      "     |      \n",
      "     |      This is an async iterator that takes advantage\n",
      "     |      of :func:`~mode.timers.Timer` to monitor drift and timer\n",
      "     |      oerlap.\n",
      "     |      \n",
      "     |      Uses ``Service.sleep`` so exits fast when the service is\n",
      "     |      stopped.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          Will sleep the full `interval` seconds before returning\n",
      "     |          from first iteration.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |          >>> async for sleep_time in self.itertimer(1.0):\n",
      "     |          ...   print('another second passed, just woke up...')\n",
      "     |          ...   await perform_some_http_request()\n",
      "     |  \n",
      "     |  async join_services(self, services: Sequence[mode.types.services.ServiceT]) -> None\n",
      "     |  \n",
      "     |  async maybe_start(self) -> bool\n",
      "     |      Start the service, if it has not already been started.\n",
      "     |  \n",
      "     |  on_init(self) -> None\n",
      "     |  \n",
      "     |  on_init_dependencies(self) -> Iterable[mode.types.services.ServiceT]\n",
      "     |      Return list of service dependencies for this service.\n",
      "     |  \n",
      "     |  async remove_dependency(self, service: mode.types.services.ServiceT) -> mode.types.services.ServiceT\n",
      "     |      Stop and remove dependency of this service.\n",
      "     |  \n",
      "     |  async restart(self) -> None\n",
      "     |      Restart this service.\n",
      "     |  \n",
      "     |  service_reset(self) -> None\n",
      "     |  \n",
      "     |  set_shutdown(self) -> None\n",
      "     |      Set the shutdown signal.\n",
      "     |      \n",
      "     |      Notes:\n",
      "     |          If :attr:`wait_for_shutdown` is set, stopping the service\n",
      "     |          will wait for this flag to be set.\n",
      "     |  \n",
      "     |  async sleep(self, n: Union[datetime.timedelta, float, str], *, loop: asyncio.events.AbstractEventLoop = None) -> None\n",
      "     |      Sleep for ``n`` seconds, or until service stopped.\n",
      "     |  \n",
      "     |  async start(self) -> None\n",
      "     |  \n",
      "     |  async stop(self) -> None\n",
      "     |      Stop the service.\n",
      "     |  \n",
      "     |  async transition_with(self, flag: str, fut: Awaitable, *args: Any, **kwargs: Any) -> Any\n",
      "     |  \n",
      "     |  async wait(self, *coros: Union[_asyncio.Future, Generator[Any, NoneType, Any], Awaitable, asyncio.locks.Event, mode.utils.locks.Event], timeout: Union[datetime.timedelta, float, str] = None) -> mode.services.WaitResult\n",
      "     |      Wait for coroutines to complete, or until the service stops.\n",
      "     |  \n",
      "     |  async wait_first(self, *coros: Union[_asyncio.Future, Generator[Any, NoneType, Any], Awaitable, asyncio.locks.Event, mode.utils.locks.Event], timeout: Union[datetime.timedelta, float, str] = None) -> mode.services.WaitResults\n",
      "     |  \n",
      "     |  async wait_for_stopped(self, *coros: Union[_asyncio.Future, Generator[Any, NoneType, Any], Awaitable, asyncio.locks.Event, mode.utils.locks.Event], timeout: Union[datetime.timedelta, float, str] = None) -> bool\n",
      "     |  \n",
      "     |  async wait_many(self, coros: Iterable[Union[_asyncio.Future, Generator[Any, NoneType, Any], Awaitable, asyncio.locks.Event, mode.utils.locks.Event]], *, timeout: Union[datetime.timedelta, float, str] = None) -> mode.services.WaitResult\n",
      "     |  \n",
      "     |  async wait_until_stopped(self) -> None\n",
      "     |      Wait until the service is signalled to stop.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  __init_subclass__() -> None from abc.ABCMeta\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  from_awaitable(coro: Awaitable, *, name: str = None, **kwargs: Any) -> mode.types.services.ServiceT from abc.ABCMeta\n",
      "     |  \n",
      "     |  task(fun: Callable[[Any], Awaitable[NoneType]]) -> mode.services.ServiceTask from abc.ABCMeta\n",
      "     |      Decorate function to be used as background task.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> class S(Service):\n",
      "     |          ...\n",
      "     |          ...     @Service.task\n",
      "     |          ...     async def background_task(self):\n",
      "     |          ...         while not self.should_stop:\n",
      "     |          ...             await self.sleep(1.0)\n",
      "     |          ...             print('Waking up')\n",
      "     |  \n",
      "     |  timer(interval: Union[datetime.timedelta, float, str]) -> Callable[[Callable], mode.services.ServiceTask] from abc.ABCMeta\n",
      "     |      Background timer executing every ``n`` seconds.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> class S(Service):\n",
      "     |          ...\n",
      "     |          ...     @Service.timer(1.0)\n",
      "     |          ...     async def background_timer(self):\n",
      "     |          ...         print('Waking up')\n",
      "     |  \n",
      "     |  transitions_to(flag: str) -> Callable from abc.ABCMeta\n",
      "     |      Decorate function to set and reset diagnostic flag.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  crashed\n",
      "     |  \n",
      "     |  should_stop\n",
      "     |      Return :const:`True` if the service must stop.\n",
      "     |  \n",
      "     |  started\n",
      "     |      Return :const:`True` if the service was started.\n",
      "     |  \n",
      "     |  state\n",
      "     |      Service state - as a human readable string.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  beacon\n",
      "     |      Beacon used to track services in a dependency graph.\n",
      "     |  \n",
      "     |  crash_reason\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  Diag = <class 'mode.services.Diag'>\n",
      "     |      Service diagnostics.\n",
      "     |      \n",
      "     |      This can be used to track what your service is doing.\n",
      "     |      For example if your service is a Kafka consumer with a background\n",
      "     |      thread that commits the offset every 30 seconds, you may want to\n",
      "     |      see when this happens::\n",
      "     |      \n",
      "     |          DIAG_COMMITTING = 'committing'\n",
      "     |      \n",
      "     |          class Consumer(Service):\n",
      "     |      \n",
      "     |              @Service.task\n",
      "     |              async def _background_commit(self) -> None:\n",
      "     |                  while not self.should_stop:\n",
      "     |                      await self.sleep(30.0)\n",
      "     |                      self.diag.set_flag(DIAG_COMITTING)\n",
      "     |                      try:\n",
      "     |                          await self._consumer.commit()\n",
      "     |                      finally:\n",
      "     |                          self.diag.unset_flag(DIAG_COMMITTING)\n",
      "     |      \n",
      "     |      The above code is setting the flag manually, but you can also use\n",
      "     |      a decorator to accomplish the same thing::\n",
      "     |      \n",
      "     |          @Service.timer(30.0)\n",
      "     |          async def _background_commit(self) -> None:\n",
      "     |              await self.commit()\n",
      "     |      \n",
      "     |          @Service.transitions_with(DIAG_COMITTING)\n",
      "     |          async def commit(self) -> None:\n",
      "     |              await self._consumer.commit()\n",
      "     |  \n",
      "     |  abstract = False\n",
      "     |  \n",
      "     |  mundane_level = 'info'\n",
      "     |  \n",
      "     |  restart_count = 0\n",
      "     |  \n",
      "     |  shutdown_timeout = 60.0\n",
      "     |  \n",
      "     |  wait_for_shutdown = False\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mode.services.ServiceBase:\n",
      "     |  \n",
      "     |  async __aenter__(self) -> mode.types.services.ServiceT\n",
      "     |      Return `self` upon entering the runtime context.\n",
      "     |  \n",
      "     |  async __aexit__(self, exc_type: Type[BaseException] = None, exc_val: BaseException = None, exc_tb: traceback = None) -> Union[bool, NoneType]\n",
      "     |      Raise any exception triggered within the runtime context.\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from mode.services.ServiceBase:\n",
      "     |  \n",
      "     |  loop\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from faust.types.tables.CollectionT:\n",
      "     |  \n",
      "     |  is_global = False\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from mode.types.services.ServiceT:\n",
      "     |  \n",
      "     |  supervisor = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from contextlib.AbstractAsyncContextManager:\n",
      "     |  \n",
      "     |  __subclasshook__(C) from abc.ABCMeta\n",
      "     |      Abstract classes can override this to customize issubclass().\n",
      "     |      \n",
      "     |      This is invoked early on by abc.ABCMeta.__subclasscheck__().\n",
      "     |      It should return True, False or NotImplemented.  If it returns\n",
      "     |      NotImplemented, the normal algorithm is used.  Otherwise, it\n",
      "     |      overrides the normal algorithm (and the outcome is cached).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from contextlib.AbstractAsyncContextManager:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mode.utils.collections.ManagedUserDict:\n",
      "     |  \n",
      "     |  __delitem__(self, key: ~KT) -> None\n",
      "     |  \n",
      "     |  __getitem__(self, key: ~KT) -> Any\n",
      "     |  \n",
      "     |  __setitem__(self, key: ~KT, value: ~VT) -> None\n",
      "     |  \n",
      "     |  clear(self) -> None\n",
      "     |      D.clear() -> None.  Remove all items from D.\n",
      "     |  \n",
      "     |  on_clear(self) -> None\n",
      "     |      Handle that the mapping is being cleared.\n",
      "     |  \n",
      "     |  raw_update(self, *args: Any, **kwargs: Any) -> None\n",
      "     |  \n",
      "     |  update(self, *args: Any, **kwargs: Any) -> None\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E present and has a .keys() method, does:     for k in E: D[k] = E[k]\n",
      "     |      If E present and lacks .keys() method, does:     for (k, v) in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k, v in F.items(): D[k] = v\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mode.utils.collections.FastUserDict:\n",
      "     |  \n",
      "     |  __contains__(self, key: object) -> bool\n",
      "     |  \n",
      "     |  __iter__(self) -> Iterator[~KT]\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  copy(self) -> dict\n",
      "     |  \n",
      "     |  items(self) -> ItemsView\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |  \n",
      "     |  keys(self) -> KeysView\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |  \n",
      "     |  values(self) -> ValuesView\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from mode.utils.collections.FastUserDict:\n",
      "     |  \n",
      "     |  fromkeys(iterable: Iterable[~KT], value: ~VT = None) -> 'FastUserDict' from abc.ABCMeta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from collections.abc.MutableMapping:\n",
      "     |  \n",
      "     |  pop(self, key, default=<object object at 0x7fc595cbb150>)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |      If key is not found, d is returned if given, otherwise KeyError is raised.\n",
      "     |  \n",
      "     |  popitem(self)\n",
      "     |      D.popitem() -> (k, v), remove and return some (key, value) pair\n",
      "     |      as a 2-tuple; but raise KeyError if D is empty.\n",
      "     |  \n",
      "     |  setdefault(self, key, default=None)\n",
      "     |      D.setdefault(k[,d]) -> D.get(k,d), also set D[k]=d if k not in D\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from collections.abc.Mapping:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  get(self, key, default=None)\n",
      "     |      D.get(k[,d]) -> D[k] if k in D, else d.  d defaults to None.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from collections.abc.Mapping:\n",
      "     |  \n",
      "     |  __reversed__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from abc.ABCMeta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mode.services.ServiceCallbacks:\n",
      "     |  \n",
      "     |  async on_first_start(self) -> None\n",
      "     |      Service started for the first time in this process.\n",
      "     |  \n",
      "     |  async on_restart(self) -> None\n",
      "     |      Service is being restarted.\n",
      "     |  \n",
      "     |  async on_shutdown(self) -> None\n",
      "     |      Service is being stopped/restarted.\n",
      "     |  \n",
      "     |  async on_started(self) -> None\n",
      "     |      Service has started.\n",
      "     |  \n",
      "     |  async on_stop(self) -> None\n",
      "     |      Service is being stopped/restarted.\n",
      "    \n",
      "    class Topic(faust.channels.SerializedChannel, faust.types.topics.TopicT)\n",
      "     |  Topic(*args, **kwds)\n",
      "     |  \n",
      "     |  Define new topic description.\n",
      "     |  \n",
      "     |  Arguments:\n",
      "     |      app: App instance used to create this topic description.\n",
      "     |  \n",
      "     |      topics: List of topic names.\n",
      "     |      partitions: Number of partitions for these topics.\n",
      "     |                  On declaration, topics are created using this.\n",
      "     |                  Note: If a message is produced before the topic is\n",
      "     |                  declared, and ``autoCreateTopics`` is enabled on\n",
      "     |                  the Kafka Server, the number of partitions used\n",
      "     |                  will be specified by the server configuration.\n",
      "     |      retention: Number of seconds (as float/:class:`~datetime.timedelta`)\n",
      "     |                 to keep messages in the topic before they can\n",
      "     |                 be expired by the server.\n",
      "     |      pattern: Regular expression evaluated to decide what topics to\n",
      "     |               subscribe to. You cannot specify both topics and a pattern.\n",
      "     |      schema: Schema used for serialization/deserialization.\n",
      "     |      key_type: How to deserialize keys for messages in this topic.\n",
      "     |                Can be a :class:`faust.Model` type, :class:`str`,\n",
      "     |                :class:`bytes`, or :const:`None` for \"autodetect\"\n",
      "     |                (Overrides schema if one is defined).\n",
      "     |      value_type: How to deserialize values for messages in this topic.\n",
      "     |                Can be a :class:`faust.Model` type, :class:`str`,\n",
      "     |                :class:`bytes`, or :const:`None` for \"autodetect\"\n",
      "     |                (Overrides schema if ones is defined).\n",
      "     |      active_partitions: Set of :class:`faust.types.tuples.TP` that this\n",
      "     |                topic should be restricted to.\n",
      "     |  \n",
      "     |  Raises:\n",
      "     |      TypeError: if both `topics` and `pattern` is provided.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Topic\n",
      "     |      faust.channels.SerializedChannel\n",
      "     |      faust.channels.Channel\n",
      "     |      faust.types.topics.TopicT\n",
      "     |      faust.types.channels.ChannelT\n",
      "     |      collections.abc.AsyncIterator\n",
      "     |      collections.abc.AsyncIterable\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __aiter__(self) -> faust.types.channels.ChannelT\n",
      "     |  \n",
      "     |  __init__(self, app: faust.types.app.AppT, *, topics: Sequence[str] = None, pattern: Union[str, Pattern] = None, schema: faust.types.serializers.SchemaT = None, key_type: Union[Type[faust.types.models.ModelT], Type[bytes], Type[str]] = None, value_type: Union[Type[faust.types.models.ModelT], Type[bytes], Type[str]] = None, is_iterator: bool = False, partitions: int = None, retention: Union[datetime.timedelta, float, str] = None, compacting: bool = None, deleting: bool = None, replicas: int = None, acks: bool = True, internal: bool = False, config: Mapping[str, Any] = None, queue: mode.utils.queues.ThrowableQueue = None, key_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, value_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, maxsize: int = None, root: faust.types.channels.ChannelT = None, active_partitions: Set[faust.types.tuples.TP] = None, allow_empty: bool = None, has_prefix: bool = False, loop: asyncio.events.AbstractEventLoop = None) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __str__(self) -> str\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  async declare(self) -> None\n",
      "     |      Declare/create this topic on the server.\n",
      "     |  \n",
      "     |  derive(self, **kwargs: Any) -> faust.types.channels.ChannelT\n",
      "     |      Create topic derived from the configuration of this topic.\n",
      "     |      \n",
      "     |      Configuration will be copied from this topic, but any parameter\n",
      "     |      overridden as a keyword argument.\n",
      "     |      \n",
      "     |      See Also:\n",
      "     |          :meth:`derive_topic`: for a list of supported keyword arguments.\n",
      "     |  \n",
      "     |  derive_topic(self, *, topics: Sequence[str] = None, schema: faust.types.serializers.SchemaT = None, key_type: Union[Type[faust.types.models.ModelT], Type[bytes], Type[str]] = None, value_type: Union[Type[faust.types.models.ModelT], Type[bytes], Type[str]] = None, key_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, value_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, partitions: int = None, retention: Union[datetime.timedelta, float, str] = None, compacting: bool = None, deleting: bool = None, internal: bool = None, config: Mapping[str, Any] = None, prefix: str = '', suffix: str = '', **kwargs: Any) -> faust.types.topics.TopicT\n",
      "     |      Create new topic with configuration derived from this topic.\n",
      "     |  \n",
      "     |  get_topic_name(self) -> str\n",
      "     |      Return the main topic name of this topic description.\n",
      "     |      \n",
      "     |      As topic descriptions can have multiple topic names, this will only\n",
      "     |      return when the topic has a singular topic name in the description.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          TypeError: if configured with a regular expression pattern.\n",
      "     |          ValueError: if configured with multiple topic names.\n",
      "     |          TypeError: if not configured with any names or patterns.\n",
      "     |  \n",
      "     |  maybe_declare(self) -> None\n",
      "     |      Declare/create this topic, only if it does not exist.\n",
      "     |  \n",
      "     |  async publish_message(self, fut: faust.types.tuples.FutureMessage, wait: bool = False) -> Awaitable[faust.types.tuples.RecordMetadata]\n",
      "     |      Fulfill promise to publish message to topic.\n",
      "     |  \n",
      "     |  async put(self, event: faust.types.events.EventT) -> None\n",
      "     |      Put event directly onto the underlying queue of this topic.\n",
      "     |      \n",
      "     |      This will only affect subscribers to a particular\n",
      "     |      instance, in a particular process.\n",
      "     |  \n",
      "     |  async send(self, *, key: Union[bytes, faust.types.core._ModelT, Any, NoneType] = None, value: Union[bytes, faust.types.core._ModelT, Any] = None, partition: int = None, timestamp: float = None, headers: Union[List[Tuple[str, bytes]], Mapping[str, bytes], NoneType] = None, schema: faust.types.serializers.SchemaT = None, key_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, value_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, callback: Callable[[faust.types.tuples.FutureMessage], Union[NoneType, Awaitable[NoneType]]] = None, force: bool = False) -> Awaitable[faust.types.tuples.RecordMetadata]\n",
      "     |      Send message to topic.\n",
      "     |  \n",
      "     |  send_soon(self, *, key: Union[bytes, faust.types.core._ModelT, Any, NoneType] = None, value: Union[bytes, faust.types.core._ModelT, Any] = None, partition: int = None, timestamp: float = None, headers: Union[List[Tuple[str, bytes]], Mapping[str, bytes], NoneType] = None, schema: faust.types.serializers.SchemaT = None, key_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, value_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, callback: Callable[[faust.types.tuples.FutureMessage], Union[NoneType, Awaitable[NoneType]]] = None, force: bool = False, eager_partitioning: bool = False) -> faust.types.tuples.FutureMessage\n",
      "     |      Produce message by adding to buffer.\n",
      "     |      \n",
      "     |      Notes:\n",
      "     |          This method can be used by non-`async def` functions\n",
      "     |          to produce messages.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  partitions\n",
      "     |      Return the number of configured partitions for this topic.\n",
      "     |      \n",
      "     |      Notes:\n",
      "     |          This is only active for internal topics, fully owned\n",
      "     |          and managed by Faust itself.\n",
      "     |      \n",
      "     |          We never touch the configuration of a topic that exists in Kafka,\n",
      "     |          and Kafka will sometimes automatically create topics\n",
      "     |          when they don't exist.  In this case the number of\n",
      "     |          partitions for the automatically created topic\n",
      "     |          will depend on the Kafka server configuration\n",
      "     |          (``num.partitions``).\n",
      "     |      \n",
      "     |          Always make sure your topics have the correct\n",
      "     |          number of partitions.\n",
      "     |  \n",
      "     |  pattern\n",
      "     |      Regular expression used by this topic (if any).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'_partitions': typing.Union[int, NoneType], '_patte...\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from faust.channels.SerializedChannel:\n",
      "     |  \n",
      "     |  prepare_key(self, key: Union[bytes, faust.types.core._ModelT, Any, NoneType], key_serializer: Union[faust.types.codecs.CodecT, str, NoneType], schema: faust.types.serializers.SchemaT = None, headers: Union[List[Tuple[str, bytes]], MutableMapping[str, bytes], NoneType] = None) -> Tuple[Any, Union[List[Tuple[str, bytes]], MutableMapping[str, bytes], NoneType]]\n",
      "     |      Serialize key to format suitable for transport.\n",
      "     |  \n",
      "     |  prepare_value(self, value: Union[bytes, faust.types.core._ModelT, Any], value_serializer: Union[faust.types.codecs.CodecT, str, NoneType], schema: faust.types.serializers.SchemaT = None, headers: Union[List[Tuple[str, bytes]], MutableMapping[str, bytes], NoneType] = None) -> Tuple[Any, Union[List[Tuple[str, bytes]], MutableMapping[str, bytes], NoneType]]\n",
      "     |      Serialize value to format suitable for transport.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from faust.channels.SerializedChannel:\n",
      "     |  \n",
      "     |  __orig_bases__ = (faust.channels.Channel[~T],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from faust.channels.Channel:\n",
      "     |  \n",
      "     |  async __anext__(self) -> faust.types.events.EventT[~T]\n",
      "     |      Return the next item or raise StopAsyncIteration when exhausted.\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  as_future_message(self, key: Union[bytes, faust.types.core._ModelT, Any, NoneType] = None, value: Union[bytes, faust.types.core._ModelT, Any] = None, partition: int = None, timestamp: float = None, headers: Union[List[Tuple[str, bytes]], Mapping[str, bytes], NoneType] = None, schema: faust.types.serializers.SchemaT = None, key_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, value_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, callback: Callable[[faust.types.tuples.FutureMessage], Union[NoneType, Awaitable[NoneType]]] = None, eager_partitioning: bool = False) -> faust.types.tuples.FutureMessage\n",
      "     |      Create promise that message will be transmitted.\n",
      "     |  \n",
      "     |  clone(self, *, is_iterator: bool = None, **kwargs: Any) -> faust.types.channels.ChannelT[~T]\n",
      "     |      Create clone of this channel.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          is_iterator: Set to True if this is now a channel\n",
      "     |              that is being iterated over.\n",
      "     |      \n",
      "     |      Keyword Arguments:\n",
      "     |          **kwargs: Any keyword arguments passed will override any\n",
      "     |              of the arguments supported by\n",
      "     |              :class:`Channel.__init__ <Channel>`.\n",
      "     |  \n",
      "     |  clone_using_queue(self, queue: asyncio.queues.Queue) -> faust.types.channels.ChannelT[~T]\n",
      "     |      Create clone of this channel using specific queue instance.\n",
      "     |  \n",
      "     |  async decode(self, message: faust.types.tuples.Message, *, propagate: bool = False) -> faust.types.events.EventT[~T]\n",
      "     |      Decode :class:`~faust.types.Message` into :class:`~faust.Event`.\n",
      "     |  \n",
      "     |  async deliver(self, message: faust.types.tuples.Message) -> None\n",
      "     |      Deliver message to queue from consumer.\n",
      "     |      \n",
      "     |      This is called by the consumer to deliver the message\n",
      "     |      to the channel.\n",
      "     |  \n",
      "     |  empty(self) -> bool\n",
      "     |      Return :const:`True` if the queue is empty.\n",
      "     |  \n",
      "     |  async get(self, *, timeout: Union[datetime.timedelta, float, str] = None) -> faust.types.events.EventT[~T]\n",
      "     |      Get the next :class:`~faust.Event` received on this channel.\n",
      "     |  \n",
      "     |  async on_decode_error(self, exc: Exception, message: faust.types.tuples.Message) -> None\n",
      "     |      Signal that there was an error reading an event in the queue.\n",
      "     |      \n",
      "     |      When a message in the channel needs deserialization\n",
      "     |      to be reconstructed back to its original form, we will sometimes\n",
      "     |      see decoding/deserialization errors being raised, from missing\n",
      "     |      fields or malformed payloads, and so on.\n",
      "     |      \n",
      "     |      We will log the exception, but you can also override this\n",
      "     |      to perform additional actions.\n",
      "     |      \n",
      "     |      Admonition: Kafka\n",
      "     |          In the event a deserialization error occurs, we\n",
      "     |          HAVE to commit the offset of the source message to continue\n",
      "     |          processing the stream.\n",
      "     |      \n",
      "     |          For this reason it is important that you keep a close eye on\n",
      "     |          error logs. For easy of use, we suggest using log aggregation\n",
      "     |          software, such as Sentry, to surface these errors to your\n",
      "     |          operations team.\n",
      "     |  \n",
      "     |  async on_key_decode_error(self, exc: Exception, message: faust.types.tuples.Message) -> None\n",
      "     |      Unable to decode the key of an item in the queue.\n",
      "     |      \n",
      "     |      See Also:\n",
      "     |          :meth:`on_decode_error`\n",
      "     |  \n",
      "     |  on_stop_iteration(self) -> None\n",
      "     |      Signal that iteration over this channel was stopped.\n",
      "     |      \n",
      "     |      Tip:\n",
      "     |          Remember to call ``super`` when overriding this method.\n",
      "     |  \n",
      "     |  async on_value_decode_error(self, exc: Exception, message: faust.types.tuples.Message) -> None\n",
      "     |      Unable to decode the value of an item in the queue.\n",
      "     |      \n",
      "     |      See Also:\n",
      "     |          :meth:`on_decode_error`\n",
      "     |  \n",
      "     |  prepare_headers(self, headers: Union[List[Tuple[str, bytes]], Mapping[str, bytes], NoneType]) -> Union[List[Tuple[str, bytes]], MutableMapping[str, bytes], NoneType]\n",
      "     |      Prepare ``headers`` passed before publishing.\n",
      "     |  \n",
      "     |  stream(self, **kwargs: Any) -> faust.types.streams.StreamT[~T]\n",
      "     |      Create stream reading from this channel.\n",
      "     |  \n",
      "     |  async throw(self, exc: BaseException) -> None\n",
      "     |      Throw exception to be received by channel subscribers.\n",
      "     |      \n",
      "     |      Tip:\n",
      "     |          When you find yourself having to call this from\n",
      "     |          a regular, non-``async def`` function, you can use :meth:`_throw`\n",
      "     |          instead.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from faust.channels.Channel:\n",
      "     |  \n",
      "     |  label\n",
      "     |      Short textual description of channel.\n",
      "     |  \n",
      "     |  queue\n",
      "     |      Return the underlying queue/buffer backing this channel.\n",
      "     |  \n",
      "     |  subscriber_count\n",
      "     |      Return number of active subscribers to local channel.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from faust.types.topics.TopicT:\n",
      "     |  \n",
      "     |  has_prefix = False\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from faust.types.channels.ChannelT:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from collections.abc.AsyncIterator:\n",
      "     |  \n",
      "     |  __subclasshook__(C) from abc.ABCMeta\n",
      "     |      Abstract classes can override this to customize issubclass().\n",
      "     |      \n",
      "     |      This is invoked early on by abc.ABCMeta.__subclasscheck__().\n",
      "     |      It should return True, False or NotImplemented.  If it returns\n",
      "     |      NotImplemented, the normal algorithm is used.  Otherwise, it\n",
      "     |      overrides the normal algorithm (and the outcome is cached).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from abc.ABCMeta\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from abc.ABCMeta\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class TopicT(faust.types.channels.ChannelT)\n",
      "     |  TopicT(*args, **kwds)\n",
      "     |  \n",
      "     |  Abstract base class for generic types.\n",
      "     |  \n",
      "     |  A generic type is typically declared by inheriting from\n",
      "     |  this class parameterized with one or more type variables.\n",
      "     |  For example, a generic mapping type might be defined as::\n",
      "     |  \n",
      "     |    class Mapping(Generic[KT, VT]):\n",
      "     |        def __getitem__(self, key: KT) -> VT:\n",
      "     |            ...\n",
      "     |        # Etc.\n",
      "     |  \n",
      "     |  This class can then be used as follows::\n",
      "     |  \n",
      "     |    def lookup_name(mapping: Mapping[KT, VT], key: KT, default: VT) -> VT:\n",
      "     |        try:\n",
      "     |            return mapping[key]\n",
      "     |        except KeyError:\n",
      "     |            return default\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TopicT\n",
      "     |      faust.types.channels.ChannelT\n",
      "     |      collections.abc.AsyncIterator\n",
      "     |      collections.abc.AsyncIterable\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, app: faust.types.topics._AppT, *, topics: Sequence[str] = None, pattern: Union[str, Pattern] = None, schema: faust.types.topics._SchemaT = None, key_type: faust.types.topics._ModelArg = None, value_type: faust.types.topics._ModelArg = None, is_iterator: bool = False, partitions: int = None, retention: Union[datetime.timedelta, float, str] = None, compacting: bool = None, deleting: bool = None, replicas: int = None, acks: bool = True, internal: bool = False, config: Mapping[str, Any] = None, queue: mode.utils.queues.ThrowableQueue = None, key_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, value_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, maxsize: int = None, root: faust.types.channels.ChannelT = None, active_partitions: Set[faust.types.tuples.TP] = None, allow_empty: bool = False, has_prefix: bool = False, loop: asyncio.events.AbstractEventLoop = None) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  derive(self, **kwargs: Any) -> faust.types.channels.ChannelT\n",
      "     |  \n",
      "     |  derive_topic(self, *, topics: Sequence[str] = None, schema: faust.types.topics._SchemaT = None, key_type: faust.types.topics._ModelArg = None, value_type: faust.types.topics._ModelArg = None, partitions: int = None, retention: Union[datetime.timedelta, float, str] = None, compacting: bool = None, deleting: bool = None, internal: bool = False, config: Mapping[str, Any] = None, prefix: str = '', suffix: str = '', **kwargs: Any) -> 'TopicT'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  partitions\n",
      "     |  \n",
      "     |  pattern\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset({'__aiter__', '__anext__', '__init__',...\n",
      "     |  \n",
      "     |  __annotations__ = {'acks': <class 'bool'>, 'active_partitions': typing...\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  has_prefix = False\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from faust.types.channels.ChannelT:\n",
      "     |  \n",
      "     |  __aiter__(self) -> 'ChannelT'\n",
      "     |  \n",
      "     |  __anext__(self) -> Awaitable[faust.types.channels._EventT[~_T]]\n",
      "     |      Return the next item or raise StopAsyncIteration when exhausted.\n",
      "     |  \n",
      "     |  as_future_message(self, key: Union[bytes, faust.types.core._ModelT, Any, NoneType] = None, value: Union[bytes, faust.types.core._ModelT, Any] = None, partition: int = None, timestamp: float = None, headers: Union[List[Tuple[str, bytes]], Mapping[str, bytes], NoneType] = None, schema: faust.types.channels._SchemaT = None, key_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, value_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, callback: Callable[[faust.types.tuples.FutureMessage], Union[NoneType, Awaitable[NoneType]]] = None, eager_partitioning: bool = False) -> faust.types.tuples.FutureMessage\n",
      "     |  \n",
      "     |  clone(self, *, is_iterator: bool = None, **kwargs: Any) -> 'ChannelT[_T]'\n",
      "     |  \n",
      "     |  clone_using_queue(self, queue: asyncio.queues.Queue) -> 'ChannelT[_T]'\n",
      "     |  \n",
      "     |  async declare(self) -> None\n",
      "     |  \n",
      "     |  async decode(self, message: faust.types.tuples.Message, *, propagate: bool = False) -> faust.types.channels._EventT[~_T]\n",
      "     |  \n",
      "     |  async deliver(self, message: faust.types.tuples.Message) -> None\n",
      "     |  \n",
      "     |  empty(self) -> bool\n",
      "     |  \n",
      "     |  async get(self, *, timeout: Union[datetime.timedelta, float, str] = None) -> faust.types.channels._EventT[~_T]\n",
      "     |  \n",
      "     |  get_topic_name(self) -> str\n",
      "     |  \n",
      "     |  maybe_declare(self) -> None\n",
      "     |  \n",
      "     |  async on_decode_error(self, exc: Exception, message: faust.types.tuples.Message) -> None\n",
      "     |  \n",
      "     |  async on_key_decode_error(self, exc: Exception, message: faust.types.tuples.Message) -> None\n",
      "     |  \n",
      "     |  on_stop_iteration(self) -> None\n",
      "     |  \n",
      "     |  async on_value_decode_error(self, exc: Exception, message: faust.types.tuples.Message) -> None\n",
      "     |  \n",
      "     |  prepare_key(self, key: Union[bytes, faust.types.core._ModelT, Any, NoneType], key_serializer: Union[faust.types.codecs.CodecT, str, NoneType], schema: faust.types.channels._SchemaT = None) -> Any\n",
      "     |  \n",
      "     |  prepare_value(self, value: Union[bytes, faust.types.core._ModelT, Any], value_serializer: Union[faust.types.codecs.CodecT, str, NoneType], schema: faust.types.channels._SchemaT = None) -> Any\n",
      "     |  \n",
      "     |  async publish_message(self, fut: faust.types.tuples.FutureMessage, wait: bool = True) -> Awaitable[faust.types.tuples.RecordMetadata]\n",
      "     |  \n",
      "     |  async put(self, value: faust.types.channels._EventT[~_T]) -> None\n",
      "     |  \n",
      "     |  async send(self, *, key: Union[bytes, faust.types.core._ModelT, Any, NoneType] = None, value: Union[bytes, faust.types.core._ModelT, Any] = None, partition: int = None, timestamp: float = None, headers: Union[List[Tuple[str, bytes]], Mapping[str, bytes], NoneType] = None, schema: faust.types.channels._SchemaT = None, key_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, value_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, callback: Callable[[faust.types.tuples.FutureMessage], Union[NoneType, Awaitable[NoneType]]] = None, force: bool = False) -> Awaitable[faust.types.tuples.RecordMetadata]\n",
      "     |  \n",
      "     |  send_soon(self, *, key: Union[bytes, faust.types.core._ModelT, Any, NoneType] = None, value: Union[bytes, faust.types.core._ModelT, Any] = None, partition: int = None, timestamp: float = None, headers: Union[List[Tuple[str, bytes]], Mapping[str, bytes], NoneType] = None, schema: faust.types.channels._SchemaT = None, key_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, value_serializer: Union[faust.types.codecs.CodecT, str, NoneType] = None, callback: Callable[[faust.types.tuples.FutureMessage], Union[NoneType, Awaitable[NoneType]]] = None, force: bool = False, eager_partitioning: bool = False) -> faust.types.tuples.FutureMessage\n",
      "     |  \n",
      "     |  stream(self, **kwargs: Any) -> '_StreamT[_T]'\n",
      "     |  \n",
      "     |  async throw(self, exc: BaseException) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from faust.types.channels.ChannelT:\n",
      "     |  \n",
      "     |  queue\n",
      "     |  \n",
      "     |  subscriber_count\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from faust.types.channels.ChannelT:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from faust.types.channels.ChannelT:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.AsyncIterator[faust.types.channels._EventT[~_...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from collections.abc.AsyncIterator:\n",
      "     |  \n",
      "     |  __subclasshook__(C) from abc.ABCMeta\n",
      "     |      Abstract classes can override this to customize issubclass().\n",
      "     |      \n",
      "     |      This is invoked early on by abc.ABCMeta.__subclasscheck__().\n",
      "     |      It should return True, False or NotImplemented.  If it returns\n",
      "     |      NotImplemented, the normal algorithm is used.  Otherwise, it\n",
      "     |      overrides the normal algorithm (and the outcome is cached).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from abc.ABCMeta\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from abc.ABCMeta\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class TumblingWindow(_PyHoppingWindow)\n",
      "     |  TumblingWindow(size: Union[datetime.timedelta, float, str], expires: Union[datetime.timedelta, float, str] = None) -> None\n",
      "     |  \n",
      "     |  Tumbling window type.\n",
      "     |  \n",
      "     |  Fixed-size, non-overlapping, gap-less windows.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TumblingWindow\n",
      "     |      _PyHoppingWindow\n",
      "     |      Window\n",
      "     |      faust.types.windows.WindowT\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, size: Union[datetime.timedelta, float, str], expires: Union[datetime.timedelta, float, str] = None) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _PyHoppingWindow:\n",
      "     |  \n",
      "     |  current(self, timestamp: float) -> Tuple[float, float]\n",
      "     |      Get the latest window range for a given timestamp.\n",
      "     |  \n",
      "     |  delta(self, timestamp: float, d: Union[datetime.timedelta, float, str]) -> Tuple[float, float]\n",
      "     |  \n",
      "     |  earliest(self, timestamp: float) -> Tuple[float, float]\n",
      "     |  \n",
      "     |  ranges(self, timestamp: float) -> List[Tuple[float, float]]\n",
      "     |  \n",
      "     |  stale(self, timestamp: float, latest_timestamp: float) -> bool\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from _PyHoppingWindow:\n",
      "     |  \n",
      "     |  __annotations__ = {'size': <class 'float'>, 'step': <class 'float'>}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from faust.types.windows.WindowT:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from faust.types.windows.WindowT:\n",
      "     |  \n",
      "     |  expires = None\n",
      "     |  \n",
      "     |  tz = None\n",
      "    \n",
      "    class Window(faust.types.windows.WindowT)\n",
      "     |  Base class for window types.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Window\n",
      "     |      faust.types.windows.WindowT\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset({'current', 'delta', 'earliest', 'rang...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from faust.types.windows.WindowT:\n",
      "     |  \n",
      "     |  current(self, timestamp: float) -> Tuple[float, float]\n",
      "     |  \n",
      "     |  delta(self, timestamp: float, d: Union[datetime.timedelta, float, str]) -> Tuple[float, float]\n",
      "     |  \n",
      "     |  earliest(self, timestamp: float) -> Tuple[float, float]\n",
      "     |  \n",
      "     |  ranges(self, timestamp: float) -> List[Tuple[float, float]]\n",
      "     |  \n",
      "     |  stale(self, timestamp: float, latest_timestamp: float) -> bool\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from faust.types.windows.WindowT:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from faust.types.windows.WindowT:\n",
      "     |  \n",
      "     |  __annotations__ = {'expires': typing.Union[float, NoneType], 'tz': typ...\n",
      "     |  \n",
      "     |  expires = None\n",
      "     |  \n",
      "     |  tz = None\n",
      "    \n",
      "    class Worker(mode.worker.Worker)\n",
      "     |  Worker(*args, **kwds)\n",
      "     |  \n",
      "     |  Worker.\n",
      "     |  \n",
      "     |  See Also:\n",
      "     |      This is a subclass of :class:`mode.Worker`.\n",
      "     |  \n",
      "     |  Usage:\n",
      "     |      You can start a worker using:\n",
      "     |  \n",
      "     |          1) the :program:`faust worker` program.\n",
      "     |  \n",
      "     |          2) instantiating Worker programmatically and calling\n",
      "     |             `execute_from_commandline()`::\n",
      "     |  \n",
      "     |                  >>> worker = Worker(app)\n",
      "     |                  >>> worker.execute_from_commandline()\n",
      "     |  \n",
      "     |          3) or if you already have an event loop, calling ``await start``,\n",
      "     |             but in that case *you are responsible for gracefully shutting\n",
      "     |             down the event loop*::\n",
      "     |  \n",
      "     |                  async def start_worker(worker: Worker) -> None:\n",
      "     |                      await worker.start()\n",
      "     |  \n",
      "     |                  def manage_loop():\n",
      "     |                      loop = asyncio.get_event_loop()\n",
      "     |                      worker = Worker(app, loop=loop)\n",
      "     |                      try:\n",
      "     |                          loop.run_until_complete(start_worker(worker)\n",
      "     |                      finally:\n",
      "     |                          worker.stop_and_shutdown_loop()\n",
      "     |  \n",
      "     |  Arguments:\n",
      "     |      app: The Faust app to start.\n",
      "     |      *services: Services to start with worker.\n",
      "     |          This includes application instances to start.\n",
      "     |  \n",
      "     |      sensors (Iterable[SensorT]): List of sensors to include.\n",
      "     |      debug (bool): Enables debugging mode [disabled by default].\n",
      "     |      quiet (bool): Do not output anything to console [disabled by default].\n",
      "     |      loglevel (Union[str, int]): Level to use for logging, can be string\n",
      "     |          (one of: CRIT|ERROR|WARN|INFO|DEBUG), or integer.\n",
      "     |      logfile (Union[str, IO]): Name of file or a stream to log to.\n",
      "     |      stdout (IO): Standard out stream.\n",
      "     |      stderr (IO): Standard err stream.\n",
      "     |      blocking_timeout (float): When :attr:`debug` is enabled this\n",
      "     |          sets the timeout for detecting that the event loop is blocked.\n",
      "     |      workdir (Union[str, Path]): Custom working directory for the process\n",
      "     |          that the worker will change into when started.\n",
      "     |          This working directory change is permanent for the process,\n",
      "     |          or until something else changes the working directory again.\n",
      "     |      loop (asyncio.AbstractEventLoop): Custom event loop object.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Worker\n",
      "     |      mode.worker.Worker\n",
      "     |      mode.services.Service\n",
      "     |      mode.services.ServiceBase\n",
      "     |      mode.types.services.ServiceT\n",
      "     |      contextlib.AbstractAsyncContextManager\n",
      "     |      abc.ABC\n",
      "     |      typing.Generic\n",
      "     |      mode.services.ServiceCallbacks\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, app: faust.types.app.AppT, *services: mode.types.services.ServiceT, sensors: Iterable[faust.types.sensors.SensorT] = None, debug: bool = False, quiet: bool = False, loglevel: Union[str, int] = None, logfile: Union[str, IO] = None, stdout: <class 'IO'> = <ipykernel.iostream.OutStream object at 0x7fc5915787f0>, stderr: <class 'IO'> = <ipykernel.iostream.OutStream object at 0x7fc591578760>, blocking_timeout: float = 10.0, workdir: Union[pathlib.Path, str] = None, console_port: int = 50101, loop: asyncio.events.AbstractEventLoop = None, redirect_stdouts: bool = None, redirect_stdouts_level: Union[int, str] = None, logging_config: Dict = None, **kwargs: Any) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  autodiscover(self) -> None\n",
      "     |      Autodiscover modules and files to find @agent decorators, etc.\n",
      "     |  \n",
      "     |  change_workdir(self, path: pathlib.Path) -> None\n",
      "     |      Change the current working directory (CWD).\n",
      "     |  \n",
      "     |  async maybe_start_blockdetection(self) -> None\n",
      "     |      Start blocking detector if enabled.\n",
      "     |  \n",
      "     |  async on_execute(self) -> None\n",
      "     |      Signal called when the worker is about to start.\n",
      "     |  \n",
      "     |  async on_first_start(self) -> None\n",
      "     |      Signal called the first time the worker starts.\n",
      "     |      \n",
      "     |      First time, means this callback is not called if the\n",
      "     |      worker is restarted by an exception being raised.\n",
      "     |  \n",
      "     |  on_init_dependencies(self) -> Iterable[mode.types.services.ServiceT]\n",
      "     |      Return service dependencies that must start with the worker.\n",
      "     |  \n",
      "     |  on_setup_root_logger(self, logger: logging.Logger, level: int) -> None\n",
      "     |      Signal called when the root logger is being configured.\n",
      "     |  \n",
      "     |  async on_start(self) -> None\n",
      "     |      Signal called every time the worker starts.\n",
      "     |  \n",
      "     |  async on_startup_finished(self) -> None\n",
      "     |      Signal called when worker has started.\n",
      "     |  \n",
      "     |  on_worker_shutdown(self) -> None\n",
      "     |      Signal called before the worker is shutting down.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'_shutdown_immediately': <class 'bool'>, 'app': <cl...\n",
      "     |  \n",
      "     |  logger = <Logger faust.worker (INFO)>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mode.worker.Worker:\n",
      "     |  \n",
      "     |  carp(self, msg: str) -> None\n",
      "     |      Write warning to standard err.\n",
      "     |  \n",
      "     |  async default_on_first_start(self) -> None\n",
      "     |  \n",
      "     |  execute_from_commandline(self) -> NoReturn\n",
      "     |  \n",
      "     |  install_signal_handlers(self) -> None\n",
      "     |  \n",
      "     |  async on_started(self) -> None\n",
      "     |      Service has started.\n",
      "     |  \n",
      "     |  say(self, msg: str) -> None\n",
      "     |      Write message to standard out.\n",
      "     |  \n",
      "     |  stop_and_shutdown(self) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from mode.worker.Worker:\n",
      "     |  \n",
      "     |  blocking_detector\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from mode.worker.Worker:\n",
      "     |  \n",
      "     |  BLOCK_DETECTOR = 'mode.debug:BlockingDetector'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  __post_init__(self) -> None\n",
      "     |      Additional user initialization.\n",
      "     |  \n",
      "     |  async add_async_context(self, context: AbstractAsyncContextManager) -> Any\n",
      "     |  \n",
      "     |  add_context(self, context: AbstractContextManager) -> Any\n",
      "     |  \n",
      "     |  add_dependency(self, service: mode.types.services.ServiceT) -> mode.types.services.ServiceT\n",
      "     |      Add dependency to other service.\n",
      "     |      \n",
      "     |      The service will be started/stopped with this service.\n",
      "     |  \n",
      "     |  add_future(self, coro: Awaitable) -> _asyncio.Future\n",
      "     |      Add relationship to asyncio.Future.\n",
      "     |      \n",
      "     |      The future will be joined when this service is stopped.\n",
      "     |  \n",
      "     |  async add_runtime_dependency(self, service: mode.types.services.ServiceT) -> mode.types.services.ServiceT\n",
      "     |  \n",
      "     |  async crash(self, reason: BaseException) -> None\n",
      "     |      Crash the service and all child services.\n",
      "     |  \n",
      "     |  async itertimer(self, interval: Union[datetime.timedelta, float, str], *, max_drift_correction: float = 0.1, loop: asyncio.events.AbstractEventLoop = None, sleep: Callable[..., Awaitable] = None, clock: Callable[[], float] = <built-in function perf_counter>, name: str = '') -> AsyncIterator[float]\n",
      "     |      Sleep ``interval`` seconds for every iteration.\n",
      "     |      \n",
      "     |      This is an async iterator that takes advantage\n",
      "     |      of :func:`~mode.timers.Timer` to monitor drift and timer\n",
      "     |      oerlap.\n",
      "     |      \n",
      "     |      Uses ``Service.sleep`` so exits fast when the service is\n",
      "     |      stopped.\n",
      "     |      \n",
      "     |      Note:\n",
      "     |          Will sleep the full `interval` seconds before returning\n",
      "     |          from first iteration.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |          >>> async for sleep_time in self.itertimer(1.0):\n",
      "     |          ...   print('another second passed, just woke up...')\n",
      "     |          ...   await perform_some_http_request()\n",
      "     |  \n",
      "     |  async join_services(self, services: Sequence[mode.types.services.ServiceT]) -> None\n",
      "     |  \n",
      "     |  async maybe_start(self) -> bool\n",
      "     |      Start the service, if it has not already been started.\n",
      "     |  \n",
      "     |  on_init(self) -> None\n",
      "     |  \n",
      "     |  async remove_dependency(self, service: mode.types.services.ServiceT) -> mode.types.services.ServiceT\n",
      "     |      Stop and remove dependency of this service.\n",
      "     |  \n",
      "     |  async restart(self) -> None\n",
      "     |      Restart this service.\n",
      "     |  \n",
      "     |  service_reset(self) -> None\n",
      "     |  \n",
      "     |  set_shutdown(self) -> None\n",
      "     |      Set the shutdown signal.\n",
      "     |      \n",
      "     |      Notes:\n",
      "     |          If :attr:`wait_for_shutdown` is set, stopping the service\n",
      "     |          will wait for this flag to be set.\n",
      "     |  \n",
      "     |  async sleep(self, n: Union[datetime.timedelta, float, str], *, loop: asyncio.events.AbstractEventLoop = None) -> None\n",
      "     |      Sleep for ``n`` seconds, or until service stopped.\n",
      "     |  \n",
      "     |  async start(self) -> None\n",
      "     |  \n",
      "     |  async stop(self) -> None\n",
      "     |      Stop the service.\n",
      "     |  \n",
      "     |  async transition_with(self, flag: str, fut: Awaitable, *args: Any, **kwargs: Any) -> Any\n",
      "     |  \n",
      "     |  async wait(self, *coros: Union[_asyncio.Future, Generator[Any, NoneType, Any], Awaitable, asyncio.locks.Event, mode.utils.locks.Event], timeout: Union[datetime.timedelta, float, str] = None) -> mode.services.WaitResult\n",
      "     |      Wait for coroutines to complete, or until the service stops.\n",
      "     |  \n",
      "     |  async wait_first(self, *coros: Union[_asyncio.Future, Generator[Any, NoneType, Any], Awaitable, asyncio.locks.Event, mode.utils.locks.Event], timeout: Union[datetime.timedelta, float, str] = None) -> mode.services.WaitResults\n",
      "     |  \n",
      "     |  async wait_for_stopped(self, *coros: Union[_asyncio.Future, Generator[Any, NoneType, Any], Awaitable, asyncio.locks.Event, mode.utils.locks.Event], timeout: Union[datetime.timedelta, float, str] = None) -> bool\n",
      "     |  \n",
      "     |  async wait_many(self, coros: Iterable[Union[_asyncio.Future, Generator[Any, NoneType, Any], Awaitable, asyncio.locks.Event, mode.utils.locks.Event]], *, timeout: Union[datetime.timedelta, float, str] = None) -> mode.services.WaitResult\n",
      "     |  \n",
      "     |  async wait_until_stopped(self) -> None\n",
      "     |      Wait until the service is signalled to stop.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  __init_subclass__() -> None from abc.ABCMeta\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |  \n",
      "     |  from_awaitable(coro: Awaitable, *, name: str = None, **kwargs: Any) -> mode.types.services.ServiceT from abc.ABCMeta\n",
      "     |  \n",
      "     |  task(fun: Callable[[Any], Awaitable[NoneType]]) -> mode.services.ServiceTask from abc.ABCMeta\n",
      "     |      Decorate function to be used as background task.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> class S(Service):\n",
      "     |          ...\n",
      "     |          ...     @Service.task\n",
      "     |          ...     async def background_task(self):\n",
      "     |          ...         while not self.should_stop:\n",
      "     |          ...             await self.sleep(1.0)\n",
      "     |          ...             print('Waking up')\n",
      "     |  \n",
      "     |  timer(interval: Union[datetime.timedelta, float, str]) -> Callable[[Callable], mode.services.ServiceTask] from abc.ABCMeta\n",
      "     |      Background timer executing every ``n`` seconds.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> class S(Service):\n",
      "     |          ...\n",
      "     |          ...     @Service.timer(1.0)\n",
      "     |          ...     async def background_timer(self):\n",
      "     |          ...         print('Waking up')\n",
      "     |  \n",
      "     |  transitions_to(flag: str) -> Callable from abc.ABCMeta\n",
      "     |      Decorate function to set and reset diagnostic flag.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  crashed\n",
      "     |  \n",
      "     |  label\n",
      "     |      Label used for graphs.\n",
      "     |  \n",
      "     |  shortlabel\n",
      "     |      Label used for logging.\n",
      "     |  \n",
      "     |  should_stop\n",
      "     |      Return :const:`True` if the service must stop.\n",
      "     |  \n",
      "     |  started\n",
      "     |      Return :const:`True` if the service was started.\n",
      "     |  \n",
      "     |  state\n",
      "     |      Service state - as a human readable string.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  beacon\n",
      "     |      Beacon used to track services in a dependency graph.\n",
      "     |  \n",
      "     |  crash_reason\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from mode.services.Service:\n",
      "     |  \n",
      "     |  Diag = <class 'mode.services.Diag'>\n",
      "     |      Service diagnostics.\n",
      "     |      \n",
      "     |      This can be used to track what your service is doing.\n",
      "     |      For example if your service is a Kafka consumer with a background\n",
      "     |      thread that commits the offset every 30 seconds, you may want to\n",
      "     |      see when this happens::\n",
      "     |      \n",
      "     |          DIAG_COMMITTING = 'committing'\n",
      "     |      \n",
      "     |          class Consumer(Service):\n",
      "     |      \n",
      "     |              @Service.task\n",
      "     |              async def _background_commit(self) -> None:\n",
      "     |                  while not self.should_stop:\n",
      "     |                      await self.sleep(30.0)\n",
      "     |                      self.diag.set_flag(DIAG_COMITTING)\n",
      "     |                      try:\n",
      "     |                          await self._consumer.commit()\n",
      "     |                      finally:\n",
      "     |                          self.diag.unset_flag(DIAG_COMMITTING)\n",
      "     |      \n",
      "     |      The above code is setting the flag manually, but you can also use\n",
      "     |      a decorator to accomplish the same thing::\n",
      "     |      \n",
      "     |          @Service.timer(30.0)\n",
      "     |          async def _background_commit(self) -> None:\n",
      "     |              await self.commit()\n",
      "     |      \n",
      "     |          @Service.transitions_with(DIAG_COMITTING)\n",
      "     |          async def commit(self) -> None:\n",
      "     |              await self._consumer.commit()\n",
      "     |  \n",
      "     |  abstract = False\n",
      "     |  \n",
      "     |  mundane_level = 'info'\n",
      "     |  \n",
      "     |  restart_count = 0\n",
      "     |  \n",
      "     |  shutdown_timeout = 60.0\n",
      "     |  \n",
      "     |  wait_for_shutdown = False\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mode.services.ServiceBase:\n",
      "     |  \n",
      "     |  async __aenter__(self) -> mode.types.services.ServiceT\n",
      "     |      Return `self` upon entering the runtime context.\n",
      "     |  \n",
      "     |  async __aexit__(self, exc_type: Type[BaseException] = None, exc_val: BaseException = None, exc_tb: traceback = None) -> Union[bool, NoneType]\n",
      "     |      Raise any exception triggered within the runtime context.\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from mode.services.ServiceBase:\n",
      "     |  \n",
      "     |  loop\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from mode.services.ServiceBase:\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from mode.types.services.ServiceT:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.AbstractAsyncContextManager,)\n",
      "     |  \n",
      "     |  supervisor = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from contextlib.AbstractAsyncContextManager:\n",
      "     |  \n",
      "     |  __subclasshook__(C) from abc.ABCMeta\n",
      "     |      Abstract classes can override this to customize issubclass().\n",
      "     |      \n",
      "     |      This is invoked early on by abc.ABCMeta.__subclasscheck__().\n",
      "     |      It should return True, False or NotImplemented.  If it returns\n",
      "     |      NotImplemented, the normal algorithm is used.  Otherwise, it\n",
      "     |      overrides the normal algorithm (and the outcome is cached).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from contextlib.AbstractAsyncContextManager:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from abc.ABCMeta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwds)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mode.services.ServiceCallbacks:\n",
      "     |  \n",
      "     |  async on_restart(self) -> None\n",
      "     |      Service is being restarted.\n",
      "     |  \n",
      "     |  async on_shutdown(self) -> None\n",
      "     |      Service is being stopped/restarted.\n",
      "     |  \n",
      "     |  async on_stop(self) -> None\n",
      "     |      Service is being stopped/restarted.\n",
      "\n",
      "FUNCTIONS\n",
      "    current_event() -> Union[faust.types.events.EventT, NoneType]\n",
      "        Return the event currently being processed, or None.\n",
      "    \n",
      "    uuid() -> str\n",
      "        Generate random UUID string.\n",
      "        \n",
      "        Shortcut to ``str(uuid4())``.\n",
      "\n",
      "DATA\n",
      "    __all__ = ('Agent', 'App', 'Channel', 'ChannelT', 'Event', 'EventT', '...\n",
      "    __contact__ = 'contact@fauststream.com'\n",
      "    __docformat__ = 'restructuredtext'\n",
      "    __homepage__ = 'http://faust.readthedocs.io/'\n",
      "\n",
      "VERSION\n",
      "    1.10.4\n",
      "\n",
      "AUTHOR\n",
      "    Robinhood Markets, Inc.\n",
      "\n",
      "FILE\n",
      "    /home/jdowling/anaconda3/envs/38/lib/python3.8/site-packages/faust/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(faust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b8b0110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import hsfs\n",
    "\n",
    "HOST=\"34.78.148.2\"\n",
    "PROJECT=\"demo_fs_meb10000\"\n",
    "\n",
    "connection = hsfs.connection(\n",
    "    host=HOST,\n",
    "    project=PROJECT,\n",
    "    api_key_value=\"9tybM5t8Vj5ZPH6L.badVzfTTdelhCTZLDHthlHL7ITfDTI9IRsplEQ91ViHmBdn5JFDXJsJ47s7UtklL\",\n",
    "    engine=\"python\"\n",
    ")\n",
    "fs = connection.get_feature_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bf44a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \"/tmp/\" + HOST + \"/\" + PROJECT + \"/\"\n",
    "CA_FILE = BASE_PATH + \"ca_chain.pem\"\n",
    "CERT_FILE = BASE_PATH + \"client_cert.pem\"\n",
    "KEY_FILE = BASE_PATH + \"client_key.pem\"\n",
    "ssl_context = ssl.create_default_context(purpose=ssl.Purpose.SERVER_AUTH, cafile=CA_FILE)\n",
    "ssl_context.load_cert_chain(CERT_FILE, keyfile=KEY_FILE)\n",
    "# ssl_context = kafka.get_ssl_context()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af9d0427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw -> avro??\n",
    "BROKER_URL = \"kafka://\" + HOST + \":9092\"\n",
    "app = faust.App('empty', broker=BROKER_URL, #store='rocksdb://', \n",
    "  value_serializer='json', broker_credentials=ssl_context)    #A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de1e52e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_topic = app.topic('empty', key_type=str, value_type=str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ded387f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This sends events every 1 second to the process method above.\n",
    "@app.timer(interval=10.0)\n",
    "async def topic_writer(app):\n",
    "    await cc_topic.send(\n",
    "        value=\"hello\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0d38d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.agent(ingest)\n",
    "async def test(stream):\n",
    "    async for values in stream.take(100, within=10):\n",
    "        yield values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18965f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_topic = app.topic('cc_transactions', key_type=str, value_type=cc_transaction)\n",
    "\n",
    "# Order is a json serialized dictionary,\n",
    "# having these fields:\n",
    "\n",
    "class cc_transaction(faust.Record, serializer=’avro’):\n",
    "    cc_num: str\n",
    "    category: str\n",
    "    amount: float\n",
    "    transaction_ts: str\n",
    "\n",
    "count_by_cc_num = app.Table('cc_count', default=int)\n",
    "\n",
    "@app.agent(cc_topic)\n",
    "async def process(cc_trans: faust.Stream[cc_transaction]) -> None:\n",
    "    async for trans in cc_trans.group_by(cc_transaction.cc_num):\n",
    "        count_by_cc_num[trans.cc_num] += 1\n",
    "\n",
    "\n",
    "# This sends events every 1 second to the process method above.\n",
    "@app.timer(interval=1.0)\n",
    "async def topic_writer(app):\n",
    "    await cc_topic.send(\n",
    "        value=cc_transaction(cc_num='Faust', category='you', amount=’’, transaction_ts=’’),\n",
    "    )\n",
    "\n",
    "\n",
    "# Have this one only write in batchs to HSFS\n",
    "@app.agent(orders_topic)\n",
    "async def process_order(orders):\n",
    "    async for order in orders:\n",
    "        # process each order using regular Python\n",
    "        total_price = order.price * order.quantity\n",
    "        await send_order_received_email(order.account_id, order)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5de78980",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n",
      "Usage: ipykernel_launcher.py [OPTIONS] COMMAND [ARGS]...\n",
      "Try 'ipykernel_launcher.py --help' for help.\n",
      "\n",
      "Error: Missing command.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUsageError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/38/lib/python3.8/site-packages/click/core.py:782\u001b[0m, in \u001b[0;36mBaseCommand.main\u001b[0;34m(self, args, prog_name, complete_var, standalone_mode, **extra)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_context(prog_name, args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra) \u001b[38;5;28;01mas\u001b[39;00m ctx:\n\u001b[0;32m--> 782\u001b[0m     rv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m standalone_mode:\n",
      "File \u001b[0;32m~/anaconda3/envs/38/lib/python3.8/site-packages/click/core.py:1240\u001b[0m, in \u001b[0;36mMultiCommand.invoke\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m   1239\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m _process_result([])\n\u001b[0;32m-> 1240\u001b[0m     \u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfail\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMissing command.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[38;5;66;03m# Fetch args back out\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/38/lib/python3.8/site-packages/click/core.py:550\u001b[0m, in \u001b[0;36mContext.fail\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;124;03m\"\"\"Aborts the execution of the program with a specific error\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;124;03mmessage.\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \n\u001b[1;32m    548\u001b[0m \u001b[38;5;124;03m:param message: the error message to fail with.\u001b[39;00m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 550\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m UsageError(message, \u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mUsageError\u001b[0m: Missing command.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/38/lib/python3.8/site-packages/faust/app/base.py:749\u001b[0m, in \u001b[0;36mApp.main\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworker_init_post_autodiscover()\n\u001b[0;32m--> 749\u001b[0m \u001b[43mcli\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mSystemExit\u001b[39;00m(\u001b[38;5;241m3451\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/38/lib/python3.8/site-packages/click/core.py:829\u001b[0m, in \u001b[0;36mBaseCommand.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;124;03m\"\"\"Alias for :meth:`main`.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 829\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/38/lib/python3.8/site-packages/click/core.py:800\u001b[0m, in \u001b[0;36mBaseCommand.main\u001b[0;34m(self, args, prog_name, complete_var, standalone_mode, **extra)\u001b[0m\n\u001b[1;32m    799\u001b[0m     e\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m--> 800\u001b[0m     \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit_code\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mSystemExit\u001b[0m: 2",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/38/lib/python3.8/site-packages/IPython/core/interactiveshell.py:1982\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   1979\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception_only:\n\u001b[1;32m   1980\u001b[0m     stb \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn exception has occurred, use \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mtb to see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1981\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe full traceback.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m-> 1982\u001b[0m     stb\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInteractiveTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_exception_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1983\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1984\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1985\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1986\u001b[0m         \u001b[38;5;66;03m# Exception classes can customise their traceback - we\u001b[39;00m\n\u001b[1;32m   1987\u001b[0m         \u001b[38;5;66;03m# use this in IPython.parallel for exceptions occurring\u001b[39;00m\n\u001b[1;32m   1988\u001b[0m         \u001b[38;5;66;03m# in the engines. This should return a list of strings.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/38/lib/python3.8/site-packages/IPython/core/ultratb.py:585\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_exception_only\u001b[39m(\u001b[38;5;28mself\u001b[39m, etype, value):\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;124;03m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[1;32m    579\u001b[0m \n\u001b[1;32m    580\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;124;03m    value : exception value\u001b[39;00m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 585\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mListTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/38/lib/python3.8/site-packages/IPython/core/ultratb.py:443\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    440\u001b[0m     chained_exc_ids\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(exception[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    441\u001b[0m     chained_exceptions_tb_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    442\u001b[0m     out_list \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 443\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchained_exc_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchained_exceptions_tb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;241m+\u001b[39m chained_exception_message\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;241m+\u001b[39m out_list)\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_list\n",
      "File \u001b[0;32m~/anaconda3/envs/38/lib/python3.8/site-packages/IPython/core/ultratb.py:1118\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1116\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1117\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtb \u001b[38;5;241m=\u001b[39m tb\n\u001b[0;32m-> 1118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/38/lib/python3.8/site-packages/IPython/core/ultratb.py:1012\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1009\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose_modes:\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[0;32m-> 1012\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMinimal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ListTB\u001b[38;5;241m.\u001b[39mget_exception_only(\u001b[38;5;28mself\u001b[39m, etype, value)\n",
      "File \u001b[0;32m~/anaconda3/envs/38/lib/python3.8/site-packages/IPython/core/ultratb.py:865\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstructured_traceback\u001b[39m(\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    858\u001b[0m     etype: \u001b[38;5;28mtype\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    862\u001b[0m     number_of_lines_of_context: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m    863\u001b[0m ):\n\u001b[1;32m    864\u001b[0m     \u001b[38;5;124;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 865\u001b[0m     formatted_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    868\u001b[0m     colors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mColors  \u001b[38;5;66;03m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[1;32m    869\u001b[0m     colorsnormal \u001b[38;5;241m=\u001b[39m colors\u001b[38;5;241m.\u001b[39mNormal  \u001b[38;5;66;03m# used a lot\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/38/lib/python3.8/site-packages/IPython/core/ultratb.py:799\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tb_offset, \u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m    797\u001b[0m head \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_header(etype, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlong_header)\n\u001b[1;32m    798\u001b[0m records \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 799\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m etb \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m    800\u001b[0m )\n\u001b[1;32m    802\u001b[0m frames \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    803\u001b[0m skipped \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/38/lib/python3.8/site-packages/IPython/core/ultratb.py:854\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[0;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m    848\u001b[0m     formatter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    849\u001b[0m options \u001b[38;5;241m=\u001b[39m stack_data\u001b[38;5;241m.\u001b[39mOptions(\n\u001b[1;32m    850\u001b[0m     before\u001b[38;5;241m=\u001b[39mbefore,\n\u001b[1;32m    851\u001b[0m     after\u001b[38;5;241m=\u001b[39mafter,\n\u001b[1;32m    852\u001b[0m     pygments_formatter\u001b[38;5;241m=\u001b[39mformatter,\n\u001b[1;32m    853\u001b[0m )\n\u001b[0;32m--> 854\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstack_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFrameInfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[tb_offset:]\n",
      "File \u001b[0;32m~/anaconda3/envs/38/lib/python3.8/site-packages/stack_data/core.py:546\u001b[0m, in \u001b[0;36mFrameInfo.stack_data\u001b[0;34m(cls, frame_or_tb, options, collapse_repeated_frames)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstack_data\u001b[39m(\n\u001b[1;32m    532\u001b[0m         \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    536\u001b[0m         collapse_repeated_frames: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    537\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Union[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrameInfo\u001b[39m\u001b[38;5;124m'\u001b[39m, RepeatedFrames]]:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;124;03m    An iterator of FrameInfo and RepeatedFrames objects representing\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;124;03m    a full traceback or stack. Similar consecutive frames are collapsed into RepeatedFrames\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;124;03m    and optionally an Options object to configure.\u001b[39;00m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 546\u001b[0m     stack \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miter_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_or_tb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    548\u001b[0m     \u001b[38;5;66;03m# Reverse the stack from a frame so that it's in the same order\u001b[39;00m\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;66;03m# as the order from a traceback, which is the order of a printed\u001b[39;00m\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;66;03m# traceback when read top to bottom (most recent call last)\u001b[39;00m\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_frame(frame_or_tb):\n",
      "File \u001b[0;32m~/anaconda3/envs/38/lib/python3.8/site-packages/stack_data/utils.py:98\u001b[0m, in \u001b[0;36miter_stack\u001b[0;34m(frame_or_tb)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m frame_or_tb:\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m frame_or_tb\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_or_tb\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     99\u001b[0m         frame_or_tb \u001b[38;5;241m=\u001b[39m frame_or_tb\u001b[38;5;241m.\u001b[39mf_back\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/38/lib/python3.8/site-packages/stack_data/utils.py:91\u001b[0m, in \u001b[0;36mis_frame\u001b[0;34m(frame_or_tb)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_frame\u001b[39m(frame_or_tb: Union[FrameType, TracebackType]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m---> 91\u001b[0m     \u001b[43massert_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mframe_or_tb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFrameType\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTracebackType\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(frame_or_tb, (types\u001b[38;5;241m.\u001b[39mFrameType,))\n",
      "File \u001b[0;32m~/anaconda3/envs/38/lib/python3.8/site-packages/stack_data/utils.py:172\u001b[0m, in \u001b[0;36massert_\u001b[0;34m(condition, error)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(error, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    171\u001b[0m     error \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mAssertionError\u001b[39;00m(error)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "app.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9e4bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "38",
   "language": "python",
   "name": "38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
